{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numpy experimentation\n",
    "a=np.ones((10))\n",
    "b=np.zeros(10)\n",
    "b[1]=1\n",
    "print a.shape, \" \", b.shape\n",
    "c =1.2*np.outer(a,b)\n",
    "print (a*b)\n",
    "print np.square(c)\n",
    "print c\n",
    "print c[:,1].shape\n",
    "a[0][b==0]=4\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename,'rb') as fp:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', fp.read(4))\n",
    "        shape = tuple(struct.unpack('>I', fp.read(4))[0] for d in range(dims))\n",
    "        np_array = np.frombuffer(fp.read(), dtype=np.uint8).reshape(shape)\n",
    "    return np_array\n",
    "\n",
    "def preprocess_type1(image_file, label_file):\n",
    "    images = read_file(image_file)\n",
    "    labels = read_file(label_file)\n",
    "    if (len(labels) > 10000):\n",
    "        labels = labels[:10000]\n",
    "        images = images[:10000]    \n",
    "    images = images/255.0\n",
    "    images = images.reshape( (10000, 784))\n",
    "\n",
    "    labels = labels.reshape(-1,1)\n",
    "    data = np.concatenate((images, labels), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def preprocess_type2(image_file, label_file):\n",
    "    images = read_file(image_file)\n",
    "    labels = read_file(label_file)\n",
    "    if (len(labels) > 10000):\n",
    "        labels = labels[:10000]\n",
    "        images = images[:10000]    \n",
    "    images = images/255.0\n",
    "    images_sample = np.zeros((10000, 14, 14))\n",
    "    for i,image in enumerate(images):\n",
    "        for j in range(14):\n",
    "            for k in range(14):\n",
    "                images_sample[i][j][k] = max(image[j*2][k*2], image[j*2][k*2+1],\n",
    "                                                 image[j*2+1][k*2], image[j*2+1][k*2+1])\n",
    "    images_sample = images_sample.reshape( (10000, 196))\n",
    "\n",
    "    labels = labels.reshape(-1,1)\n",
    "    data = np.concatenate((images_sample, labels), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def get_features_labels(data, bias):\n",
    "    examples = data[:,:-1]\n",
    "    labels = data[:,-1]\n",
    "    classifier_labels = np.zeros((10, len(labels)))\n",
    "    for i in range(10):\n",
    "        classifier_labels[i][labels == i] = 1\n",
    "    examples = np.append(examples, bias, 1)\n",
    "    return examples, labels, classifier_labels\n",
    "\n",
    "def get_true_label(digit, perceptron_type):\n",
    "    if digit == perceptron_type:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(test_data, weights):\n",
    "    data_size = len(test_data)\n",
    "    bias = np.ones((data_size,1))\n",
    "    examples, labels, classifier_labels = get_features_labels(test_data, bias)\n",
    "    prediction = np.ones(data_size, dtype = int)\n",
    "    correct = 0\n",
    "    for i, example in enumerate(examples):\n",
    "        activation_values = sigmoid(np.sum(weights*example, axis = 1))\n",
    "        prediction[i] = np.argmax(activation_values)\n",
    "        if prediction[i] == labels[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct*1.0/data_size\n",
    "    return prediction, labels, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "def sigmoid(value):\n",
    "    value[value > 100] = 100\n",
    "    value[value < -100] = -100\n",
    "    return 1/(1+np.exp(-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../hw2/DATA_FOLDER/\"\n",
    "\n",
    "train_data_type1 = preprocess_type1(path + '/train-images.idx3-ubyte', path + '/train-labels.idx1-ubyte')\n",
    "# print train_data[1]\n",
    "test_data_type1 = preprocess_type1(path + '/t10k-images.idx3-ubyte', path + '/t10k-labels.idx1-ubyte')\n",
    "\n",
    "train_data_type2 = preprocess_type2(path + '/train-images.idx3-ubyte', path + '/train-labels.idx1-ubyte')\n",
    "# print train_data[1]\n",
    "test_data_type2 = preprocess_type2(path + '/t10k-images.idx3-ubyte', path + '/t10k-labels.idx1-ubyte')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 785)\n",
      "(10000, 785)\n",
      "(10000, 197)\n",
      "[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.13725490e-01   8.58823529e-01   1.00000000e+00\n",
      "   5.33333333e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   5.88235294e-02   9.56862745e-01   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.92156863e-01   3.80392157e-01\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.09803922e-02   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   4.23529412e-01   9.49019608e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.80392157e-02   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   1.41176471e-01   9.92156863e-01   9.92156863e-01   7.84313725e-03\n",
      "   0.00000000e+00   0.00000000e+00   7.37254902e-01   9.92156863e-01\n",
      "   2.74509804e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.33333333e-01   4.90196078e-01\n",
      "   9.84313725e-01   9.84313725e-01   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   7.60784314e-01   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.92156863e-01   2.70588235e-01\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   9.68627451e-01   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   4.58823529e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   4.19607843e-01\n",
      "   9.92156863e-01   4.54901961e-01   2.82352941e-01   9.92156863e-01\n",
      "   9.92156863e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   9.92156863e-01   9.92156863e-01   0.00000000e+00\n",
      "   1.33333333e-01   9.92156863e-01   9.92156863e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   8.50980392e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.92156863e-01   9.92156863e-01\n",
      "   6.39215686e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   7.84313725e-03   8.54901961e-01   9.92156863e-01\n",
      "   9.92156863e-01   4.78431373e-01   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   8.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print train_data_type1.shape\n",
    "print test_data_type1.shape\n",
    "print train_data_type2.shape\n",
    "print test_data_type2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sgd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    feature_length = train_data.shape[1]\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,feature_length])\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,feature_length))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.00000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.00000001)\n",
    "        \n",
    "        weights -= delta_weights - lamda*weights\n",
    "        loss /= -data_size*1.0 + lamda\n",
    "        loss = np.sum(loss)\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "#         if loss < 3.4 and epoch > 50:\n",
    "#             return weights, loss\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    feature_length = train_data.shape[1]\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,feature_length])\n",
    "    bias = np.ones((data_size,1))\n",
    "    prev_loss = 1000\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,feature_length))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.0000000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.0000000001)\n",
    "        \n",
    "        weights = weights - delta_weights - lamda*weights\n",
    "        loss = loss*-1.0/data_size + lamda*np.sum(np.square(weights), axis = 1)/2.0\n",
    "        loss = np.sum(loss)/10.0\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "        delta_loss = prev_loss - loss\n",
    "        prev_loss = loss\n",
    "#         print \"delta loss \", delta_loss\n",
    "        if delta_loss > 0 and delta_loss < 0.0001 and epochs > 100:\n",
    "            return weights, loss\n",
    "    return weights, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.674931541741  Training Accuracy:  0.2804  Test Accuracy:  0.2712\n",
      "epoch  1 : Training loss:  1.19823364967  Training Accuracy:  0.3526  Test Accuracy:  0.3386\n",
      "epoch  2 : Training loss:  0.744361075544  Training Accuracy:  0.4597  Test Accuracy:  0.4477\n",
      "epoch  3 : Training loss:  0.401092482749  Training Accuracy:  0.5884  Test Accuracy:  0.5817\n",
      "epoch  4 : Training loss:  0.248319846932  Training Accuracy:  0.742  Test Accuracy:  0.7284\n",
      "epoch  5 : Training loss:  0.163279300994  Training Accuracy:  0.7626  Test Accuracy:  0.7606\n",
      "epoch  6 : Training loss:  0.163768828407  Training Accuracy:  0.7928  Test Accuracy:  0.787\n",
      "epoch  7 : Training loss:  0.146542632221  Training Accuracy:  0.8009  Test Accuracy:  0.7947\n",
      "epoch  8 : Training loss:  0.148842618766  Training Accuracy:  0.8013  Test Accuracy:  0.7987\n",
      "epoch  9 : Training loss:  0.141737354505  Training Accuracy:  0.7705  Test Accuracy:  0.7691\n",
      "epoch  10 : Training loss:  0.157665764417  Training Accuracy:  0.833  Test Accuracy:  0.829\n",
      "epoch  11 : Training loss:  0.127688261229  Training Accuracy:  0.825  Test Accuracy:  0.8243\n",
      "epoch  12 : Training loss:  0.128047173343  Training Accuracy:  0.8202  Test Accuracy:  0.8148\n",
      "epoch  13 : Training loss:  0.127343547536  Training Accuracy:  0.8123  Test Accuracy:  0.8112\n",
      "epoch  14 : Training loss:  0.130047223633  Training Accuracy:  0.8184  Test Accuracy:  0.8129\n",
      "epoch  15 : Training loss:  0.125286297194  Training Accuracy:  0.8134  Test Accuracy:  0.8116\n",
      "epoch  16 : Training loss:  0.128295585841  Training Accuracy:  0.8338  Test Accuracy:  0.8309\n",
      "epoch  17 : Training loss:  0.119282750756  Training Accuracy:  0.8303  Test Accuracy:  0.8284\n",
      "epoch  18 : Training loss:  0.119903210662  Training Accuracy:  0.8417  Test Accuracy:  0.8382\n",
      "epoch  19 : Training loss:  0.115558375  Training Accuracy:  0.8389  Test Accuracy:  0.8354\n",
      "epoch  20 : Training loss:  0.116371264926  Training Accuracy:  0.8507  Test Accuracy:  0.8459\n",
      "epoch  21 : Training loss:  0.111740518339  Training Accuracy:  0.8477  Test Accuracy:  0.8434\n",
      "epoch  22 : Training loss:  0.112079033467  Training Accuracy:  0.8583  Test Accuracy:  0.8524\n",
      "epoch  23 : Training loss:  0.108391421521  Training Accuracy:  0.8551  Test Accuracy:  0.8503\n",
      "epoch  24 : Training loss:  0.108459584022  Training Accuracy:  0.8632  Test Accuracy:  0.8572\n",
      "epoch  25 : Training loss:  0.105420789281  Training Accuracy:  0.8623  Test Accuracy:  0.857\n",
      "epoch  26 : Training loss:  0.105314646723  Training Accuracy:  0.8697  Test Accuracy:  0.8619\n",
      "epoch  27 : Training loss:  0.102798719625  Training Accuracy:  0.8679  Test Accuracy:  0.8617\n",
      "epoch  28 : Training loss:  0.102581514302  Training Accuracy:  0.8726  Test Accuracy:  0.866\n",
      "epoch  29 : Training loss:  0.100492767126  Training Accuracy:  0.8723  Test Accuracy:  0.8668\n",
      "epoch  30 : Training loss:  0.100204478262  Training Accuracy:  0.8766  Test Accuracy:  0.8703\n",
      "epoch  31 : Training loss:  0.0984691211817  Training Accuracy:  0.8761  Test Accuracy:  0.8706\n",
      "epoch  32 : Training loss:  0.0981356206614  Training Accuracy:  0.8792  Test Accuracy:  0.8728\n",
      "epoch  33 : Training loss:  0.0966948188187  Training Accuracy:  0.8793  Test Accuracy:  0.8739\n",
      "epoch  34 : Training loss:  0.0963337255341  Training Accuracy:  0.8819  Test Accuracy:  0.8761\n",
      "epoch  35 : Training loss:  0.0951383072748  Training Accuracy:  0.8818  Test Accuracy:  0.8766\n",
      "epoch  36 : Training loss:  0.0947620505174  Training Accuracy:  0.883  Test Accuracy:  0.8772\n",
      "epoch  37 : Training loss:  0.093769265091  Training Accuracy:  0.884  Test Accuracy:  0.8796\n",
      "epoch  38 : Training loss:  0.0933867667965  Training Accuracy:  0.8851  Test Accuracy:  0.8788\n",
      "epoch  39 : Training loss:  0.0925588564143  Training Accuracy:  0.885  Test Accuracy:  0.8819\n",
      "epoch  40 : Training loss:  0.0921766217523  Training Accuracy:  0.8869  Test Accuracy:  0.8804\n",
      "epoch  41 : Training loss:  0.0914805713007  Training Accuracy:  0.8871  Test Accuracy:  0.883\n",
      "epoch  42 : Training loss:  0.0911034281974  Training Accuracy:  0.8877  Test Accuracy:  0.8819\n",
      "epoch  43 : Training loss:  0.0905111728809  Training Accuracy:  0.8883  Test Accuracy:  0.8841\n",
      "epoch  44 : Training loss:  0.0901427399018  Training Accuracy:  0.8881  Test Accuracy:  0.8834\n",
      "epoch  45 : Training loss:  0.0896312804889  Training Accuracy:  0.8894  Test Accuracy:  0.8845\n",
      "epoch  46 : Training loss:  0.0892742355916  Training Accuracy:  0.8894  Test Accuracy:  0.884\n",
      "epoch  47 : Training loss:  0.0888254007731  Training Accuracy:  0.8901  Test Accuracy:  0.8853\n",
      "epoch  48 : Training loss:  0.0884816261215  Training Accuracy:  0.8904  Test Accuracy:  0.8848\n",
      "epoch  49 : Training loss:  0.0880814890565  Training Accuracy:  0.8911  Test Accuracy:  0.8865\n",
      "epoch  50 : Training loss:  0.0877521573941  Training Accuracy:  0.8911  Test Accuracy:  0.8857\n",
      "epoch  51 : Training loss:  0.0873902626429  Training Accuracy:  0.8914  Test Accuracy:  0.8869\n",
      "epoch  52 : Training loss:  0.087075913576  Training Accuracy:  0.8918  Test Accuracy:  0.8869\n",
      "epoch  53 : Training loss:  0.0867444893141  Training Accuracy:  0.892  Test Accuracy:  0.888\n",
      "epoch  54 : Training loss:  0.0864451221395  Training Accuracy:  0.8924  Test Accuracy:  0.8884\n",
      "epoch  55 : Training loss:  0.0861383939515  Training Accuracy:  0.8924  Test Accuracy:  0.8888\n",
      "epoch  56 : Training loss:  0.0858535821129  Training Accuracy:  0.8932  Test Accuracy:  0.8888\n",
      "epoch  57 : Training loss:  0.0855672324407  Training Accuracy:  0.8937  Test Accuracy:  0.8894\n",
      "epoch  58 : Training loss:  0.0852962495053  Training Accuracy:  0.8942  Test Accuracy:  0.8892\n",
      "epoch  59 : Training loss:  0.085027017084  Training Accuracy:  0.8944  Test Accuracy:  0.8902\n",
      "epoch  60 : Training loss:  0.0847689584016  Training Accuracy:  0.895  Test Accuracy:  0.89\n",
      "epoch  61 : Training loss:  0.0845143504634  Training Accuracy:  0.8946  Test Accuracy:  0.8909\n",
      "epoch  62 : Training loss:  0.0842682368358  Training Accuracy:  0.8957  Test Accuracy:  0.8906\n",
      "epoch  63 : Training loss:  0.0840263241373  Training Accuracy:  0.8954  Test Accuracy:  0.8914\n",
      "epoch  64 : Training loss:  0.0837911799175  Training Accuracy:  0.8962  Test Accuracy:  0.891\n",
      "epoch  65 : Training loss:  0.0835604500307  Training Accuracy:  0.8956  Test Accuracy:  0.8919\n",
      "epoch  66 : Training loss:  0.083335354418  Training Accuracy:  0.8966  Test Accuracy:  0.8912\n",
      "epoch  67 : Training loss:  0.0831146055677  Training Accuracy:  0.8965  Test Accuracy:  0.8921\n",
      "epoch  68 : Training loss:  0.0828987204406  Training Accuracy:  0.8968  Test Accuracy:  0.8918\n",
      "epoch  69 : Training loss:  0.082686983802  Training Accuracy:  0.8971  Test Accuracy:  0.8927\n",
      "epoch  70 : Training loss:  0.0824795637141  Training Accuracy:  0.8975  Test Accuracy:  0.8922\n",
      "epoch  71 : Training loss:  0.0822760460362  Training Accuracy:  0.8984  Test Accuracy:  0.8929\n",
      "epoch  72 : Training loss:  0.0820764363855  Training Accuracy:  0.8985  Test Accuracy:  0.8923\n",
      "epoch  73 : Training loss:  0.0818804774067  Training Accuracy:  0.8992  Test Accuracy:  0.8931\n",
      "epoch  74 : Training loss:  0.0816881059829  Training Accuracy:  0.8998  Test Accuracy:  0.893\n",
      "epoch  75 : Training loss:  0.0814991467821  Training Accuracy:  0.8999  Test Accuracy:  0.8939\n",
      "epoch  76 : Training loss:  0.081313512564  Training Accuracy:  0.9  Test Accuracy:  0.8941\n",
      "epoch  77 : Training loss:  0.0811310720842  Training Accuracy:  0.8999  Test Accuracy:  0.8944\n",
      "epoch  78 : Training loss:  0.0809517337912  Training Accuracy:  0.9002  Test Accuracy:  0.8948\n",
      "epoch  79 : Training loss:  0.0807753914919  Training Accuracy:  0.9004  Test Accuracy:  0.8946\n",
      "epoch  80 : Training loss:  0.0806019572532  Training Accuracy:  0.9007  Test Accuracy:  0.8947\n",
      "epoch  81 : Training loss:  0.0804313403479  Training Accuracy:  0.901  Test Accuracy:  0.8948\n",
      "epoch  82 : Training loss:  0.0802634590427  Training Accuracy:  0.901  Test Accuracy:  0.895\n",
      "epoch  83 : Training loss:  0.0800982331333  Training Accuracy:  0.9011  Test Accuracy:  0.895\n",
      "epoch  84 : Training loss:  0.0799355874567  Training Accuracy:  0.9013  Test Accuracy:  0.895\n",
      "epoch  85 : Training loss:  0.0797754496539  Training Accuracy:  0.9015  Test Accuracy:  0.8952\n",
      "epoch  86 : Training loss:  0.0796177507066  Training Accuracy:  0.9017  Test Accuracy:  0.8955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  87 : Training loss:  0.0794624245402  Training Accuracy:  0.9018  Test Accuracy:  0.8957\n",
      "epoch  88 : Training loss:  0.0793094076505  Training Accuracy:  0.9022  Test Accuracy:  0.8956\n",
      "epoch  89 : Training loss:  0.0791586392525  Training Accuracy:  0.9024  Test Accuracy:  0.8956\n",
      "epoch  90 : Training loss:  0.0790100607391  Training Accuracy:  0.9023  Test Accuracy:  0.8957\n",
      "epoch  91 : Training loss:  0.0788636159216  Training Accuracy:  0.9026  Test Accuracy:  0.8959\n",
      "epoch  92 : Training loss:  0.0787192505498  Training Accuracy:  0.9027  Test Accuracy:  0.896\n",
      "epoch  93 : Training loss:  0.0785769125091  Training Accuracy:  0.903  Test Accuracy:  0.896\n",
      "epoch  94 : Training loss:  0.0784365514486  Training Accuracy:  0.9032  Test Accuracy:  0.8964\n",
      "epoch  95 : Training loss:  0.0782981189109  Training Accuracy:  0.9035  Test Accuracy:  0.8965\n",
      "epoch  96 : Training loss:  0.0781615680573  Training Accuracy:  0.9035  Test Accuracy:  0.8969\n",
      "epoch  97 : Training loss:  0.0780268537402  Training Accuracy:  0.9038  Test Accuracy:  0.897\n",
      "epoch  98 : Training loss:  0.0778939323019  Training Accuracy:  0.904  Test Accuracy:  0.8972\n",
      "epoch  99 : Training loss:  0.0777627616066  Training Accuracy:  0.904  Test Accuracy:  0.8975\n",
      "epoch  100 : Training loss:  0.0776333008914  Training Accuracy:  0.9041  Test Accuracy:  0.8973\n",
      "epoch  101 : Training loss:  0.0775055107712  Training Accuracy:  0.9043  Test Accuracy:  0.8977\n",
      "epoch  102 : Training loss:  0.0773793531269  Training Accuracy:  0.9049  Test Accuracy:  0.8981\n",
      "epoch  103 : Training loss:  0.0772547910932  Training Accuracy:  0.905  Test Accuracy:  0.8984\n",
      "epoch  104 : Training loss:  0.0771317889724  Training Accuracy:  0.905  Test Accuracy:  0.8983\n",
      "epoch  105 : Training loss:  0.0770103122126  Training Accuracy:  0.9053  Test Accuracy:  0.8983\n",
      "epoch  106 : Training loss:  0.0768903273394  Training Accuracy:  0.9056  Test Accuracy:  0.8984\n",
      "epoch  107 : Training loss:  0.0767718019286  Training Accuracy:  0.9057  Test Accuracy:  0.8985\n",
      "epoch  108 : Training loss:  0.0766547045513  Training Accuracy:  0.9058  Test Accuracy:  0.8985\n",
      "epoch  109 : Training loss:  0.076539004744  Training Accuracy:  0.906  Test Accuracy:  0.8989\n",
      "epoch  110 : Training loss:  0.0764246729627  Training Accuracy:  0.9062  Test Accuracy:  0.899\n",
      "epoch  111 : Training loss:  0.0763116805535  Training Accuracy:  0.9061  Test Accuracy:  0.8993\n",
      "epoch  112 : Training loss:  0.0761999997127  Training Accuracy:  0.9063  Test Accuracy:  0.8993\n",
      "epoch  113 : Training loss:  0.0760896034584  Training Accuracy:  0.9065  Test Accuracy:  0.8995\n",
      "epoch  114 : Training loss:  0.0759804655961  Training Accuracy:  0.9066  Test Accuracy:  0.8995\n",
      "epoch  115 : Training loss:  0.0758725606915  Training Accuracy:  0.9068  Test Accuracy:  0.8995\n",
      "epoch  116 : Training loss:  0.0757658640401  Training Accuracy:  0.9073  Test Accuracy:  0.8997\n",
      "epoch  117 : Training loss:  0.0756603516416  Training Accuracy:  0.9075  Test Accuracy:  0.9001\n",
      "epoch  118 : Training loss:  0.075556000173  Training Accuracy:  0.9076  Test Accuracy:  0.9002\n",
      "epoch  119 : Training loss:  0.0754527869647  Training Accuracy:  0.9076  Test Accuracy:  0.9004\n",
      "epoch  120 : Training loss:  0.0753506899765  Training Accuracy:  0.9078  Test Accuracy:  0.9005\n",
      "epoch  121 : Training loss:  0.0752496877751  Training Accuracy:  0.9079  Test Accuracy:  0.9006\n",
      "epoch  122 : Training loss:  0.0751497595125  Training Accuracy:  0.9081  Test Accuracy:  0.9006\n",
      "test accuracy  0.9006  training loss:  0.0751497595125\n"
     ]
    }
   ],
   "source": [
    "train_data_size = 10000\n",
    "epochs = 150\n",
    "learning_rate = 0.0001\n",
    "# lamda = 0.0001\n",
    "lamda = 0\n",
    "gd_weights, train_loss = train_gd(train_data_type1[:10000], epochs, learning_rate, lamda, test_data_type1)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data_type1, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.717509198154  Training Accuracy:  0.2636  Test Accuracy:  0.2512\n",
      "epoch  1 : Training loss:  0.740062702405  Training Accuracy:  0.4146  Test Accuracy:  0.3977\n",
      "epoch  2 : Training loss:  0.514912596479  Training Accuracy:  0.5113  Test Accuracy:  0.5119\n",
      "epoch  3 : Training loss:  0.325354984991  Training Accuracy:  0.6611  Test Accuracy:  0.6472\n",
      "epoch  4 : Training loss:  0.238064205898  Training Accuracy:  0.7445  Test Accuracy:  0.7399\n",
      "epoch  5 : Training loss:  0.209893676988  Training Accuracy:  0.7889  Test Accuracy:  0.7803\n",
      "epoch  6 : Training loss:  0.198924976666  Training Accuracy:  0.7943  Test Accuracy:  0.7927\n",
      "epoch  7 : Training loss:  0.190488726034  Training Accuracy:  0.8055  Test Accuracy:  0.8017\n",
      "epoch  8 : Training loss:  0.183341092464  Training Accuracy:  0.8115  Test Accuracy:  0.8092\n",
      "epoch  9 : Training loss:  0.177219560053  Training Accuracy:  0.818  Test Accuracy:  0.8141\n",
      "epoch  10 : Training loss:  0.171865631702  Training Accuracy:  0.8225  Test Accuracy:  0.819\n",
      "epoch  11 : Training loss:  0.167143238027  Training Accuracy:  0.8287  Test Accuracy:  0.8233\n",
      "epoch  12 : Training loss:  0.162933311126  Training Accuracy:  0.8312  Test Accuracy:  0.8273\n",
      "epoch  13 : Training loss:  0.159154017984  Training Accuracy:  0.8342  Test Accuracy:  0.8303\n",
      "epoch  14 : Training loss:  0.155736801939  Training Accuracy:  0.8367  Test Accuracy:  0.8326\n",
      "epoch  15 : Training loss:  0.152628954783  Training Accuracy:  0.8385  Test Accuracy:  0.8344\n",
      "epoch  16 : Training loss:  0.149787142523  Training Accuracy:  0.8403  Test Accuracy:  0.837\n",
      "epoch  17 : Training loss:  0.147176125087  Training Accuracy:  0.8418  Test Accuracy:  0.8388\n",
      "epoch  18 : Training loss:  0.144766822425  Training Accuracy:  0.8437  Test Accuracy:  0.8404\n",
      "epoch  19 : Training loss:  0.142534895238  Training Accuracy:  0.8454  Test Accuracy:  0.8417\n",
      "epoch  20 : Training loss:  0.140459975567  Training Accuracy:  0.8466  Test Accuracy:  0.8434\n",
      "epoch  21 : Training loss:  0.138524727147  Training Accuracy:  0.8477  Test Accuracy:  0.8445\n",
      "epoch  22 : Training loss:  0.136714408188  Training Accuracy:  0.8497  Test Accuracy:  0.8453\n",
      "epoch  23 : Training loss:  0.135016315936  Training Accuracy:  0.8508  Test Accuracy:  0.8468\n",
      "epoch  24 : Training loss:  0.13341949188  Training Accuracy:  0.852  Test Accuracy:  0.8482\n",
      "epoch  25 : Training loss:  0.131914393928  Training Accuracy:  0.8535  Test Accuracy:  0.8496\n",
      "epoch  26 : Training loss:  0.130492690572  Training Accuracy:  0.854  Test Accuracy:  0.8508\n",
      "epoch  27 : Training loss:  0.129147059253  Training Accuracy:  0.855  Test Accuracy:  0.8519\n",
      "epoch  28 : Training loss:  0.12787104233  Training Accuracy:  0.8558  Test Accuracy:  0.8522\n",
      "epoch  29 : Training loss:  0.12665891667  Training Accuracy:  0.856  Test Accuracy:  0.8528\n",
      "epoch  30 : Training loss:  0.125505592466  Training Accuracy:  0.8564  Test Accuracy:  0.8534\n",
      "epoch  31 : Training loss:  0.124406525117  Training Accuracy:  0.8578  Test Accuracy:  0.8546\n",
      "epoch  32 : Training loss:  0.123357643456  Training Accuracy:  0.8585  Test Accuracy:  0.8554\n",
      "epoch  33 : Training loss:  0.122355288132  Training Accuracy:  0.8594  Test Accuracy:  0.8564\n",
      "epoch  34 : Training loss:  0.12139616002  Training Accuracy:  0.8602  Test Accuracy:  0.8567\n",
      "epoch  35 : Training loss:  0.12047727599  Training Accuracy:  0.8608  Test Accuracy:  0.8576\n",
      "epoch  36 : Training loss:  0.119595931265  Training Accuracy:  0.8617  Test Accuracy:  0.8587\n",
      "epoch  37 : Training loss:  0.118749667014  Training Accuracy:  0.8622  Test Accuracy:  0.8596\n",
      "epoch  38 : Training loss:  0.117936242463  Training Accuracy:  0.8631  Test Accuracy:  0.8602\n",
      "epoch  39 : Training loss:  0.11715361074  Training Accuracy:  0.8637  Test Accuracy:  0.8607\n",
      "epoch  40 : Training loss:  0.116399897915  Training Accuracy:  0.8639  Test Accuracy:  0.8614\n",
      "epoch  41 : Training loss:  0.11567338472  Training Accuracy:  0.8646  Test Accuracy:  0.8615\n",
      "epoch  42 : Training loss:  0.114972490582  Training Accuracy:  0.8658  Test Accuracy:  0.8621\n",
      "epoch  43 : Training loss:  0.114295759613  Training Accuracy:  0.8662  Test Accuracy:  0.8626\n",
      "epoch  44 : Training loss:  0.113641848286  Training Accuracy:  0.8668  Test Accuracy:  0.8632\n",
      "epoch  45 : Training loss:  0.113009514567  Training Accuracy:  0.8677  Test Accuracy:  0.8636\n",
      "epoch  46 : Training loss:  0.112397608301  Training Accuracy:  0.868  Test Accuracy:  0.8646\n",
      "epoch  47 : Training loss:  0.111805062681  Training Accuracy:  0.8685  Test Accuracy:  0.8649\n",
      "epoch  48 : Training loss:  0.11123088667  Training Accuracy:  0.8688  Test Accuracy:  0.8651\n",
      "epoch  49 : Training loss:  0.110674158242  Training Accuracy:  0.869  Test Accuracy:  0.8656\n",
      "epoch  50 : Training loss:  0.110134018346  Training Accuracy:  0.8696  Test Accuracy:  0.8665\n",
      "epoch  51 : Training loss:  0.1096096655  Training Accuracy:  0.8703  Test Accuracy:  0.8671\n",
      "epoch  52 : Training loss:  0.109100350944  Training Accuracy:  0.8705  Test Accuracy:  0.8677\n",
      "epoch  53 : Training loss:  0.108605374275  Training Accuracy:  0.8705  Test Accuracy:  0.8686\n",
      "epoch  54 : Training loss:  0.108124079526  Training Accuracy:  0.8706  Test Accuracy:  0.8693\n",
      "epoch  55 : Training loss:  0.107655851611  Training Accuracy:  0.871  Test Accuracy:  0.8692\n",
      "epoch  56 : Training loss:  0.107200113127  Training Accuracy:  0.8715  Test Accuracy:  0.8693\n",
      "epoch  57 : Training loss:  0.106756321442  Training Accuracy:  0.8723  Test Accuracy:  0.8702\n",
      "epoch  58 : Training loss:  0.106323966064  Training Accuracy:  0.8725  Test Accuracy:  0.8703\n",
      "epoch  59 : Training loss:  0.105902566241  Training Accuracy:  0.8727  Test Accuracy:  0.8705\n",
      "epoch  60 : Training loss:  0.10549166878  Training Accuracy:  0.8734  Test Accuracy:  0.8709\n",
      "epoch  61 : Training loss:  0.105090846058  Training Accuracy:  0.8732  Test Accuracy:  0.8712\n",
      "epoch  62 : Training loss:  0.104699694204  Training Accuracy:  0.8736  Test Accuracy:  0.8714\n",
      "epoch  63 : Training loss:  0.104317831437  Training Accuracy:  0.8738  Test Accuracy:  0.8719\n",
      "epoch  64 : Training loss:  0.103944896545  Training Accuracy:  0.8742  Test Accuracy:  0.8722\n",
      "epoch  65 : Training loss:  0.103580547483  Training Accuracy:  0.8746  Test Accuracy:  0.8723\n",
      "epoch  66 : Training loss:  0.1032244601  Training Accuracy:  0.8752  Test Accuracy:  0.8727\n",
      "epoch  67 : Training loss:  0.102876326951  Training Accuracy:  0.8755  Test Accuracy:  0.8727\n",
      "epoch  68 : Training loss:  0.102535856216  Training Accuracy:  0.8757  Test Accuracy:  0.8727\n",
      "epoch  69 : Training loss:  0.1022027707  Training Accuracy:  0.8758  Test Accuracy:  0.873\n",
      "epoch  70 : Training loss:  0.101876806903  Training Accuracy:  0.8763  Test Accuracy:  0.8728\n",
      "epoch  71 : Training loss:  0.101557714173  Training Accuracy:  0.8767  Test Accuracy:  0.873\n",
      "epoch  72 : Training loss:  0.101245253914  Training Accuracy:  0.8769  Test Accuracy:  0.8731\n",
      "epoch  73 : Training loss:  0.100939198852  Training Accuracy:  0.8769  Test Accuracy:  0.8734\n",
      "epoch  74 : Training loss:  0.100639332364  Training Accuracy:  0.8768  Test Accuracy:  0.8735\n",
      "epoch  75 : Training loss:  0.100345447839  Training Accuracy:  0.8771  Test Accuracy:  0.8735\n",
      "epoch  76 : Training loss:  0.100057348105  Training Accuracy:  0.8773  Test Accuracy:  0.8742\n",
      "epoch  77 : Training loss:  0.0997748448752  Training Accuracy:  0.8775  Test Accuracy:  0.8744\n",
      "epoch  78 : Training loss:  0.0994977582501  Training Accuracy:  0.8777  Test Accuracy:  0.8744\n",
      "epoch  79 : Training loss:  0.0992259162425  Training Accuracy:  0.8782  Test Accuracy:  0.8745\n",
      "epoch  80 : Training loss:  0.0989591543395  Training Accuracy:  0.8783  Test Accuracy:  0.8749\n",
      "epoch  81 : Training loss:  0.0986973150926  Training Accuracy:  0.879  Test Accuracy:  0.8753\n",
      "epoch  82 : Training loss:  0.0984402477347  Training Accuracy:  0.8793  Test Accuracy:  0.8754\n",
      "epoch  83 : Training loss:  0.0981878078229  Training Accuracy:  0.8794  Test Accuracy:  0.8757\n",
      "epoch  84 : Training loss:  0.0979398569031  Training Accuracy:  0.8796  Test Accuracy:  0.8759\n",
      "epoch  85 : Training loss:  0.0976962621969  Training Accuracy:  0.8797  Test Accuracy:  0.8762\n",
      "epoch  86 : Training loss:  0.0974568963083  Training Accuracy:  0.8798  Test Accuracy:  0.876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  87 : Training loss:  0.0972216369477  Training Accuracy:  0.8798  Test Accuracy:  0.8763\n",
      "epoch  88 : Training loss:  0.0969903666741  Training Accuracy:  0.8803  Test Accuracy:  0.8766\n",
      "epoch  89 : Training loss:  0.096762972652  Training Accuracy:  0.8804  Test Accuracy:  0.8767\n",
      "epoch  90 : Training loss:  0.0965393464238  Training Accuracy:  0.8804  Test Accuracy:  0.8768\n",
      "epoch  91 : Training loss:  0.0963193836953  Training Accuracy:  0.8807  Test Accuracy:  0.8771\n",
      "epoch  92 : Training loss:  0.0961029841337  Training Accuracy:  0.8806  Test Accuracy:  0.8775\n",
      "epoch  93 : Training loss:  0.0958900511778  Training Accuracy:  0.8809  Test Accuracy:  0.8778\n",
      "epoch  94 : Training loss:  0.0956804918591  Training Accuracy:  0.8815  Test Accuracy:  0.8782\n",
      "epoch  95 : Training loss:  0.0954742166329  Training Accuracy:  0.8816  Test Accuracy:  0.8782\n",
      "epoch  96 : Training loss:  0.095271139219  Training Accuracy:  0.8817  Test Accuracy:  0.8782\n",
      "epoch  97 : Training loss:  0.0950711764515  Training Accuracy:  0.8818  Test Accuracy:  0.8787\n",
      "epoch  98 : Training loss:  0.0948742481369  Training Accuracy:  0.8821  Test Accuracy:  0.8791\n",
      "epoch  99 : Training loss:  0.09468027692  Training Accuracy:  0.8823  Test Accuracy:  0.8795\n",
      "epoch  100 : Training loss:  0.0944891881566  Training Accuracy:  0.8824  Test Accuracy:  0.8795\n",
      "epoch  101 : Training loss:  0.0943009097941  Training Accuracy:  0.8827  Test Accuracy:  0.8794\n",
      "epoch  102 : Training loss:  0.0941153722572  Training Accuracy:  0.8829  Test Accuracy:  0.8796\n",
      "epoch  103 : Training loss:  0.0939325083409  Training Accuracy:  0.8833  Test Accuracy:  0.8797\n",
      "epoch  104 : Training loss:  0.0937522531082  Training Accuracy:  0.8833  Test Accuracy:  0.88\n",
      "epoch  105 : Training loss:  0.0935745437931  Training Accuracy:  0.8835  Test Accuracy:  0.8803\n",
      "epoch  106 : Training loss:  0.0933993197097  Training Accuracy:  0.8838  Test Accuracy:  0.8807\n",
      "epoch  107 : Training loss:  0.0932265221641  Training Accuracy:  0.8837  Test Accuracy:  0.881\n",
      "epoch  108 : Training loss:  0.0930560943727  Training Accuracy:  0.884  Test Accuracy:  0.881\n",
      "epoch  109 : Training loss:  0.0928879813827  Training Accuracy:  0.884  Test Accuracy:  0.8811\n",
      "epoch  110 : Training loss:  0.0927221299985  Training Accuracy:  0.8841  Test Accuracy:  0.8815\n",
      "epoch  111 : Training loss:  0.0925584887098  Training Accuracy:  0.884  Test Accuracy:  0.8815\n",
      "epoch  112 : Training loss:  0.0923970076246  Training Accuracy:  0.8844  Test Accuracy:  0.8815\n",
      "epoch  113 : Training loss:  0.0922376384049  Training Accuracy:  0.8845  Test Accuracy:  0.8816\n",
      "epoch  114 : Training loss:  0.0920803342051  Training Accuracy:  0.8845  Test Accuracy:  0.8823\n",
      "epoch  115 : Training loss:  0.0919250496143  Training Accuracy:  0.8847  Test Accuracy:  0.8824\n",
      "epoch  116 : Training loss:  0.0917717406004  Training Accuracy:  0.8849  Test Accuracy:  0.8825\n",
      "epoch  117 : Training loss:  0.0916203644574  Training Accuracy:  0.885  Test Accuracy:  0.8825\n",
      "epoch  118 : Training loss:  0.0914708797543  Training Accuracy:  0.8853  Test Accuracy:  0.8826\n",
      "epoch  119 : Training loss:  0.0913232462879  Training Accuracy:  0.8857  Test Accuracy:  0.8828\n",
      "epoch  120 : Training loss:  0.091177425036  Training Accuracy:  0.8857  Test Accuracy:  0.883\n",
      "epoch  121 : Training loss:  0.0910333781137  Training Accuracy:  0.8857  Test Accuracy:  0.8833\n",
      "epoch  122 : Training loss:  0.0908910687317  Training Accuracy:  0.8856  Test Accuracy:  0.8836\n",
      "epoch  123 : Training loss:  0.0907504611561  Training Accuracy:  0.8857  Test Accuracy:  0.8837\n",
      "epoch  124 : Training loss:  0.0906115206697  Training Accuracy:  0.8857  Test Accuracy:  0.8839\n",
      "epoch  125 : Training loss:  0.0904742135362  Training Accuracy:  0.8858  Test Accuracy:  0.8839\n",
      "epoch  126 : Training loss:  0.0903385069643  Training Accuracy:  0.8857  Test Accuracy:  0.884\n",
      "epoch  127 : Training loss:  0.0902043690746  Training Accuracy:  0.8856  Test Accuracy:  0.884\n",
      "epoch  128 : Training loss:  0.0900717688677  Training Accuracy:  0.8856  Test Accuracy:  0.8842\n",
      "epoch  129 : Training loss:  0.089940676193  Training Accuracy:  0.8857  Test Accuracy:  0.8844\n",
      "epoch  130 : Training loss:  0.0898110617193  Training Accuracy:  0.8856  Test Accuracy:  0.8846\n",
      "epoch  131 : Training loss:  0.0896828969072  Training Accuracy:  0.8855  Test Accuracy:  0.8849\n",
      "epoch  132 : Training loss:  0.0895561539812  Training Accuracy:  0.8857  Test Accuracy:  0.885\n",
      "epoch  133 : Training loss:  0.0894308059045  Training Accuracy:  0.8857  Test Accuracy:  0.8854\n",
      "epoch  134 : Training loss:  0.0893068263536  Training Accuracy:  0.8859  Test Accuracy:  0.8853\n",
      "epoch  135 : Training loss:  0.0891841896949  Training Accuracy:  0.8861  Test Accuracy:  0.8855\n",
      "epoch  136 : Training loss:  0.0890628709614  Training Accuracy:  0.8862  Test Accuracy:  0.8854\n",
      "epoch  137 : Training loss:  0.088942845831  Training Accuracy:  0.8863  Test Accuracy:  0.8854\n",
      "epoch  138 : Training loss:  0.0888240906053  Training Accuracy:  0.8863  Test Accuracy:  0.8855\n",
      "epoch  139 : Training loss:  0.0887065821894  Training Accuracy:  0.8867  Test Accuracy:  0.8856\n",
      "epoch  140 : Training loss:  0.0885902980722  Training Accuracy:  0.8869  Test Accuracy:  0.8857\n",
      "epoch  141 : Training loss:  0.0884752163079  Training Accuracy:  0.887  Test Accuracy:  0.8859\n",
      "epoch  142 : Training loss:  0.0883613154982  Training Accuracy:  0.887  Test Accuracy:  0.8859\n",
      "epoch  143 : Training loss:  0.0882485747744  Training Accuracy:  0.8873  Test Accuracy:  0.8859\n",
      "epoch  144 : Training loss:  0.0881369737813  Training Accuracy:  0.8873  Test Accuracy:  0.8859\n",
      "epoch  145 : Training loss:  0.0880264926609  Training Accuracy:  0.8873  Test Accuracy:  0.8861\n",
      "epoch  146 : Training loss:  0.0879171120372  Training Accuracy:  0.8876  Test Accuracy:  0.8863\n",
      "epoch  147 : Training loss:  0.0878088130011  Training Accuracy:  0.8877  Test Accuracy:  0.8862\n",
      "epoch  148 : Training loss:  0.0877015770965  Training Accuracy:  0.8878  Test Accuracy:  0.8863\n",
      "epoch  149 : Training loss:  0.0875953863061  Training Accuracy:  0.8878  Test Accuracy:  0.8865\n",
      "test accuracy  0.8865  training loss:  0.0875953863061\n"
     ]
    }
   ],
   "source": [
    "gd_weights, train_loss = train_gd(train_data_type2[:10000], epochs, learning_rate, lamda, test_data_type2)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data_type2, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.zeros((10,1))\n",
    "sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
