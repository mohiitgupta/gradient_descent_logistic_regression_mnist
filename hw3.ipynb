{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)   (10,)\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[[ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "(10,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-a2c2c077ca89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# numpy experimentation\n",
    "a=np.ones((10))\n",
    "b=np.zeros(10)\n",
    "b[1]=1\n",
    "print a.shape, \" \", b.shape\n",
    "c =1.2*np.outer(a,b)\n",
    "print (a*b)\n",
    "print np.square(c)\n",
    "print c\n",
    "print c[:,1].shape\n",
    "a[0][b==0]=4\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename,'rb') as fp:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', fp.read(4))\n",
    "        shape = tuple(struct.unpack('>I', fp.read(4))[0] for d in range(dims))\n",
    "        np_array = np.frombuffer(fp.read(), dtype=np.uint8).reshape(shape)\n",
    "    return np_array\n",
    "\n",
    "def preprocess(image_file, label_file):\n",
    "    images = read_file(image_file)\n",
    "    labels = read_file(label_file)\n",
    "    if (len(labels) > 10000):\n",
    "        labels = labels[:10000]\n",
    "        images = images[:10000]    \n",
    "    images = images/255.0\n",
    "    images = images.reshape( (10000, 784))\n",
    "\n",
    "    labels = labels.reshape(-1,1)\n",
    "    data = np.concatenate((images, labels), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def get_features_labels(data, bias):\n",
    "    examples = data[:,:-1]\n",
    "    labels = data[:,-1]\n",
    "    classifier_labels = np.zeros((10, len(labels)))\n",
    "    for i in range(10):\n",
    "        classifier_labels[i][labels == i] = 1\n",
    "    examples = np.append(examples, bias, 1)\n",
    "    return examples, labels, classifier_labels\n",
    "\n",
    "def get_true_label(digit, perceptron_type):\n",
    "    if digit == perceptron_type:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(test_data, weights):\n",
    "    data_size = len(test_data)\n",
    "    bias = np.ones((data_size,1))\n",
    "    examples, labels, classifier_labels = get_features_labels(test_data, bias)\n",
    "    prediction = np.ones(data_size, dtype = int)\n",
    "    correct = 0\n",
    "    for i, example in enumerate(examples):\n",
    "        activation_values = sigmoid(np.sum(weights*example, axis = 1))\n",
    "        prediction[i] = np.argmax(activation_values)\n",
    "        if prediction[i] == labels[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct*1.0/data_size\n",
    "    return prediction, labels, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "def sigmoid(value):\n",
    "    value[value > 100] = 100\n",
    "    value[value < -100] = -100\n",
    "    return 1/(1+np.exp(-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"../hw2/DATA_FOLDER/\"\n",
    "\n",
    "train_data = preprocess(path + '/train-images.idx3-ubyte', path + '/train-labels.idx1-ubyte')\n",
    "# print train_data[1]\n",
    "test_data = preprocess(path + '/t10k-images.idx3-ubyte', path + '/t10k-labels.idx1-ubyte')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate(w, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "\n",
    "    A = sigmoid(np.dot(w,X.T)) \n",
    "    print A.shape\n",
    "\n",
    "    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n",
    "\n",
    "    dz= (1/m)*(A - Y)\n",
    "    dw = np.dot(dz,X)\n",
    "    print dw.shape\n",
    "\n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\"dw\": dw}\n",
    "\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sgd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,785])\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,785))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.00000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.00000001)\n",
    "        \n",
    "        weights -= delta_weights - lamda*weights\n",
    "        loss /= -data_size*1.0 + lamda\n",
    "        loss = np.sum(loss)\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "#         if loss < 3.4 and epoch > 50:\n",
    "#             return weights, loss\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,785])\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,785))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.0000000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.0000000001)\n",
    "        \n",
    "        weights = weights - delta_weights - lamda*weights\n",
    "        loss = loss*-1.0/data_size + lamda*np.sum(np.square(weights), axis = 1)/2.0\n",
    "        loss = np.sum(loss)/10.0\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "#         if loss < 3.4 and epoch > 50:\n",
    "#             return weights, loss\n",
    "    return weights, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.731236185586  Training Accuracy:  0.2143  Test Accuracy:  0.2157\n",
      "epoch  1 : Training loss:  2.30258504981  Training Accuracy:  0.3873  Test Accuracy:  0.3861\n",
      "epoch  2 : Training loss:  2.29070834874  Training Accuracy:  0.4509  Test Accuracy:  0.4474\n",
      "epoch  3 : Training loss:  1.73144637633  Training Accuracy:  0.549  Test Accuracy:  0.5353\n",
      "epoch  4 : Training loss:  1.21561101483  Training Accuracy:  0.6335  Test Accuracy:  0.6241\n",
      "epoch  5 : Training loss:  0.873589227886  Training Accuracy:  0.7855  Test Accuracy:  0.7746\n",
      "epoch  6 : Training loss:  0.561741706794  Training Accuracy:  0.7104  Test Accuracy:  0.7045\n",
      "epoch  7 : Training loss:  0.815785057782  Training Accuracy:  0.7224  Test Accuracy:  0.7157\n",
      "epoch  8 : Training loss:  0.656823415819  Training Accuracy:  0.7248  Test Accuracy:  0.7175\n",
      "epoch  9 : Training loss:  0.633155815187  Training Accuracy:  0.8214  Test Accuracy:  0.8115\n",
      "epoch  10 : Training loss:  0.368261454508  Training Accuracy:  0.8275  Test Accuracy:  0.8193\n",
      "epoch  11 : Training loss:  0.324307483144  Training Accuracy:  0.7802  Test Accuracy:  0.7722\n",
      "epoch  12 : Training loss:  0.501217014952  Training Accuracy:  0.6972  Test Accuracy:  0.6839\n",
      "epoch  13 : Training loss:  0.722494852  Training Accuracy:  0.7777  Test Accuracy:  0.7656\n",
      "epoch  14 : Training loss:  0.487155659523  Training Accuracy:  0.6888  Test Accuracy:  0.6769\n",
      "epoch  15 : Training loss:  0.637641548807  Training Accuracy:  0.7336  Test Accuracy:  0.7206\n",
      "epoch  16 : Training loss:  0.636342368343  Training Accuracy:  0.7128  Test Accuracy:  0.7076\n",
      "epoch  17 : Training loss:  0.66538410541  Training Accuracy:  0.8334  Test Accuracy:  0.8239\n",
      "epoch  18 : Training loss:  0.367735048228  Training Accuracy:  0.8528  Test Accuracy:  0.8491\n",
      "epoch  19 : Training loss:  0.387184367067  Training Accuracy:  0.7137  Test Accuracy:  0.6999\n",
      "epoch  20 : Training loss:  0.690025954521  Training Accuracy:  0.8187  Test Accuracy:  0.8098\n",
      "epoch  21 : Training loss:  0.407943305259  Training Accuracy:  0.7448  Test Accuracy:  0.7328\n",
      "epoch  22 : Training loss:  0.55652649457  Training Accuracy:  0.8146  Test Accuracy:  0.8012\n",
      "epoch  23 : Training loss:  0.421887671392  Training Accuracy:  0.8235  Test Accuracy:  0.8159\n",
      "epoch  24 : Training loss:  0.355140499779  Training Accuracy:  0.8794  Test Accuracy:  0.8723\n",
      "epoch  25 : Training loss:  0.226399855837  Training Accuracy:  0.8589  Test Accuracy:  0.8517\n",
      "epoch  26 : Training loss:  0.258443025751  Training Accuracy:  0.845  Test Accuracy:  0.8403\n",
      "epoch  27 : Training loss:  0.368340667775  Training Accuracy:  0.7546  Test Accuracy:  0.7465\n",
      "epoch  28 : Training loss:  0.551326458863  Training Accuracy:  0.8496  Test Accuracy:  0.8453\n",
      "epoch  29 : Training loss:  0.303453859906  Training Accuracy:  0.7859  Test Accuracy:  0.7821\n",
      "epoch  30 : Training loss:  0.440504145791  Training Accuracy:  0.8551  Test Accuracy:  0.8415\n",
      "epoch  31 : Training loss:  0.254169653213  Training Accuracy:  0.8145  Test Accuracy:  0.804\n",
      "epoch  32 : Training loss:  0.393179667666  Training Accuracy:  0.8077  Test Accuracy:  0.7955\n",
      "epoch  33 : Training loss:  0.397080363232  Training Accuracy:  0.8451  Test Accuracy:  0.8314\n",
      "epoch  34 : Training loss:  0.275939322283  Training Accuracy:  0.8509  Test Accuracy:  0.837\n",
      "epoch  35 : Training loss:  0.275793865575  Training Accuracy:  0.7853  Test Accuracy:  0.7734\n",
      "epoch  36 : Training loss:  0.393249241038  Training Accuracy:  0.798  Test Accuracy:  0.7877\n",
      "epoch  37 : Training loss:  0.457643430475  Training Accuracy:  0.7453  Test Accuracy:  0.7353\n",
      "epoch  38 : Training loss:  0.521981275962  Training Accuracy:  0.8559  Test Accuracy:  0.8454\n",
      "epoch  39 : Training loss:  0.320827731601  Training Accuracy:  0.7781  Test Accuracy:  0.7692\n",
      "epoch  40 : Training loss:  0.469268053107  Training Accuracy:  0.8757  Test Accuracy:  0.8623\n",
      "epoch  41 : Training loss:  0.262823884227  Training Accuracy:  0.8249  Test Accuracy:  0.8123\n",
      "epoch  42 : Training loss:  0.368658158503  Training Accuracy:  0.8581  Test Accuracy:  0.8476\n",
      "epoch  43 : Training loss:  0.333270015412  Training Accuracy:  0.7728  Test Accuracy:  0.7624\n",
      "epoch  44 : Training loss:  0.473846680276  Training Accuracy:  0.8568  Test Accuracy:  0.8453\n",
      "epoch  45 : Training loss:  0.271117047723  Training Accuracy:  0.7909  Test Accuracy:  0.7781\n",
      "epoch  46 : Training loss:  0.374334548364  Training Accuracy:  0.8448  Test Accuracy:  0.8332\n",
      "epoch  47 : Training loss:  0.286157949175  Training Accuracy:  0.7851  Test Accuracy:  0.7723\n",
      "epoch  48 : Training loss:  0.388937761853  Training Accuracy:  0.8186  Test Accuracy:  0.8076\n",
      "epoch  49 : Training loss:  0.346239693872  Training Accuracy:  0.7959  Test Accuracy:  0.7847\n",
      "epoch  50 : Training loss:  0.352386832627  Training Accuracy:  0.7968  Test Accuracy:  0.7877\n",
      "epoch  51 : Training loss:  0.401885471222  Training Accuracy:  0.8032  Test Accuracy:  0.7904\n",
      "epoch  52 : Training loss:  0.342579724678  Training Accuracy:  0.85  Test Accuracy:  0.8327\n",
      "epoch  53 : Training loss:  0.25436352011  Training Accuracy:  0.8122  Test Accuracy:  0.7993\n",
      "epoch  54 : Training loss:  0.303614002426  Training Accuracy:  0.78  Test Accuracy:  0.7658\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-310-d0df5e8da7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgd_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgd_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"test accuracy \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" training loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-302-8aca4a288dd4>\u001b[0m in \u001b[0;36mtrain_gd\u001b[0;34m(train_data, num_epoches, learning_rate, lamda, test_data)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdata_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_data_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtest_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"epoch \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": Training loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" Training Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" Test Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-206-54212a443a76>\u001b[0m in \u001b[0;36minference\u001b[0;34m(test_data, weights)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mactivation_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-243-5b32f8b754ff>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data_size = 10000\n",
    "epochs = 200\n",
    "learning_rate = 0.001\n",
    "lamda = 0.00001\n",
    "lamda = 0\n",
    "gd_weights, train_loss = train_gd(train_data[:10000], epochs, learning_rate, lamda, test_data)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.zeros((10,1))\n",
    "sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
