{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)   (10,)\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[[ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "(10,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-a2c2c077ca89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# numpy experimentation\n",
    "a=np.ones((10))\n",
    "b=np.zeros(10)\n",
    "b[1]=1\n",
    "print a.shape, \" \", b.shape\n",
    "c =1.2*np.outer(a,b)\n",
    "print (a*b)\n",
    "print np.square(c)\n",
    "print c\n",
    "print c[:,1].shape\n",
    "a[0][b==0]=4\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename,'rb') as fp:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', fp.read(4))\n",
    "        shape = tuple(struct.unpack('>I', fp.read(4))[0] for d in range(dims))\n",
    "        np_array = np.frombuffer(fp.read(), dtype=np.uint8).reshape(shape)\n",
    "    return np_array\n",
    "\n",
    "def preprocess(image_file, label_file):\n",
    "    images = read_file(image_file)\n",
    "    labels = read_file(label_file)\n",
    "    if (len(labels) > 10000):\n",
    "        labels = labels[:10000]\n",
    "        images = images[:10000]    \n",
    "    images = images/255.0\n",
    "    images = images.reshape( (10000, 784))\n",
    "\n",
    "    labels = labels.reshape(-1,1)\n",
    "    data = np.concatenate((images, labels), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def get_features_labels(data, bias):\n",
    "    examples = data[:,:-1]\n",
    "    labels = data[:,-1]\n",
    "    classifier_labels = np.zeros((10, len(labels)))\n",
    "    for i in range(10):\n",
    "        classifier_labels[i][labels == i] = 1\n",
    "    examples = np.append(examples, bias, 1)\n",
    "    return examples, labels, classifier_labels\n",
    "\n",
    "def get_true_label(digit, perceptron_type):\n",
    "    if digit == perceptron_type:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(test_data, weights):\n",
    "    data_size = len(test_data)\n",
    "    bias = np.ones((data_size,1))\n",
    "    examples, labels, classifier_labels = get_features_labels(test_data, bias)\n",
    "    prediction = np.ones(data_size, dtype = int)\n",
    "    correct = 0\n",
    "    for i, example in enumerate(examples):\n",
    "        activation_values = sigmoid(np.sum(weights*example, axis = 1))\n",
    "        prediction[i] = np.argmax(activation_values)\n",
    "        if prediction[i] == labels[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct*1.0/data_size\n",
    "    return prediction, labels, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "def sigmoid(value):\n",
    "    value[value > 100] = 100\n",
    "    value[value < -100] = -100\n",
    "    return 1/(1+np.exp(-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"../hw2/DATA_FOLDER/\"\n",
    "\n",
    "train_data = preprocess(path + '/train-images.idx3-ubyte', path + '/train-labels.idx1-ubyte')\n",
    "# print train_data[1]\n",
    "test_data = preprocess(path + '/t10k-images.idx3-ubyte', path + '/t10k-labels.idx1-ubyte')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate(w, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "\n",
    "    A = sigmoid(np.dot(w,X.T)) \n",
    "    print A.shape\n",
    "\n",
    "    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n",
    "\n",
    "    dz= (1/m)*(A - Y)\n",
    "    dw = np.dot(dz,X)\n",
    "    print dw.shape\n",
    "\n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\"dw\": dw}\n",
    "\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sgd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,785])\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,785))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.00000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.00000001)\n",
    "        \n",
    "        weights -= delta_weights - lamda*weights\n",
    "        loss /= -data_size*1.0 + lamda\n",
    "        loss = np.sum(loss)\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "#         if loss < 3.4 and epoch > 50:\n",
    "#             return weights, loss\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,785])\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,785))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.0000000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.0000000001)\n",
    "        \n",
    "        weights = weights - delta_weights - lamda*weights\n",
    "        loss = loss*-1.0/data_size + lamda*np.sum(np.square(weights), axis = 1)/2.0\n",
    "        loss = np.sum(loss)/10.0\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "#         if loss < 3.4 and epoch > 50:\n",
    "#             return weights, loss\n",
    "    return weights, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.706672768741  Training Accuracy:  0.1852  Test Accuracy:  0.1789\n",
      "epoch  1 : Training loss:  1.29744579709  Training Accuracy:  0.2769  Test Accuracy:  0.2674\n",
      "epoch  2 : Training loss:  0.827568992205  Training Accuracy:  0.3071  Test Accuracy:  0.2985\n",
      "epoch  3 : Training loss:  0.412070061101  Training Accuracy:  0.6708  Test Accuracy:  0.6717\n",
      "epoch  4 : Training loss:  0.196299370789  Training Accuracy:  0.7251  Test Accuracy:  0.7067\n",
      "epoch  5 : Training loss:  0.16231403662  Training Accuracy:  0.7245  Test Accuracy:  0.7172\n",
      "epoch  6 : Training loss:  0.169865154929  Training Accuracy:  0.6811  Test Accuracy:  0.6708\n",
      "epoch  7 : Training loss:  0.179724609849  Training Accuracy:  0.7875  Test Accuracy:  0.782\n",
      "epoch  8 : Training loss:  0.145855028405  Training Accuracy:  0.7423  Test Accuracy:  0.7323\n",
      "epoch  9 : Training loss:  0.148581372358  Training Accuracy:  0.7928  Test Accuracy:  0.7912\n",
      "epoch  10 : Training loss:  0.141257054633  Training Accuracy:  0.7336  Test Accuracy:  0.7214\n",
      "epoch  11 : Training loss:  0.159008465922  Training Accuracy:  0.8346  Test Accuracy:  0.8306\n",
      "epoch  12 : Training loss:  0.125464888392  Training Accuracy:  0.7956  Test Accuracy:  0.7893\n",
      "epoch  13 : Training loss:  0.129069935065  Training Accuracy:  0.837  Test Accuracy:  0.836\n",
      "epoch  14 : Training loss:  0.12264054561  Training Accuracy:  0.8015  Test Accuracy:  0.7946\n",
      "epoch  15 : Training loss:  0.131181223136  Training Accuracy:  0.8414  Test Accuracy:  0.8391\n",
      "epoch  16 : Training loss:  0.119352588603  Training Accuracy:  0.8152  Test Accuracy:  0.8053\n",
      "epoch  17 : Training loss:  0.128089334613  Training Accuracy:  0.8488  Test Accuracy:  0.8478\n",
      "epoch  18 : Training loss:  0.114786245444  Training Accuracy:  0.8331  Test Accuracy:  0.8252\n",
      "epoch  19 : Training loss:  0.120424892169  Training Accuracy:  0.8538  Test Accuracy:  0.85\n",
      "epoch  20 : Training loss:  0.111866251692  Training Accuracy:  0.8431  Test Accuracy:  0.8343\n",
      "epoch  21 : Training loss:  0.116426365479  Training Accuracy:  0.8585  Test Accuracy:  0.8534\n",
      "epoch  22 : Training loss:  0.108870301341  Training Accuracy:  0.8523  Test Accuracy:  0.8445\n",
      "epoch  23 : Training loss:  0.112080930262  Training Accuracy:  0.8626  Test Accuracy:  0.8564\n",
      "epoch  24 : Training loss:  0.106193687455  Training Accuracy:  0.8596  Test Accuracy:  0.8517\n",
      "epoch  25 : Training loss:  0.10838682941  Training Accuracy:  0.8666  Test Accuracy:  0.8601\n",
      "epoch  26 : Training loss:  0.103763766516  Training Accuracy:  0.8652  Test Accuracy:  0.8584\n",
      "epoch  27 : Training loss:  0.105174581714  Training Accuracy:  0.871  Test Accuracy:  0.8625\n",
      "epoch  28 : Training loss:  0.101558580511  Training Accuracy:  0.8691  Test Accuracy:  0.8635\n",
      "epoch  29 : Training loss:  0.102382912999  Training Accuracy:  0.873  Test Accuracy:  0.8662\n",
      "epoch  30 : Training loss:  0.0995605090894  Training Accuracy:  0.8736  Test Accuracy:  0.8694\n",
      "epoch  31 : Training loss:  0.0999591497098  Training Accuracy:  0.8747  Test Accuracy:  0.868\n",
      "epoch  32 : Training loss:  0.0977552073948  Training Accuracy:  0.8764  Test Accuracy:  0.8711\n",
      "epoch  33 : Training loss:  0.0978569847229  Training Accuracy:  0.8775  Test Accuracy:  0.8702\n",
      "epoch  34 : Training loss:  0.0961299566282  Training Accuracy:  0.8799  Test Accuracy:  0.8746\n",
      "epoch  35 : Training loss:  0.0960344153124  Training Accuracy:  0.8791  Test Accuracy:  0.8723\n",
      "epoch  36 : Training loss:  0.0946716716803  Training Accuracy:  0.8817  Test Accuracy:  0.8767\n",
      "epoch  37 : Training loss:  0.0944523895719  Training Accuracy:  0.8811  Test Accuracy:  0.8744\n"
     ]
    }
   ],
   "source": [
    "train_data_size = 10000\n",
    "epochs = 200\n",
    "learning_rate = 0.0001\n",
    "lamda = 0.00001\n",
    "# lamda = 0\n",
    "gd_weights, train_loss = train_gd(train_data[:10000], epochs, learning_rate, lamda, test_data)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.zeros((10,1))\n",
    "sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
