{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numpy experimentation\n",
    "a=np.ones((10))\n",
    "b=np.zeros(10)\n",
    "b[1]=1\n",
    "print a.shape, \" \", b.shape\n",
    "c =1.2*np.outer(a,b)\n",
    "print (a*b)\n",
    "print np.square(c)\n",
    "print c\n",
    "print c[:,1].shape\n",
    "a[0][b==0]=4\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename,'rb') as fp:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', fp.read(4))\n",
    "        shape = tuple(struct.unpack('>I', fp.read(4))[0] for d in range(dims))\n",
    "        np_array = np.frombuffer(fp.read(), dtype=np.uint8).reshape(shape)\n",
    "    return np_array\n",
    "\n",
    "def preprocess_type1(image_file, label_file):\n",
    "    images = read_file(image_file)\n",
    "    labels = read_file(label_file)\n",
    "    if (len(labels) > 10000):\n",
    "        labels = labels[:10000]\n",
    "        images = images[:10000]    \n",
    "    images = images/255.0\n",
    "    images = images.reshape( (10000, 784))\n",
    "\n",
    "    labels = labels.reshape(-1,1)\n",
    "    data = np.concatenate((images, labels), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def preprocess_type2(image_file, label_file):\n",
    "    images = read_file(image_file)\n",
    "    labels = read_file(label_file)\n",
    "    if (len(labels) > 10000):\n",
    "        labels = labels[:10000]\n",
    "        images = images[:10000]    \n",
    "    images = images/255.0\n",
    "    images_sample = np.zeros((10000, 14, 14))\n",
    "    for i,image in enumerate(images):\n",
    "        for j in range(14):\n",
    "            for k in range(14):\n",
    "                images_sample[i][j][k] = max(image[j*2][k*2], image[j*2][k*2+1],\n",
    "                                                 image[j*2+1][k*2], image[j*2+1][k*2+1])\n",
    "    images_sample = images_sample.reshape( (10000, 196))\n",
    "\n",
    "    labels = labels.reshape(-1,1)\n",
    "    data = np.concatenate((images_sample, labels), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def get_features_labels(data, bias):\n",
    "    examples = data[:,:-1]\n",
    "    labels = data[:,-1]\n",
    "    classifier_labels = np.zeros((10, len(labels)))\n",
    "    for i in range(10):\n",
    "        classifier_labels[i][labels == i] = 1\n",
    "    examples = np.append(examples, bias, 1)\n",
    "    return examples, labels, classifier_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(test_data, weights):\n",
    "    data_size = len(test_data)\n",
    "    bias = np.ones((data_size,1))\n",
    "    examples, labels, classifier_labels = get_features_labels(test_data, bias)\n",
    "    prediction = np.ones(data_size, dtype = int)\n",
    "    correct = 0\n",
    "    for i, example in enumerate(examples):\n",
    "        activation_values = sigmoid(np.sum(weights*example, axis = 1))\n",
    "        prediction[i] = np.argmax(activation_values)\n",
    "        if prediction[i] == labels[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct*1.0/data_size\n",
    "    return prediction, labels, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "def sigmoid(value):\n",
    "    value[value > 100] = 100\n",
    "    value[value < -100] = -100\n",
    "    return 1/(1+np.exp(-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../hw2/DATA_FOLDER/\"\n",
    "\n",
    "train_data_type1 = preprocess_type1(path + '/train-images.idx3-ubyte', path + '/train-labels.idx1-ubyte')\n",
    "# print train_data[1]\n",
    "test_data_type1 = preprocess_type1(path + '/t10k-images.idx3-ubyte', path + '/t10k-labels.idx1-ubyte')\n",
    "\n",
    "train_data_type2 = preprocess_type2(path + '/train-images.idx3-ubyte', path + '/train-labels.idx1-ubyte')\n",
    "# print train_data[1]\n",
    "test_data_type2 = preprocess_type2(path + '/t10k-images.idx3-ubyte', path + '/t10k-labels.idx1-ubyte')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 785)\n",
      "(10000, 785)\n",
      "(10000, 197)\n",
      "[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.13725490e-01   8.58823529e-01   1.00000000e+00\n",
      "   5.33333333e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   5.88235294e-02   9.56862745e-01   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.92156863e-01   3.80392157e-01\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.09803922e-02   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   4.23529412e-01   9.49019608e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.80392157e-02   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   1.41176471e-01   9.92156863e-01   9.92156863e-01   7.84313725e-03\n",
      "   0.00000000e+00   0.00000000e+00   7.37254902e-01   9.92156863e-01\n",
      "   2.74509804e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.33333333e-01   4.90196078e-01\n",
      "   9.84313725e-01   9.84313725e-01   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   7.60784314e-01   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.92156863e-01   2.70588235e-01\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   9.68627451e-01   9.92156863e-01\n",
      "   9.92156863e-01   9.92156863e-01   4.58823529e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   4.19607843e-01\n",
      "   9.92156863e-01   4.54901961e-01   2.82352941e-01   9.92156863e-01\n",
      "   9.92156863e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   9.92156863e-01   9.92156863e-01   0.00000000e+00\n",
      "   1.33333333e-01   9.92156863e-01   9.92156863e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   8.50980392e-01\n",
      "   9.92156863e-01   9.92156863e-01   9.92156863e-01   9.92156863e-01\n",
      "   6.39215686e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   7.84313725e-03   8.54901961e-01   9.92156863e-01\n",
      "   9.92156863e-01   4.78431373e-01   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   8.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print train_data_type1.shape\n",
    "print test_data_type1.shape\n",
    "print train_data_type2.shape\n",
    "print test_data_type2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    feature_length = train_data.shape[1]\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,feature_length])\n",
    "    bias = np.ones((data_size,1))\n",
    "    prev_loss = 1000\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,feature_length))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.0000000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.0000000001)\n",
    "        \n",
    "        weights = weights - delta_weights - learning_rate*lamda*weights\n",
    "        loss = loss*-1.0/data_size + lamda*np.sum(np.square(weights), axis = 1)/2.0\n",
    "        loss = np.sum(loss)/10.0\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "        delta_loss = prev_loss - loss\n",
    "        prev_loss = loss\n",
    "#         print \"delta loss \", delta_loss\n",
    "#         if delta_loss > 0 and delta_loss < 0.0001 and epoch > 100:\n",
    "#             return weights, loss\n",
    "    return weights, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sgd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    feature_length = train_data.shape[1]\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,feature_length])\n",
    "    bias = np.ones((data_size,1))\n",
    "    prev_loss = 1000\n",
    "    batch_size_loss = 1000\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        for i,example in enumerate(examples):\n",
    "            delta_weights = np.zeros((10,feature_length))\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            weights = weights - delta_weights - learning_rate*lamda*weights\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.0000000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.0000000001)\n",
    "\n",
    "            if i%batch_size_loss==0:\n",
    "                loss = loss*-1.0/batch_size_loss + lamda*np.sum(np.square(weights), axis = 1)/2.0\n",
    "                loss = np.sum(loss)/10.0\n",
    "                \n",
    "                train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "                test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "                print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "                delta_loss = prev_loss - loss\n",
    "                prev_loss = loss\n",
    "                loss = np.zeros(10)\n",
    "    #             print \"delta loss \", delta_loss\n",
    "                if delta_loss < 0.0001 and train_accuracy > 0.92:\n",
    "                    return weights, loss\n",
    "    return weights, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.000737346915721  Training Accuracy:  0.0799  Test Accuracy:  0.0823\n",
      "epoch  0 : Training loss:  0.197952422612  Training Accuracy:  0.8243  Test Accuracy:  0.8134\n",
      "epoch  0 : Training loss:  0.120229914222  Training Accuracy:  0.8544  Test Accuracy:  0.8455\n",
      "epoch  0 : Training loss:  0.108446815244  Training Accuracy:  0.8725  Test Accuracy:  0.8606\n",
      "epoch  0 : Training loss:  0.10082171913  Training Accuracy:  0.8782  Test Accuracy:  0.8712\n",
      "epoch  0 : Training loss:  0.0989253279014  Training Accuracy:  0.8887  Test Accuracy:  0.881\n",
      "epoch  0 : Training loss:  0.0977343305002  Training Accuracy:  0.8809  Test Accuracy:  0.8752\n",
      "epoch  0 : Training loss:  0.0896659019481  Training Accuracy:  0.8953  Test Accuracy:  0.8877\n",
      "epoch  0 : Training loss:  0.0896838271678  Training Accuracy:  0.894  Test Accuracy:  0.8847\n",
      "epoch  0 : Training loss:  0.0874300190852  Training Accuracy:  0.8915  Test Accuracy:  0.8838\n",
      "epoch  1 : Training loss:  3.1124675688e-05  Training Accuracy:  0.8977  Test Accuracy:  0.8917\n",
      "epoch  1 : Training loss:  0.0790586923916  Training Accuracy:  0.8976  Test Accuracy:  0.8916\n",
      "epoch  1 : Training loss:  0.0816662984527  Training Accuracy:  0.9039  Test Accuracy:  0.8908\n",
      "epoch  1 : Training loss:  0.0744779372014  Training Accuracy:  0.9047  Test Accuracy:  0.8935\n",
      "epoch  1 : Training loss:  0.0780014119096  Training Accuracy:  0.898  Test Accuracy:  0.891\n",
      "epoch  1 : Training loss:  0.0809434510051  Training Accuracy:  0.9038  Test Accuracy:  0.8928\n",
      "epoch  1 : Training loss:  0.0759827373048  Training Accuracy:  0.9087  Test Accuracy:  0.8975\n",
      "epoch  1 : Training loss:  0.0700699197218  Training Accuracy:  0.905  Test Accuracy:  0.8929\n",
      "epoch  1 : Training loss:  0.0828022786714  Training Accuracy:  0.9099  Test Accuracy:  0.8957\n",
      "epoch  1 : Training loss:  0.0794834415549  Training Accuracy:  0.9079  Test Accuracy:  0.8973\n",
      "epoch  2 : Training loss:  2.49944735112e-05  Training Accuracy:  0.9056  Test Accuracy:  0.8976\n",
      "epoch  2 : Training loss:  0.0775375217887  Training Accuracy:  0.9112  Test Accuracy:  0.8964\n",
      "epoch  2 : Training loss:  0.0755128952599  Training Accuracy:  0.9095  Test Accuracy:  0.8957\n",
      "epoch  2 : Training loss:  0.0659982374352  Training Accuracy:  0.9085  Test Accuracy:  0.8959\n",
      "epoch  2 : Training loss:  0.0754465072097  Training Accuracy:  0.9157  Test Accuracy:  0.9001\n",
      "epoch  2 : Training loss:  0.0765657667362  Training Accuracy:  0.9106  Test Accuracy:  0.8967\n",
      "epoch  2 : Training loss:  0.0746535401808  Training Accuracy:  0.9134  Test Accuracy:  0.9012\n",
      "epoch  2 : Training loss:  0.0631620972206  Training Accuracy:  0.9147  Test Accuracy:  0.899\n",
      "epoch  2 : Training loss:  0.0710151787173  Training Accuracy:  0.9146  Test Accuracy:  0.903\n",
      "epoch  2 : Training loss:  0.0694984234988  Training Accuracy:  0.9167  Test Accuracy:  0.9007\n",
      "epoch  3 : Training loss:  2.55730320585e-05  Training Accuracy:  0.9159  Test Accuracy:  0.9003\n",
      "epoch  3 : Training loss:  0.0678297805131  Training Accuracy:  0.9154  Test Accuracy:  0.898\n",
      "epoch  3 : Training loss:  0.0747703911655  Training Accuracy:  0.9157  Test Accuracy:  0.9014\n",
      "epoch  3 : Training loss:  0.0730909848105  Training Accuracy:  0.918  Test Accuracy:  0.9068\n",
      "epoch  3 : Training loss:  0.0629402224743  Training Accuracy:  0.9188  Test Accuracy:  0.9061\n",
      "epoch  3 : Training loss:  0.073645250339  Training Accuracy:  0.9141  Test Accuracy:  0.9006\n",
      "epoch  3 : Training loss:  0.0675918570719  Training Accuracy:  0.9185  Test Accuracy:  0.9002\n",
      "epoch  3 : Training loss:  0.063944833661  Training Accuracy:  0.9175  Test Accuracy:  0.9008\n",
      "epoch  3 : Training loss:  0.0685109656724  Training Accuracy:  0.9145  Test Accuracy:  0.8961\n",
      "epoch  3 : Training loss:  0.0652423132115  Training Accuracy:  0.9202  Test Accuracy:  0.9034\n",
      "epoch  4 : Training loss:  5.7249367634e-05  Training Accuracy:  0.9205  Test Accuracy:  0.9041\n",
      "epoch  4 : Training loss:  0.05856876407  Training Accuracy:  0.9204  Test Accuracy:  0.9033\n",
      "test accuracy  0.9033  training loss:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#stochastic gradient descent\n",
    "train_data_size = 10000\n",
    "epochs = 20\n",
    "learning_rate = 0.01\n",
    "lamda = 0.000001\n",
    "# lamda = 0\n",
    "gd_weights, train_loss = train_sgd(train_data_type1[:10000], epochs, learning_rate, lamda, test_data_type1)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data_type1, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.000656523051241  Training Accuracy:  0.1192  Test Accuracy:  0.1217\n",
      "epoch  0 : Training loss:  0.237418335823  Training Accuracy:  0.7812  Test Accuracy:  0.7745\n",
      "epoch  0 : Training loss:  0.160782442733  Training Accuracy:  0.8317  Test Accuracy:  0.8328\n",
      "epoch  0 : Training loss:  0.143470880245  Training Accuracy:  0.8466  Test Accuracy:  0.8468\n",
      "epoch  0 : Training loss:  0.127198016965  Training Accuracy:  0.8437  Test Accuracy:  0.8383\n",
      "epoch  0 : Training loss:  0.115728444415  Training Accuracy:  0.8613  Test Accuracy:  0.8568\n",
      "epoch  0 : Training loss:  0.108107128075  Training Accuracy:  0.8583  Test Accuracy:  0.8525\n",
      "epoch  0 : Training loss:  0.10619215709  Training Accuracy:  0.8765  Test Accuracy:  0.8753\n",
      "epoch  0 : Training loss:  0.103345400502  Training Accuracy:  0.8688  Test Accuracy:  0.8648\n",
      "epoch  0 : Training loss:  0.0989091052652  Training Accuracy:  0.8766  Test Accuracy:  0.8743\n",
      "epoch  1 : Training loss:  0.00028695619101  Training Accuracy:  0.8811  Test Accuracy:  0.8785\n",
      "epoch  1 : Training loss:  0.0921898191876  Training Accuracy:  0.8794  Test Accuracy:  0.8775\n",
      "epoch  1 : Training loss:  0.0951913888706  Training Accuracy:  0.8834  Test Accuracy:  0.8748\n",
      "epoch  1 : Training loss:  0.09568021822  Training Accuracy:  0.8845  Test Accuracy:  0.8824\n",
      "epoch  1 : Training loss:  0.0879709922072  Training Accuracy:  0.8816  Test Accuracy:  0.8807\n",
      "epoch  1 : Training loss:  0.0927456204733  Training Accuracy:  0.8831  Test Accuracy:  0.8827\n",
      "epoch  1 : Training loss:  0.0957344153026  Training Accuracy:  0.8866  Test Accuracy:  0.8829\n",
      "epoch  1 : Training loss:  0.0862599020928  Training Accuracy:  0.8816  Test Accuracy:  0.8765\n",
      "epoch  1 : Training loss:  0.0915929295633  Training Accuracy:  0.8932  Test Accuracy:  0.8872\n",
      "epoch  1 : Training loss:  0.0838460519986  Training Accuracy:  0.8917  Test Accuracy:  0.8861\n",
      "epoch  2 : Training loss:  1.58966371642e-05  Training Accuracy:  0.89  Test Accuracy:  0.886\n",
      "epoch  2 : Training loss:  0.0841629051406  Training Accuracy:  0.8926  Test Accuracy:  0.8841\n",
      "epoch  2 : Training loss:  0.0823949234444  Training Accuracy:  0.896  Test Accuracy:  0.8908\n",
      "epoch  2 : Training loss:  0.0795177879986  Training Accuracy:  0.8909  Test Accuracy:  0.8885\n",
      "epoch  2 : Training loss:  0.0792798951552  Training Accuracy:  0.896  Test Accuracy:  0.8906\n",
      "epoch  2 : Training loss:  0.0854477025063  Training Accuracy:  0.8951  Test Accuracy:  0.8907\n",
      "epoch  2 : Training loss:  0.0822893872904  Training Accuracy:  0.8963  Test Accuracy:  0.8923\n",
      "epoch  2 : Training loss:  0.0870097596539  Training Accuracy:  0.8952  Test Accuracy:  0.891\n",
      "epoch  2 : Training loss:  0.0826910772784  Training Accuracy:  0.8959  Test Accuracy:  0.8876\n",
      "epoch  2 : Training loss:  0.0820341884941  Training Accuracy:  0.8961  Test Accuracy:  0.8924\n",
      "epoch  3 : Training loss:  0.000108936039233  Training Accuracy:  0.8969  Test Accuracy:  0.8913\n",
      "epoch  3 : Training loss:  0.0795533012888  Training Accuracy:  0.8973  Test Accuracy:  0.8911\n",
      "epoch  3 : Training loss:  0.0742438442571  Training Accuracy:  0.8977  Test Accuracy:  0.8941\n",
      "epoch  3 : Training loss:  0.0762970805116  Training Accuracy:  0.9012  Test Accuracy:  0.8939\n",
      "epoch  3 : Training loss:  0.0792505463868  Training Accuracy:  0.9022  Test Accuracy:  0.8952\n",
      "epoch  3 : Training loss:  0.0757832521515  Training Accuracy:  0.8978  Test Accuracy:  0.8911\n",
      "epoch  3 : Training loss:  0.08153200008  Training Accuracy:  0.8995  Test Accuracy:  0.8952\n",
      "epoch  3 : Training loss:  0.0763249663396  Training Accuracy:  0.9004  Test Accuracy:  0.8928\n",
      "epoch  3 : Training loss:  0.0766452922083  Training Accuracy:  0.901  Test Accuracy:  0.8942\n",
      "epoch  3 : Training loss:  0.0853015772598  Training Accuracy:  0.8989  Test Accuracy:  0.8928\n",
      "epoch  4 : Training loss:  3.62371424367e-05  Training Accuracy:  0.9015  Test Accuracy:  0.8955\n",
      "epoch  4 : Training loss:  0.0775004174853  Training Accuracy:  0.9017  Test Accuracy:  0.8956\n",
      "epoch  4 : Training loss:  0.0805306420454  Training Accuracy:  0.8997  Test Accuracy:  0.8959\n",
      "epoch  4 : Training loss:  0.0737336868692  Training Accuracy:  0.9005  Test Accuracy:  0.8959\n",
      "epoch  4 : Training loss:  0.0739192356815  Training Accuracy:  0.9022  Test Accuracy:  0.8952\n",
      "epoch  4 : Training loss:  0.07542006641  Training Accuracy:  0.9015  Test Accuracy:  0.8925\n",
      "epoch  4 : Training loss:  0.0755597712849  Training Accuracy:  0.902  Test Accuracy:  0.8925\n",
      "epoch  4 : Training loss:  0.072769780963  Training Accuracy:  0.9024  Test Accuracy:  0.8959\n",
      "epoch  4 : Training loss:  0.0788517463916  Training Accuracy:  0.9033  Test Accuracy:  0.8951\n",
      "epoch  4 : Training loss:  0.0683911194557  Training Accuracy:  0.9037  Test Accuracy:  0.897\n",
      "epoch  5 : Training loss:  9.190292628e-05  Training Accuracy:  0.9031  Test Accuracy:  0.897\n",
      "epoch  5 : Training loss:  0.075873698197  Training Accuracy:  0.9047  Test Accuracy:  0.895\n",
      "epoch  5 : Training loss:  0.0778395243159  Training Accuracy:  0.9058  Test Accuracy:  0.8958\n",
      "epoch  5 : Training loss:  0.0754883790765  Training Accuracy:  0.9035  Test Accuracy:  0.8978\n",
      "epoch  5 : Training loss:  0.074617453448  Training Accuracy:  0.9056  Test Accuracy:  0.8969\n",
      "epoch  5 : Training loss:  0.0734119081727  Training Accuracy:  0.9043  Test Accuracy:  0.8956\n",
      "epoch  5 : Training loss:  0.0719324185324  Training Accuracy:  0.9044  Test Accuracy:  0.8969\n",
      "epoch  5 : Training loss:  0.0685584822483  Training Accuracy:  0.906  Test Accuracy:  0.8976\n",
      "epoch  5 : Training loss:  0.0706259728706  Training Accuracy:  0.9049  Test Accuracy:  0.8994\n",
      "epoch  5 : Training loss:  0.0788278784171  Training Accuracy:  0.9067  Test Accuracy:  0.8984\n",
      "epoch  6 : Training loss:  2.60558998317e-05  Training Accuracy:  0.9037  Test Accuracy:  0.8965\n",
      "epoch  6 : Training loss:  0.0741865877068  Training Accuracy:  0.902  Test Accuracy:  0.8947\n",
      "epoch  6 : Training loss:  0.0737795147274  Training Accuracy:  0.9049  Test Accuracy:  0.8967\n",
      "epoch  6 : Training loss:  0.0676961123502  Training Accuracy:  0.9031  Test Accuracy:  0.896\n",
      "epoch  6 : Training loss:  0.0699761442868  Training Accuracy:  0.9075  Test Accuracy:  0.8979\n",
      "epoch  6 : Training loss:  0.0718630871712  Training Accuracy:  0.9044  Test Accuracy:  0.8939\n",
      "epoch  6 : Training loss:  0.0726542177146  Training Accuracy:  0.9074  Test Accuracy:  0.899\n",
      "epoch  6 : Training loss:  0.0782501724035  Training Accuracy:  0.9059  Test Accuracy:  0.8991\n",
      "epoch  6 : Training loss:  0.0769496456567  Training Accuracy:  0.9084  Test Accuracy:  0.9002\n",
      "epoch  6 : Training loss:  0.0654194855935  Training Accuracy:  0.9073  Test Accuracy:  0.8997\n",
      "epoch  7 : Training loss:  6.60892900405e-05  Training Accuracy:  0.9089  Test Accuracy:  0.8973\n",
      "epoch  7 : Training loss:  0.0702674037935  Training Accuracy:  0.9054  Test Accuracy:  0.8978\n",
      "epoch  7 : Training loss:  0.0690472449124  Training Accuracy:  0.9027  Test Accuracy:  0.8962\n",
      "epoch  7 : Training loss:  0.0647484042108  Training Accuracy:  0.9061  Test Accuracy:  0.898\n",
      "epoch  7 : Training loss:  0.0730248189749  Training Accuracy:  0.9082  Test Accuracy:  0.8983\n",
      "epoch  7 : Training loss:  0.0736705040041  Training Accuracy:  0.9092  Test Accuracy:  0.8977\n",
      "epoch  7 : Training loss:  0.0690609270411  Training Accuracy:  0.9079  Test Accuracy:  0.895\n",
      "epoch  7 : Training loss:  0.0693941905558  Training Accuracy:  0.9089  Test Accuracy:  0.9001\n",
      "epoch  7 : Training loss:  0.0721721549195  Training Accuracy:  0.9063  Test Accuracy:  0.8982\n",
      "epoch  7 : Training loss:  0.0741330951432  Training Accuracy:  0.9093  Test Accuracy:  0.8997\n",
      "epoch  8 : Training loss:  6.25244714914e-05  Training Accuracy:  0.9082  Test Accuracy:  0.8974\n",
      "epoch  8 : Training loss:  0.0689105362194  Training Accuracy:  0.9079  Test Accuracy:  0.898\n",
      "epoch  8 : Training loss:  0.0713894857609  Training Accuracy:  0.9064  Test Accuracy:  0.897\n",
      "epoch  8 : Training loss:  0.0671888607549  Training Accuracy:  0.9088  Test Accuracy:  0.8995\n",
      "epoch  8 : Training loss:  0.0700282422585  Training Accuracy:  0.9095  Test Accuracy:  0.8998\n",
      "epoch  8 : Training loss:  0.0707693360205  Training Accuracy:  0.9092  Test Accuracy:  0.8998\n",
      "epoch  8 : Training loss:  0.0686475087316  Training Accuracy:  0.9114  Test Accuracy:  0.9005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  8 : Training loss:  0.0713971344717  Training Accuracy:  0.9087  Test Accuracy:  0.8997\n",
      "epoch  8 : Training loss:  0.0764929468725  Training Accuracy:  0.9087  Test Accuracy:  0.9012\n",
      "epoch  8 : Training loss:  0.0698339986552  Training Accuracy:  0.9104  Test Accuracy:  0.898\n",
      "epoch  9 : Training loss:  3.45380236729e-05  Training Accuracy:  0.91  Test Accuracy:  0.8977\n",
      "epoch  9 : Training loss:  0.0670095837789  Training Accuracy:  0.9101  Test Accuracy:  0.8991\n",
      "epoch  9 : Training loss:  0.0709214446146  Training Accuracy:  0.9077  Test Accuracy:  0.8972\n",
      "epoch  9 : Training loss:  0.0695000295051  Training Accuracy:  0.9087  Test Accuracy:  0.898\n",
      "epoch  9 : Training loss:  0.0656566672541  Training Accuracy:  0.908  Test Accuracy:  0.8991\n",
      "epoch  9 : Training loss:  0.0667954892589  Training Accuracy:  0.909  Test Accuracy:  0.9021\n",
      "epoch  9 : Training loss:  0.0659153168668  Training Accuracy:  0.9096  Test Accuracy:  0.8955\n",
      "epoch  9 : Training loss:  0.0661126595656  Training Accuracy:  0.9078  Test Accuracy:  0.8963\n",
      "epoch  9 : Training loss:  0.0834431456354  Training Accuracy:  0.9102  Test Accuracy:  0.8989\n",
      "epoch  9 : Training loss:  0.0669278664279  Training Accuracy:  0.9114  Test Accuracy:  0.9005\n",
      "epoch  10 : Training loss:  5.91407546933e-05  Training Accuracy:  0.9094  Test Accuracy:  0.8997\n",
      "epoch  10 : Training loss:  0.0667655266709  Training Accuracy:  0.9124  Test Accuracy:  0.8989\n",
      "epoch  10 : Training loss:  0.0704272756829  Training Accuracy:  0.9107  Test Accuracy:  0.902\n",
      "epoch  10 : Training loss:  0.0695535360827  Training Accuracy:  0.9122  Test Accuracy:  0.9014\n",
      "epoch  10 : Training loss:  0.0671670190137  Training Accuracy:  0.911  Test Accuracy:  0.9006\n",
      "epoch  10 : Training loss:  0.0727355051119  Training Accuracy:  0.9112  Test Accuracy:  0.9003\n",
      "epoch  10 : Training loss:  0.0685931219663  Training Accuracy:  0.9106  Test Accuracy:  0.9003\n",
      "epoch  10 : Training loss:  0.063427765315  Training Accuracy:  0.9133  Test Accuracy:  0.8992\n",
      "epoch  10 : Training loss:  0.0663147260499  Training Accuracy:  0.9079  Test Accuracy:  0.9008\n",
      "epoch  10 : Training loss:  0.0682093154187  Training Accuracy:  0.9105  Test Accuracy:  0.8983\n",
      "epoch  11 : Training loss:  0.000181016798598  Training Accuracy:  0.9123  Test Accuracy:  0.9\n",
      "epoch  11 : Training loss:  0.0691358669765  Training Accuracy:  0.911  Test Accuracy:  0.8986\n",
      "epoch  11 : Training loss:  0.0728656506814  Training Accuracy:  0.9113  Test Accuracy:  0.8972\n",
      "epoch  11 : Training loss:  0.0680964593838  Training Accuracy:  0.91  Test Accuracy:  0.8974\n",
      "epoch  11 : Training loss:  0.0711163162686  Training Accuracy:  0.9118  Test Accuracy:  0.9019\n",
      "epoch  11 : Training loss:  0.0710034728746  Training Accuracy:  0.9131  Test Accuracy:  0.8995\n",
      "epoch  11 : Training loss:  0.0629747570755  Training Accuracy:  0.9095  Test Accuracy:  0.8974\n",
      "epoch  11 : Training loss:  0.0638257493231  Training Accuracy:  0.9135  Test Accuracy:  0.9003\n",
      "epoch  11 : Training loss:  0.0689700267187  Training Accuracy:  0.9116  Test Accuracy:  0.8984\n",
      "epoch  11 : Training loss:  0.0673878080705  Training Accuracy:  0.9107  Test Accuracy:  0.9002\n",
      "epoch  12 : Training loss:  3.05442124224e-05  Training Accuracy:  0.9102  Test Accuracy:  0.8987\n",
      "epoch  12 : Training loss:  0.0633639808779  Training Accuracy:  0.9116  Test Accuracy:  0.8997\n",
      "epoch  12 : Training loss:  0.0611350153094  Training Accuracy:  0.9098  Test Accuracy:  0.9003\n",
      "epoch  12 : Training loss:  0.0638704660826  Training Accuracy:  0.9117  Test Accuracy:  0.8992\n",
      "epoch  12 : Training loss:  0.0634377044353  Training Accuracy:  0.912  Test Accuracy:  0.8978\n",
      "epoch  12 : Training loss:  0.0692242472332  Training Accuracy:  0.9121  Test Accuracy:  0.8984\n",
      "epoch  12 : Training loss:  0.0656064234123  Training Accuracy:  0.9137  Test Accuracy:  0.8982\n",
      "epoch  12 : Training loss:  0.0712570025661  Training Accuracy:  0.912  Test Accuracy:  0.9004\n",
      "epoch  12 : Training loss:  0.0700164766244  Training Accuracy:  0.9129  Test Accuracy:  0.9012\n",
      "epoch  12 : Training loss:  0.0706682067238  Training Accuracy:  0.9123  Test Accuracy:  0.9001\n",
      "epoch  13 : Training loss:  9.03449447869e-05  Training Accuracy:  0.9114  Test Accuracy:  0.8998\n",
      "epoch  13 : Training loss:  0.0695964681077  Training Accuracy:  0.9132  Test Accuracy:  0.8993\n",
      "epoch  13 : Training loss:  0.0671975985589  Training Accuracy:  0.9115  Test Accuracy:  0.8989\n",
      "epoch  13 : Training loss:  0.0710384175109  Training Accuracy:  0.9097  Test Accuracy:  0.8985\n",
      "epoch  13 : Training loss:  0.0709793903983  Training Accuracy:  0.9107  Test Accuracy:  0.896\n",
      "epoch  13 : Training loss:  0.0657651792394  Training Accuracy:  0.9116  Test Accuracy:  0.8943\n",
      "epoch  13 : Training loss:  0.0687761184536  Training Accuracy:  0.912  Test Accuracy:  0.8995\n",
      "epoch  13 : Training loss:  0.0580191653592  Training Accuracy:  0.9114  Test Accuracy:  0.8981\n",
      "epoch  13 : Training loss:  0.0690533192533  Training Accuracy:  0.913  Test Accuracy:  0.8964\n",
      "epoch  13 : Training loss:  0.0619183398439  Training Accuracy:  0.9143  Test Accuracy:  0.9013\n",
      "epoch  14 : Training loss:  4.46231178933e-05  Training Accuracy:  0.9138  Test Accuracy:  0.9016\n",
      "epoch  14 : Training loss:  0.0684222690874  Training Accuracy:  0.9157  Test Accuracy:  0.9039\n",
      "epoch  14 : Training loss:  0.065080944178  Training Accuracy:  0.9161  Test Accuracy:  0.9004\n",
      "epoch  14 : Training loss:  0.068324834271  Training Accuracy:  0.9135  Test Accuracy:  0.9\n",
      "epoch  14 : Training loss:  0.0622911061139  Training Accuracy:  0.9108  Test Accuracy:  0.8981\n",
      "epoch  14 : Training loss:  0.0650832290059  Training Accuracy:  0.9151  Test Accuracy:  0.8997\n",
      "epoch  14 : Training loss:  0.0664037207094  Training Accuracy:  0.9138  Test Accuracy:  0.8977\n",
      "epoch  14 : Training loss:  0.0721360193695  Training Accuracy:  0.9125  Test Accuracy:  0.8978\n",
      "epoch  14 : Training loss:  0.068716703965  Training Accuracy:  0.9146  Test Accuracy:  0.9002\n",
      "epoch  14 : Training loss:  0.0588255011522  Training Accuracy:  0.9154  Test Accuracy:  0.8997\n",
      "epoch  15 : Training loss:  5.90708554488e-05  Training Accuracy:  0.9133  Test Accuracy:  0.8992\n",
      "epoch  15 : Training loss:  0.0631748585651  Training Accuracy:  0.9129  Test Accuracy:  0.8969\n",
      "epoch  15 : Training loss:  0.065263498821  Training Accuracy:  0.9136  Test Accuracy:  0.9012\n",
      "epoch  15 : Training loss:  0.0670283253567  Training Accuracy:  0.9153  Test Accuracy:  0.8996\n",
      "epoch  15 : Training loss:  0.062492147448  Training Accuracy:  0.9129  Test Accuracy:  0.9007\n",
      "epoch  15 : Training loss:  0.070976064502  Training Accuracy:  0.9134  Test Accuracy:  0.8999\n",
      "epoch  15 : Training loss:  0.0669208680657  Training Accuracy:  0.9156  Test Accuracy:  0.8999\n",
      "epoch  15 : Training loss:  0.0648764020841  Training Accuracy:  0.9147  Test Accuracy:  0.9013\n",
      "epoch  15 : Training loss:  0.0718782129175  Training Accuracy:  0.9164  Test Accuracy:  0.8999\n",
      "epoch  15 : Training loss:  0.06137050316  Training Accuracy:  0.9151  Test Accuracy:  0.8984\n",
      "epoch  16 : Training loss:  3.61564163323e-05  Training Accuracy:  0.9149  Test Accuracy:  0.9006\n",
      "epoch  16 : Training loss:  0.0577752877126  Training Accuracy:  0.9171  Test Accuracy:  0.9007\n",
      "epoch  16 : Training loss:  0.0672047471324  Training Accuracy:  0.9131  Test Accuracy:  0.902\n",
      "epoch  16 : Training loss:  0.06731300218  Training Accuracy:  0.9152  Test Accuracy:  0.9011\n",
      "epoch  16 : Training loss:  0.0636878996918  Training Accuracy:  0.915  Test Accuracy:  0.902\n",
      "epoch  16 : Training loss:  0.0725548671099  Training Accuracy:  0.9161  Test Accuracy:  0.9008\n",
      "epoch  16 : Training loss:  0.0633763436689  Training Accuracy:  0.9141  Test Accuracy:  0.8987\n",
      "epoch  16 : Training loss:  0.0608564526399  Training Accuracy:  0.9134  Test Accuracy:  0.8962\n",
      "epoch  16 : Training loss:  0.0686087992565  Training Accuracy:  0.9156  Test Accuracy:  0.9029\n",
      "epoch  16 : Training loss:  0.0662094605806  Training Accuracy:  0.9161  Test Accuracy:  0.8988\n",
      "epoch  17 : Training loss:  4.13702921801e-05  Training Accuracy:  0.9162  Test Accuracy:  0.9021\n",
      "epoch  17 : Training loss:  0.0572485238056  Training Accuracy:  0.9167  Test Accuracy:  0.9024\n",
      "epoch  17 : Training loss:  0.0697802536343  Training Accuracy:  0.9143  Test Accuracy:  0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  17 : Training loss:  0.0676124963563  Training Accuracy:  0.9139  Test Accuracy:  0.9007\n",
      "epoch  17 : Training loss:  0.0682703946265  Training Accuracy:  0.9139  Test Accuracy:  0.8991\n",
      "epoch  17 : Training loss:  0.0666034509474  Training Accuracy:  0.9184  Test Accuracy:  0.9014\n",
      "epoch  17 : Training loss:  0.0618684338611  Training Accuracy:  0.9155  Test Accuracy:  0.9024\n",
      "epoch  17 : Training loss:  0.0685200255973  Training Accuracy:  0.9147  Test Accuracy:  0.9003\n",
      "epoch  17 : Training loss:  0.0638279685842  Training Accuracy:  0.9166  Test Accuracy:  0.9012\n",
      "epoch  17 : Training loss:  0.0651358834104  Training Accuracy:  0.9167  Test Accuracy:  0.9003\n",
      "epoch  18 : Training loss:  0.00010201420607  Training Accuracy:  0.9137  Test Accuracy:  0.8971\n",
      "epoch  18 : Training loss:  0.0609833167695  Training Accuracy:  0.9142  Test Accuracy:  0.8977\n",
      "epoch  18 : Training loss:  0.0656769975467  Training Accuracy:  0.9181  Test Accuracy:  0.9036\n",
      "epoch  18 : Training loss:  0.0649817625712  Training Accuracy:  0.9152  Test Accuracy:  0.898\n",
      "epoch  18 : Training loss:  0.061678851988  Training Accuracy:  0.917  Test Accuracy:  0.8999\n",
      "epoch  18 : Training loss:  0.0613912857679  Training Accuracy:  0.9176  Test Accuracy:  0.9016\n",
      "epoch  18 : Training loss:  0.0673442568189  Training Accuracy:  0.9136  Test Accuracy:  0.8983\n",
      "epoch  18 : Training loss:  0.0641074897762  Training Accuracy:  0.9141  Test Accuracy:  0.897\n",
      "epoch  18 : Training loss:  0.0621071566199  Training Accuracy:  0.9137  Test Accuracy:  0.8985\n",
      "epoch  18 : Training loss:  0.0631585181637  Training Accuracy:  0.913  Test Accuracy:  0.8967\n",
      "epoch  19 : Training loss:  5.26979725865e-05  Training Accuracy:  0.9158  Test Accuracy:  0.8997\n",
      "epoch  19 : Training loss:  0.065934436775  Training Accuracy:  0.915  Test Accuracy:  0.8997\n",
      "epoch  19 : Training loss:  0.0675353859087  Training Accuracy:  0.9156  Test Accuracy:  0.8987\n",
      "epoch  19 : Training loss:  0.0669396117959  Training Accuracy:  0.9156  Test Accuracy:  0.9036\n",
      "epoch  19 : Training loss:  0.0640539798148  Training Accuracy:  0.9161  Test Accuracy:  0.8985\n",
      "epoch  19 : Training loss:  0.0603133143359  Training Accuracy:  0.9156  Test Accuracy:  0.9025\n",
      "epoch  19 : Training loss:  0.0663938221194  Training Accuracy:  0.9169  Test Accuracy:  0.9033\n",
      "epoch  19 : Training loss:  0.0650316279624  Training Accuracy:  0.9188  Test Accuracy:  0.9014\n",
      "epoch  19 : Training loss:  0.0652994780466  Training Accuracy:  0.9157  Test Accuracy:  0.9004\n",
      "epoch  19 : Training loss:  0.0604390641597  Training Accuracy:  0.9142  Test Accuracy:  0.9012\n",
      "test accuracy  0.9016  training loss:  [-23.47699426 -34.93119983 -84.09851876 -77.69282751 -48.51815516\n",
      " -73.77481509 -35.3354525  -45.78996183 -99.95898808 -74.67644106]\n"
     ]
    }
   ],
   "source": [
    "gd_weights, train_loss = train_sgd(train_data_type2[:10000], epochs, learning_rate, lamda, test_data_type2)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data_type2, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.753976337734  Training Accuracy:  0.1569  Test Accuracy:  0.1528\n",
      "epoch  1 : Training loss:  1.30043553619  Training Accuracy:  0.259  Test Accuracy:  0.2519\n",
      "epoch  2 : Training loss:  0.842865492892  Training Accuracy:  0.3262  Test Accuracy:  0.3216\n",
      "epoch  3 : Training loss:  0.516366197759  Training Accuracy:  0.6354  Test Accuracy:  0.6302\n",
      "epoch  4 : Training loss:  0.293630856218  Training Accuracy:  0.7185  Test Accuracy:  0.709\n",
      "epoch  5 : Training loss:  0.209186401167  Training Accuracy:  0.6899  Test Accuracy:  0.6772\n",
      "epoch  6 : Training loss:  0.21409761761  Training Accuracy:  0.8011  Test Accuracy:  0.7843\n",
      "epoch  7 : Training loss:  0.16890063753  Training Accuracy:  0.7741  Test Accuracy:  0.7664\n",
      "epoch  8 : Training loss:  0.175099671427  Training Accuracy:  0.8188  Test Accuracy:  0.8099\n",
      "epoch  9 : Training loss:  0.16426043788  Training Accuracy:  0.7841  Test Accuracy:  0.7715\n",
      "epoch  10 : Training loss:  0.176186799596  Training Accuracy:  0.826  Test Accuracy:  0.82\n",
      "epoch  11 : Training loss:  0.160834171222  Training Accuracy:  0.7856  Test Accuracy:  0.7741\n",
      "epoch  12 : Training loss:  0.175434145254  Training Accuracy:  0.8387  Test Accuracy:  0.8339\n",
      "epoch  13 : Training loss:  0.152258401434  Training Accuracy:  0.8178  Test Accuracy:  0.8101\n",
      "epoch  14 : Training loss:  0.158384974131  Training Accuracy:  0.8417  Test Accuracy:  0.8357\n",
      "epoch  15 : Training loss:  0.151227267559  Training Accuracy:  0.8172  Test Accuracy:  0.8082\n",
      "epoch  16 : Training loss:  0.160100468854  Training Accuracy:  0.8483  Test Accuracy:  0.8445\n",
      "epoch  17 : Training loss:  0.146991235924  Training Accuracy:  0.8354  Test Accuracy:  0.8252\n",
      "epoch  18 : Training loss:  0.152323079784  Training Accuracy:  0.8517  Test Accuracy:  0.8485\n",
      "epoch  19 : Training loss:  0.145067116663  Training Accuracy:  0.8427  Test Accuracy:  0.8334\n",
      "epoch  20 : Training loss:  0.149665938747  Training Accuracy:  0.8572  Test Accuracy:  0.8523\n",
      "epoch  21 : Training loss:  0.142882718615  Training Accuracy:  0.8537  Test Accuracy:  0.8438\n",
      "epoch  22 : Training loss:  0.146173541623  Training Accuracy:  0.8618  Test Accuracy:  0.8548\n",
      "epoch  23 : Training loss:  0.141039381539  Training Accuracy:  0.8608  Test Accuracy:  0.8503\n",
      "epoch  24 : Training loss:  0.143365260858  Training Accuracy:  0.8654  Test Accuracy:  0.858\n",
      "epoch  25 : Training loss:  0.139439434988  Training Accuracy:  0.8644  Test Accuracy:  0.8562\n",
      "epoch  26 : Training loss:  0.141030128712  Training Accuracy:  0.8675  Test Accuracy:  0.8612\n",
      "epoch  27 : Training loss:  0.138060045085  Training Accuracy:  0.8705  Test Accuracy:  0.8615\n",
      "epoch  28 : Training loss:  0.139106095948  Training Accuracy:  0.8703  Test Accuracy:  0.8642\n",
      "epoch  29 : Training loss:  0.136882179524  Training Accuracy:  0.8734  Test Accuracy:  0.8658\n",
      "epoch  30 : Training loss:  0.137537393612  Training Accuracy:  0.8737  Test Accuracy:  0.867\n",
      "epoch  31 : Training loss:  0.135888954662  Training Accuracy:  0.8766  Test Accuracy:  0.8696\n",
      "epoch  32 : Training loss:  0.136274441417  Training Accuracy:  0.8771  Test Accuracy:  0.8692\n",
      "epoch  33 : Training loss:  0.13506495643  Training Accuracy:  0.8799  Test Accuracy:  0.8721\n",
      "epoch  34 : Training loss:  0.135272876362  Training Accuracy:  0.8799  Test Accuracy:  0.8709\n",
      "epoch  35 : Training loss:  0.134394959341  Training Accuracy:  0.8841  Test Accuracy:  0.8749\n",
      "epoch  36 : Training loss:  0.134492395392  Training Accuracy:  0.8815  Test Accuracy:  0.873\n",
      "epoch  37 : Training loss:  0.133862891257  Training Accuracy:  0.8863  Test Accuracy:  0.877\n",
      "epoch  38 : Training loss:  0.133896283928  Training Accuracy:  0.8834  Test Accuracy:  0.8758\n",
      "epoch  39 : Training loss:  0.13345172443  Training Accuracy:  0.8874  Test Accuracy:  0.8786\n",
      "epoch  40 : Training loss:  0.133451635672  Training Accuracy:  0.8854  Test Accuracy:  0.8771\n",
      "epoch  41 : Training loss:  0.13314420043  Training Accuracy:  0.8887  Test Accuracy:  0.8799\n",
      "epoch  42 : Training loss:  0.133129840934  Training Accuracy:  0.8876  Test Accuracy:  0.879\n",
      "epoch  43 : Training loss:  0.132923902075  Training Accuracy:  0.8897  Test Accuracy:  0.8811\n",
      "epoch  44 : Training loss:  0.132906925856  Training Accuracy:  0.8885  Test Accuracy:  0.8806\n",
      "epoch  45 : Training loss:  0.132776190372  Training Accuracy:  0.8901  Test Accuracy:  0.8825\n",
      "epoch  46 : Training loss:  0.132763511842  Training Accuracy:  0.8893  Test Accuracy:  0.882\n",
      "epoch  47 : Training loss:  0.132688721468  Training Accuracy:  0.8902  Test Accuracy:  0.8832\n",
      "epoch  48 : Training loss:  0.132684377426  Training Accuracy:  0.891  Test Accuracy:  0.8832\n",
      "epoch  49 : Training loss:  0.132651497151  Training Accuracy:  0.8906  Test Accuracy:  0.8848\n",
      "epoch  50 : Training loss:  0.132657757716  Training Accuracy:  0.8911  Test Accuracy:  0.8841\n",
      "epoch  51 : Training loss:  0.132656578352  Training Accuracy:  0.8914  Test Accuracy:  0.8866\n",
      "epoch  52 : Training loss:  0.132674568791  Training Accuracy:  0.8921  Test Accuracy:  0.8856\n",
      "epoch  53 : Training loss:  0.132697653084  Training Accuracy:  0.8922  Test Accuracy:  0.8867\n",
      "epoch  54 : Training loss:  0.13272770876  Training Accuracy:  0.8927  Test Accuracy:  0.8856\n",
      "epoch  55 : Training loss:  0.132769615118  Training Accuracy:  0.8929  Test Accuracy:  0.8871\n",
      "epoch  56 : Training loss:  0.132811512025  Training Accuracy:  0.8936  Test Accuracy:  0.8863\n",
      "epoch  57 : Training loss:  0.132868234324  Training Accuracy:  0.894  Test Accuracy:  0.8878\n",
      "epoch  58 : Training loss:  0.132921365158  Training Accuracy:  0.894  Test Accuracy:  0.8873\n",
      "epoch  59 : Training loss:  0.132989933683  Training Accuracy:  0.8944  Test Accuracy:  0.8885\n",
      "epoch  60 : Training loss:  0.133053453741  Training Accuracy:  0.8946  Test Accuracy:  0.8881\n",
      "epoch  61 : Training loss:  0.133131651796  Training Accuracy:  0.8951  Test Accuracy:  0.8891\n",
      "epoch  62 : Training loss:  0.133204598447  Training Accuracy:  0.8954  Test Accuracy:  0.8887\n",
      "epoch  63 : Training loss:  0.133290759961  Training Accuracy:  0.8953  Test Accuracy:  0.8897\n",
      "epoch  64 : Training loss:  0.13337214424  Training Accuracy:  0.8961  Test Accuracy:  0.8894\n",
      "epoch  65 : Training loss:  0.133465007647  Training Accuracy:  0.8962  Test Accuracy:  0.8905\n",
      "epoch  66 : Training loss:  0.133553878002  Training Accuracy:  0.8971  Test Accuracy:  0.8901\n",
      "epoch  67 : Training loss:  0.133652479539  Training Accuracy:  0.8976  Test Accuracy:  0.8908\n",
      "epoch  68 : Training loss:  0.133747960601  Training Accuracy:  0.8977  Test Accuracy:  0.8907\n",
      "epoch  69 : Training loss:  0.133851555679  Training Accuracy:  0.898  Test Accuracy:  0.8914\n",
      "epoch  70 : Training loss:  0.133952866966  Training Accuracy:  0.8981  Test Accuracy:  0.8911\n",
      "epoch  71 : Training loss:  0.13406087196  Training Accuracy:  0.899  Test Accuracy:  0.8921\n",
      "epoch  72 : Training loss:  0.134167332158  Training Accuracy:  0.8992  Test Accuracy:  0.8921\n",
      "epoch  73 : Training loss:  0.134279281302  Training Accuracy:  0.8995  Test Accuracy:  0.8925\n",
      "epoch  74 : Training loss:  0.13439030337  Training Accuracy:  0.8997  Test Accuracy:  0.8926\n",
      "epoch  75 : Training loss:  0.134505816991  Training Accuracy:  0.8999  Test Accuracy:  0.8928\n",
      "epoch  76 : Training loss:  0.134620898364  Training Accuracy:  0.9003  Test Accuracy:  0.8929\n",
      "epoch  77 : Training loss:  0.134739659681  Training Accuracy:  0.901  Test Accuracy:  0.8931\n",
      "epoch  78 : Training loss:  0.134858370629  Training Accuracy:  0.901  Test Accuracy:  0.8931\n",
      "epoch  79 : Training loss:  0.134980109017  Training Accuracy:  0.901  Test Accuracy:  0.8934\n",
      "epoch  80 : Training loss:  0.13510208108  Training Accuracy:  0.9011  Test Accuracy:  0.8936\n",
      "epoch  81 : Training loss:  0.135226560205  Training Accuracy:  0.9016  Test Accuracy:  0.8939\n",
      "epoch  82 : Training loss:  0.135351475752  Training Accuracy:  0.902  Test Accuracy:  0.8941\n",
      "epoch  83 : Training loss:  0.135478485286  Training Accuracy:  0.9022  Test Accuracy:  0.8943\n",
      "epoch  84 : Training loss:  0.135606068608  Training Accuracy:  0.9024  Test Accuracy:  0.8943\n",
      "epoch  85 : Training loss:  0.135735418546  Training Accuracy:  0.9027  Test Accuracy:  0.8944\n",
      "epoch  86 : Training loss:  0.13586542852  Training Accuracy:  0.9029  Test Accuracy:  0.8946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  87 : Training loss:  0.135996945328  Training Accuracy:  0.9029  Test Accuracy:  0.8949\n",
      "epoch  88 : Training loss:  0.136129169504  Training Accuracy:  0.9031  Test Accuracy:  0.8952\n",
      "epoch  89 : Training loss:  0.13626269351  Training Accuracy:  0.9031  Test Accuracy:  0.8953\n",
      "epoch  90 : Training loss:  0.13639694338  Training Accuracy:  0.9034  Test Accuracy:  0.8953\n",
      "epoch  91 : Training loss:  0.136532326994  Training Accuracy:  0.9036  Test Accuracy:  0.8954\n",
      "epoch  92 : Training loss:  0.136668434223  Training Accuracy:  0.9038  Test Accuracy:  0.8953\n",
      "epoch  93 : Training loss:  0.136805540675  Training Accuracy:  0.9039  Test Accuracy:  0.8954\n",
      "epoch  94 : Training loss:  0.136943354081  Training Accuracy:  0.9037  Test Accuracy:  0.8958\n",
      "epoch  95 : Training loss:  0.137082056469  Training Accuracy:  0.9043  Test Accuracy:  0.896\n",
      "epoch  96 : Training loss:  0.137221439589  Training Accuracy:  0.9043  Test Accuracy:  0.8961\n",
      "epoch  97 : Training loss:  0.137361620128  Training Accuracy:  0.9046  Test Accuracy:  0.8961\n",
      "epoch  98 : Training loss:  0.137502449231  Training Accuracy:  0.9048  Test Accuracy:  0.8963\n",
      "epoch  99 : Training loss:  0.1376439986  Training Accuracy:  0.9047  Test Accuracy:  0.8966\n",
      "epoch  100 : Training loss:  0.137786161064  Training Accuracy:  0.905  Test Accuracy:  0.8969\n",
      "epoch  101 : Training loss:  0.137928977819  Training Accuracy:  0.9051  Test Accuracy:  0.897\n",
      "epoch  102 : Training loss:  0.13807237078  Training Accuracy:  0.9052  Test Accuracy:  0.8973\n",
      "epoch  103 : Training loss:  0.138216360806  Training Accuracy:  0.9055  Test Accuracy:  0.8973\n",
      "epoch  104 : Training loss:  0.138360890026  Training Accuracy:  0.9055  Test Accuracy:  0.8975\n",
      "epoch  105 : Training loss:  0.138505966016  Training Accuracy:  0.9055  Test Accuracy:  0.8979\n",
      "epoch  106 : Training loss:  0.138651544934  Training Accuracy:  0.9057  Test Accuracy:  0.898\n",
      "epoch  107 : Training loss:  0.138797625899  Training Accuracy:  0.906  Test Accuracy:  0.8981\n",
      "epoch  108 : Training loss:  0.138944174819  Training Accuracy:  0.9062  Test Accuracy:  0.8979\n",
      "epoch  109 : Training loss:  0.139091185615  Training Accuracy:  0.9063  Test Accuracy:  0.8978\n",
      "epoch  110 : Training loss:  0.139238631014  Training Accuracy:  0.9065  Test Accuracy:  0.8978\n",
      "epoch  111 : Training loss:  0.139386501903  Training Accuracy:  0.9066  Test Accuracy:  0.8979\n",
      "epoch  112 : Training loss:  0.139534775826  Training Accuracy:  0.9066  Test Accuracy:  0.8979\n",
      "epoch  113 : Training loss:  0.139683442058  Training Accuracy:  0.9068  Test Accuracy:  0.8983\n",
      "epoch  114 : Training loss:  0.139832481603  Training Accuracy:  0.9071  Test Accuracy:  0.8985\n",
      "epoch  115 : Training loss:  0.13998188303  Training Accuracy:  0.9073  Test Accuracy:  0.8988\n",
      "epoch  116 : Training loss:  0.140131629884  Training Accuracy:  0.9076  Test Accuracy:  0.899\n",
      "epoch  117 : Training loss:  0.140281710601  Training Accuracy:  0.908  Test Accuracy:  0.899\n",
      "epoch  118 : Training loss:  0.140432110642  Training Accuracy:  0.9081  Test Accuracy:  0.8992\n",
      "epoch  119 : Training loss:  0.140582818652  Training Accuracy:  0.9081  Test Accuracy:  0.8992\n",
      "epoch  120 : Training loss:  0.140733821588  Training Accuracy:  0.9084  Test Accuracy:  0.8992\n",
      "epoch  121 : Training loss:  0.1408851085  Training Accuracy:  0.9085  Test Accuracy:  0.8994\n",
      "epoch  122 : Training loss:  0.141036667546  Training Accuracy:  0.9085  Test Accuracy:  0.8994\n",
      "epoch  123 : Training loss:  0.141188488292  Training Accuracy:  0.9084  Test Accuracy:  0.8991\n",
      "epoch  124 : Training loss:  0.141340559889  Training Accuracy:  0.9083  Test Accuracy:  0.8992\n",
      "epoch  125 : Training loss:  0.141492872466  Training Accuracy:  0.9082  Test Accuracy:  0.8994\n",
      "epoch  126 : Training loss:  0.141645416022  Training Accuracy:  0.9085  Test Accuracy:  0.8993\n",
      "epoch  127 : Training loss:  0.141798181257  Training Accuracy:  0.9085  Test Accuracy:  0.8995\n",
      "epoch  128 : Training loss:  0.14195115891  Training Accuracy:  0.9085  Test Accuracy:  0.8996\n",
      "epoch  129 : Training loss:  0.142104340245  Training Accuracy:  0.9087  Test Accuracy:  0.8998\n",
      "epoch  130 : Training loss:  0.142257716656  Training Accuracy:  0.9087  Test Accuracy:  0.8996\n",
      "epoch  131 : Training loss:  0.142411279949  Training Accuracy:  0.9088  Test Accuracy:  0.8997\n",
      "epoch  132 : Training loss:  0.142565022108  Training Accuracy:  0.9087  Test Accuracy:  0.8997\n",
      "epoch  133 : Training loss:  0.142718935453  Training Accuracy:  0.9087  Test Accuracy:  0.8997\n",
      "epoch  134 : Training loss:  0.142873012504  Training Accuracy:  0.9088  Test Accuracy:  0.8997\n",
      "epoch  135 : Training loss:  0.143027246066  Training Accuracy:  0.9092  Test Accuracy:  0.8998\n",
      "epoch  136 : Training loss:  0.143181629149  Training Accuracy:  0.9093  Test Accuracy:  0.8998\n",
      "epoch  137 : Training loss:  0.143336155012  Training Accuracy:  0.9094  Test Accuracy:  0.8996\n",
      "epoch  138 : Training loss:  0.143490817115  Training Accuracy:  0.9095  Test Accuracy:  0.8996\n",
      "epoch  139 : Training loss:  0.143645609144  Training Accuracy:  0.9094  Test Accuracy:  0.8998\n",
      "epoch  140 : Training loss:  0.143800524973  Training Accuracy:  0.9097  Test Accuracy:  0.9\n",
      "epoch  141 : Training loss:  0.143955558683  Training Accuracy:  0.91  Test Accuracy:  0.9001\n",
      "epoch  142 : Training loss:  0.144110704537  Training Accuracy:  0.9102  Test Accuracy:  0.9004\n",
      "epoch  143 : Training loss:  0.144265956983  Training Accuracy:  0.9102  Test Accuracy:  0.9005\n",
      "epoch  144 : Training loss:  0.14442131064  Training Accuracy:  0.9103  Test Accuracy:  0.9005\n",
      "epoch  145 : Training loss:  0.144576760302  Training Accuracy:  0.9104  Test Accuracy:  0.9005\n",
      "epoch  146 : Training loss:  0.144732300922  Training Accuracy:  0.9104  Test Accuracy:  0.9007\n",
      "epoch  147 : Training loss:  0.144887927611  Training Accuracy:  0.9105  Test Accuracy:  0.9006\n",
      "epoch  148 : Training loss:  0.145043635634  Training Accuracy:  0.9105  Test Accuracy:  0.9006\n",
      "epoch  149 : Training loss:  0.1451994204  Training Accuracy:  0.9106  Test Accuracy:  0.9006\n",
      "epoch  150 : Training loss:  0.145355277461  Training Accuracy:  0.9108  Test Accuracy:  0.9005\n",
      "epoch  151 : Training loss:  0.145511202507  Training Accuracy:  0.9109  Test Accuracy:  0.9007\n",
      "epoch  152 : Training loss:  0.145667191359  Training Accuracy:  0.9109  Test Accuracy:  0.9006\n",
      "epoch  153 : Training loss:  0.145823239966  Training Accuracy:  0.9111  Test Accuracy:  0.9005\n",
      "epoch  154 : Training loss:  0.145979344401  Training Accuracy:  0.9112  Test Accuracy:  0.9006\n",
      "epoch  155 : Training loss:  0.146135500855  Training Accuracy:  0.9113  Test Accuracy:  0.9006\n",
      "epoch  156 : Training loss:  0.146291705637  Training Accuracy:  0.9113  Test Accuracy:  0.9007\n",
      "epoch  157 : Training loss:  0.146447955164  Training Accuracy:  0.9113  Test Accuracy:  0.9007\n",
      "epoch  158 : Training loss:  0.146604245964  Training Accuracy:  0.9114  Test Accuracy:  0.9007\n",
      "epoch  159 : Training loss:  0.146760574667  Training Accuracy:  0.9117  Test Accuracy:  0.9008\n",
      "epoch  160 : Training loss:  0.146916938007  Training Accuracy:  0.9121  Test Accuracy:  0.901\n",
      "epoch  161 : Training loss:  0.147073332813  Training Accuracy:  0.9123  Test Accuracy:  0.9012\n",
      "epoch  162 : Training loss:  0.14722975601  Training Accuracy:  0.9124  Test Accuracy:  0.9012\n",
      "epoch  163 : Training loss:  0.147386204613  Training Accuracy:  0.9125  Test Accuracy:  0.9013\n",
      "epoch  164 : Training loss:  0.147542675726  Training Accuracy:  0.9126  Test Accuracy:  0.9013\n",
      "epoch  165 : Training loss:  0.147699166542  Training Accuracy:  0.9128  Test Accuracy:  0.9015\n",
      "epoch  166 : Training loss:  0.147855674331  Training Accuracy:  0.9128  Test Accuracy:  0.9019\n",
      "epoch  167 : Training loss:  0.14801219645  Training Accuracy:  0.9128  Test Accuracy:  0.9019\n",
      "epoch  168 : Training loss:  0.148168730328  Training Accuracy:  0.913  Test Accuracy:  0.9021\n",
      "epoch  169 : Training loss:  0.148325273473  Training Accuracy:  0.9131  Test Accuracy:  0.9022\n",
      "epoch  170 : Training loss:  0.148481823466  Training Accuracy:  0.9134  Test Accuracy:  0.9022\n",
      "epoch  171 : Training loss:  0.148638377958  Training Accuracy:  0.9134  Test Accuracy:  0.9022\n",
      "epoch  172 : Training loss:  0.148794934668  Training Accuracy:  0.9134  Test Accuracy:  0.9022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  173 : Training loss:  0.148951491382  Training Accuracy:  0.9134  Test Accuracy:  0.9022\n",
      "epoch  174 : Training loss:  0.149108045952  Training Accuracy:  0.9136  Test Accuracy:  0.9023\n",
      "epoch  175 : Training loss:  0.149264596291  Training Accuracy:  0.9139  Test Accuracy:  0.9024\n",
      "epoch  176 : Training loss:  0.149421140373  Training Accuracy:  0.9139  Test Accuracy:  0.9023\n",
      "epoch  177 : Training loss:  0.149577676231  Training Accuracy:  0.914  Test Accuracy:  0.9024\n",
      "epoch  178 : Training loss:  0.149734201955  Training Accuracy:  0.9141  Test Accuracy:  0.9024\n",
      "epoch  179 : Training loss:  0.14989071569  Training Accuracy:  0.9142  Test Accuracy:  0.9025\n",
      "epoch  180 : Training loss:  0.150047215635  Training Accuracy:  0.9144  Test Accuracy:  0.9027\n",
      "epoch  181 : Training loss:  0.150203700042  Training Accuracy:  0.9143  Test Accuracy:  0.9026\n",
      "epoch  182 : Training loss:  0.150360167212  Training Accuracy:  0.9143  Test Accuracy:  0.9028\n",
      "epoch  183 : Training loss:  0.150516615496  Training Accuracy:  0.9144  Test Accuracy:  0.9029\n",
      "epoch  184 : Training loss:  0.150673043292  Training Accuracy:  0.9146  Test Accuracy:  0.903\n",
      "epoch  185 : Training loss:  0.150829449045  Training Accuracy:  0.9147  Test Accuracy:  0.903\n",
      "epoch  186 : Training loss:  0.150985831244  Training Accuracy:  0.9147  Test Accuracy:  0.9029\n",
      "epoch  187 : Training loss:  0.151142188424  Training Accuracy:  0.9147  Test Accuracy:  0.903\n",
      "epoch  188 : Training loss:  0.151298519158  Training Accuracy:  0.915  Test Accuracy:  0.9031\n",
      "epoch  189 : Training loss:  0.151454822064  Training Accuracy:  0.9152  Test Accuracy:  0.9033\n",
      "epoch  190 : Training loss:  0.151611095799  Training Accuracy:  0.9153  Test Accuracy:  0.9034\n",
      "epoch  191 : Training loss:  0.151767339058  Training Accuracy:  0.9154  Test Accuracy:  0.9034\n",
      "epoch  192 : Training loss:  0.151923550573  Training Accuracy:  0.9155  Test Accuracy:  0.9035\n",
      "epoch  193 : Training loss:  0.152079729115  Training Accuracy:  0.9157  Test Accuracy:  0.9035\n",
      "epoch  194 : Training loss:  0.152235873488  Training Accuracy:  0.9157  Test Accuracy:  0.9035\n",
      "epoch  195 : Training loss:  0.152391982533  Training Accuracy:  0.9157  Test Accuracy:  0.9035\n",
      "epoch  196 : Training loss:  0.152548055122  Training Accuracy:  0.9157  Test Accuracy:  0.9037\n",
      "epoch  197 : Training loss:  0.152704090163  Training Accuracy:  0.9158  Test Accuracy:  0.9038\n",
      "epoch  198 : Training loss:  0.152860086592  Training Accuracy:  0.9159  Test Accuracy:  0.9037\n",
      "epoch  199 : Training loss:  0.15301604338  Training Accuracy:  0.9161  Test Accuracy:  0.9037\n",
      "epoch  200 : Training loss:  0.153171959523  Training Accuracy:  0.9161  Test Accuracy:  0.9037\n",
      "epoch  201 : Training loss:  0.153327834051  Training Accuracy:  0.9161  Test Accuracy:  0.9036\n",
      "epoch  202 : Training loss:  0.153483666019  Training Accuracy:  0.9162  Test Accuracy:  0.9036\n",
      "epoch  203 : Training loss:  0.153639454512  Training Accuracy:  0.9162  Test Accuracy:  0.9035\n",
      "epoch  204 : Training loss:  0.15379519864  Training Accuracy:  0.9162  Test Accuracy:  0.9033\n",
      "epoch  205 : Training loss:  0.15395089754  Training Accuracy:  0.9162  Test Accuracy:  0.9035\n",
      "epoch  206 : Training loss:  0.154106550374  Training Accuracy:  0.9163  Test Accuracy:  0.9035\n",
      "epoch  207 : Training loss:  0.154262156331  Training Accuracy:  0.9163  Test Accuracy:  0.9035\n",
      "epoch  208 : Training loss:  0.154417714619  Training Accuracy:  0.9164  Test Accuracy:  0.9037\n",
      "epoch  209 : Training loss:  0.154573224475  Training Accuracy:  0.9165  Test Accuracy:  0.9037\n",
      "epoch  210 : Training loss:  0.154728685155  Training Accuracy:  0.9164  Test Accuracy:  0.9038\n",
      "epoch  211 : Training loss:  0.154884095939  Training Accuracy:  0.9163  Test Accuracy:  0.9039\n",
      "epoch  212 : Training loss:  0.155039456127  Training Accuracy:  0.9163  Test Accuracy:  0.9041\n",
      "epoch  213 : Training loss:  0.155194765042  Training Accuracy:  0.9165  Test Accuracy:  0.9042\n",
      "epoch  214 : Training loss:  0.155350022026  Training Accuracy:  0.9165  Test Accuracy:  0.9043\n",
      "epoch  215 : Training loss:  0.155505226442  Training Accuracy:  0.9167  Test Accuracy:  0.9043\n",
      "epoch  216 : Training loss:  0.155660377671  Training Accuracy:  0.9168  Test Accuracy:  0.9043\n",
      "epoch  217 : Training loss:  0.155815475113  Training Accuracy:  0.9168  Test Accuracy:  0.9044\n",
      "epoch  218 : Training loss:  0.155970518187  Training Accuracy:  0.9169  Test Accuracy:  0.9045\n",
      "epoch  219 : Training loss:  0.156125506331  Training Accuracy:  0.917  Test Accuracy:  0.9045\n",
      "epoch  220 : Training loss:  0.156280438999  Training Accuracy:  0.9171  Test Accuracy:  0.9045\n",
      "epoch  221 : Training loss:  0.156435315661  Training Accuracy:  0.9172  Test Accuracy:  0.9045\n",
      "epoch  222 : Training loss:  0.156590135805  Training Accuracy:  0.9173  Test Accuracy:  0.9045\n",
      "epoch  223 : Training loss:  0.156744898935  Training Accuracy:  0.9173  Test Accuracy:  0.9046\n",
      "epoch  224 : Training loss:  0.156899604571  Training Accuracy:  0.9174  Test Accuracy:  0.9046\n",
      "epoch  225 : Training loss:  0.157054252247  Training Accuracy:  0.9174  Test Accuracy:  0.9048\n",
      "epoch  226 : Training loss:  0.157208841513  Training Accuracy:  0.9174  Test Accuracy:  0.9049\n",
      "epoch  227 : Training loss:  0.157363371932  Training Accuracy:  0.9175  Test Accuracy:  0.9051\n",
      "epoch  228 : Training loss:  0.157517843083  Training Accuracy:  0.9175  Test Accuracy:  0.9051\n",
      "epoch  229 : Training loss:  0.157672254559  Training Accuracy:  0.9176  Test Accuracy:  0.9052\n",
      "epoch  230 : Training loss:  0.157826605963  Training Accuracy:  0.9176  Test Accuracy:  0.9051\n",
      "epoch  231 : Training loss:  0.157980896915  Training Accuracy:  0.9178  Test Accuracy:  0.9052\n",
      "epoch  232 : Training loss:  0.158135127046  Training Accuracy:  0.9178  Test Accuracy:  0.9052\n",
      "epoch  233 : Training loss:  0.158289295999  Training Accuracy:  0.9178  Test Accuracy:  0.905\n",
      "epoch  234 : Training loss:  0.15844340343  Training Accuracy:  0.9178  Test Accuracy:  0.905\n",
      "epoch  235 : Training loss:  0.158597449005  Training Accuracy:  0.9179  Test Accuracy:  0.905\n",
      "epoch  236 : Training loss:  0.158751432405  Training Accuracy:  0.918  Test Accuracy:  0.905\n",
      "epoch  237 : Training loss:  0.15890535332  Training Accuracy:  0.9182  Test Accuracy:  0.905\n",
      "epoch  238 : Training loss:  0.159059211449  Training Accuracy:  0.9181  Test Accuracy:  0.905\n",
      "epoch  239 : Training loss:  0.159213006505  Training Accuracy:  0.9182  Test Accuracy:  0.905\n",
      "epoch  240 : Training loss:  0.159366738209  Training Accuracy:  0.9182  Test Accuracy:  0.9049\n",
      "epoch  241 : Training loss:  0.159520406295  Training Accuracy:  0.9183  Test Accuracy:  0.9049\n",
      "epoch  242 : Training loss:  0.159674010503  Training Accuracy:  0.9183  Test Accuracy:  0.9048\n",
      "epoch  243 : Training loss:  0.159827550585  Training Accuracy:  0.9185  Test Accuracy:  0.9048\n",
      "epoch  244 : Training loss:  0.159981026303  Training Accuracy:  0.9185  Test Accuracy:  0.905\n",
      "epoch  245 : Training loss:  0.160134437426  Training Accuracy:  0.9185  Test Accuracy:  0.905\n",
      "epoch  246 : Training loss:  0.160287783733  Training Accuracy:  0.9185  Test Accuracy:  0.905\n",
      "epoch  247 : Training loss:  0.160441065012  Training Accuracy:  0.9185  Test Accuracy:  0.905\n",
      "epoch  248 : Training loss:  0.160594281059  Training Accuracy:  0.9185  Test Accuracy:  0.9051\n",
      "epoch  249 : Training loss:  0.160747431679  Training Accuracy:  0.9185  Test Accuracy:  0.9051\n",
      "epoch  250 : Training loss:  0.160900516684  Training Accuracy:  0.9185  Test Accuracy:  0.9052\n",
      "epoch  251 : Training loss:  0.161053535893  Training Accuracy:  0.9186  Test Accuracy:  0.9052\n",
      "epoch  252 : Training loss:  0.161206489136  Training Accuracy:  0.9186  Test Accuracy:  0.9051\n",
      "epoch  253 : Training loss:  0.161359376248  Training Accuracy:  0.9186  Test Accuracy:  0.905\n",
      "epoch  254 : Training loss:  0.161512197071  Training Accuracy:  0.9187  Test Accuracy:  0.9049\n",
      "epoch  255 : Training loss:  0.161664951455  Training Accuracy:  0.9188  Test Accuracy:  0.905\n",
      "epoch  256 : Training loss:  0.161817639258  Training Accuracy:  0.9188  Test Accuracy:  0.905\n",
      "epoch  257 : Training loss:  0.161970260342  Training Accuracy:  0.9188  Test Accuracy:  0.905\n",
      "epoch  258 : Training loss:  0.162122814577  Training Accuracy:  0.919  Test Accuracy:  0.905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  259 : Training loss:  0.162275301841  Training Accuracy:  0.9191  Test Accuracy:  0.9049\n",
      "epoch  260 : Training loss:  0.162427722016  Training Accuracy:  0.9192  Test Accuracy:  0.9048\n",
      "epoch  261 : Training loss:  0.162580074991  Training Accuracy:  0.9192  Test Accuracy:  0.905\n",
      "epoch  262 : Training loss:  0.162732360661  Training Accuracy:  0.9192  Test Accuracy:  0.9051\n",
      "epoch  263 : Training loss:  0.162884578927  Training Accuracy:  0.9192  Test Accuracy:  0.9051\n",
      "epoch  264 : Training loss:  0.163036729695  Training Accuracy:  0.9191  Test Accuracy:  0.9055\n",
      "epoch  265 : Training loss:  0.163188812878  Training Accuracy:  0.9193  Test Accuracy:  0.9056\n",
      "epoch  266 : Training loss:  0.163340828392  Training Accuracy:  0.9195  Test Accuracy:  0.9056\n",
      "epoch  267 : Training loss:  0.163492776161  Training Accuracy:  0.9195  Test Accuracy:  0.9056\n",
      "epoch  268 : Training loss:  0.163644656112  Training Accuracy:  0.9195  Test Accuracy:  0.9056\n",
      "epoch  269 : Training loss:  0.163796468177  Training Accuracy:  0.9196  Test Accuracy:  0.9056\n",
      "epoch  270 : Training loss:  0.163948212296  Training Accuracy:  0.9195  Test Accuracy:  0.9056\n",
      "epoch  271 : Training loss:  0.16409988841  Training Accuracy:  0.9195  Test Accuracy:  0.9058\n",
      "epoch  272 : Training loss:  0.164251496466  Training Accuracy:  0.9195  Test Accuracy:  0.9058\n",
      "epoch  273 : Training loss:  0.164403036417  Training Accuracy:  0.9195  Test Accuracy:  0.9057\n",
      "epoch  274 : Training loss:  0.164554508218  Training Accuracy:  0.9195  Test Accuracy:  0.9056\n",
      "epoch  275 : Training loss:  0.164705911831  Training Accuracy:  0.9195  Test Accuracy:  0.9056\n",
      "epoch  276 : Training loss:  0.164857247218  Training Accuracy:  0.9195  Test Accuracy:  0.9059\n",
      "epoch  277 : Training loss:  0.165008514351  Training Accuracy:  0.9195  Test Accuracy:  0.9059\n",
      "epoch  278 : Training loss:  0.1651597132  Training Accuracy:  0.9195  Test Accuracy:  0.906\n",
      "epoch  279 : Training loss:  0.165310843744  Training Accuracy:  0.9196  Test Accuracy:  0.9062\n",
      "epoch  280 : Training loss:  0.165461905962  Training Accuracy:  0.9196  Test Accuracy:  0.9064\n",
      "epoch  281 : Training loss:  0.165612899839  Training Accuracy:  0.9197  Test Accuracy:  0.9064\n",
      "epoch  282 : Training loss:  0.165763825364  Training Accuracy:  0.9196  Test Accuracy:  0.9063\n",
      "epoch  283 : Training loss:  0.165914682526  Training Accuracy:  0.9196  Test Accuracy:  0.9063\n",
      "epoch  284 : Training loss:  0.166065471323  Training Accuracy:  0.9197  Test Accuracy:  0.9063\n",
      "epoch  285 : Training loss:  0.166216191751  Training Accuracy:  0.9197  Test Accuracy:  0.9063\n",
      "epoch  286 : Training loss:  0.166366843812  Training Accuracy:  0.9198  Test Accuracy:  0.9063\n",
      "epoch  287 : Training loss:  0.166517427511  Training Accuracy:  0.9198  Test Accuracy:  0.9063\n",
      "epoch  288 : Training loss:  0.166667942857  Training Accuracy:  0.9199  Test Accuracy:  0.9063\n",
      "epoch  289 : Training loss:  0.16681838986  Training Accuracy:  0.92  Test Accuracy:  0.9063\n",
      "epoch  290 : Training loss:  0.166968768534  Training Accuracy:  0.9199  Test Accuracy:  0.9063\n",
      "epoch  291 : Training loss:  0.167119078896  Training Accuracy:  0.9199  Test Accuracy:  0.9063\n",
      "epoch  292 : Training loss:  0.167269320966  Training Accuracy:  0.92  Test Accuracy:  0.9063\n",
      "epoch  293 : Training loss:  0.167419494766  Training Accuracy:  0.9201  Test Accuracy:  0.9063\n",
      "epoch  294 : Training loss:  0.167569600321  Training Accuracy:  0.9201  Test Accuracy:  0.9063\n",
      "epoch  295 : Training loss:  0.16771963766  Training Accuracy:  0.9202  Test Accuracy:  0.9063\n",
      "epoch  296 : Training loss:  0.167869606813  Training Accuracy:  0.9202  Test Accuracy:  0.9063\n",
      "epoch  297 : Training loss:  0.168019507812  Training Accuracy:  0.9202  Test Accuracy:  0.9063\n",
      "epoch  298 : Training loss:  0.168169340693  Training Accuracy:  0.9202  Test Accuracy:  0.9062\n",
      "epoch  299 : Training loss:  0.168319105493  Training Accuracy:  0.9201  Test Accuracy:  0.9062\n",
      "test accuracy  0.9062  training loss:  0.168319105493\n"
     ]
    }
   ],
   "source": [
    "#batch gradient descent\n",
    "\n",
    "train_data_size = 10000\n",
    "epochs = 300\n",
    "learning_rate = 0.0001\n",
    "lamda = 0.01\n",
    "# lamda = 0\n",
    "gd_weights, train_loss = train_gd(train_data_type1[:10000], epochs, learning_rate, lamda, test_data_type1)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data_type1, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.723414919482  Training Accuracy:  0.1987  Test Accuracy:  0.2002\n",
      "epoch  1 : Training loss:  0.735529110715  Training Accuracy:  0.3351  Test Accuracy:  0.3318\n",
      "epoch  2 : Training loss:  0.507648894964  Training Accuracy:  0.4345  Test Accuracy:  0.4242\n",
      "epoch  3 : Training loss:  0.321121727048  Training Accuracy:  0.6626  Test Accuracy:  0.6542\n",
      "epoch  4 : Training loss:  0.24172127357  Training Accuracy:  0.7668  Test Accuracy:  0.7651\n",
      "epoch  5 : Training loss:  0.219698158549  Training Accuracy:  0.7893  Test Accuracy:  0.7841\n",
      "epoch  6 : Training loss:  0.209131493008  Training Accuracy:  0.8024  Test Accuracy:  0.8022\n",
      "epoch  7 : Training loss:  0.201633482934  Training Accuracy:  0.8065  Test Accuracy:  0.8049\n",
      "epoch  8 : Training loss:  0.195500873421  Training Accuracy:  0.8146  Test Accuracy:  0.8145\n",
      "epoch  9 : Training loss:  0.190326210703  Training Accuracy:  0.8179  Test Accuracy:  0.8184\n",
      "epoch  10 : Training loss:  0.18590242266  Training Accuracy:  0.8246  Test Accuracy:  0.8235\n",
      "epoch  11 : Training loss:  0.182087278441  Training Accuracy:  0.8284  Test Accuracy:  0.8261\n",
      "epoch  12 : Training loss:  0.178759062782  Training Accuracy:  0.8322  Test Accuracy:  0.8286\n",
      "epoch  13 : Training loss:  0.175849247522  Training Accuracy:  0.8349  Test Accuracy:  0.8332\n",
      "epoch  14 : Training loss:  0.173278348924  Training Accuracy:  0.8361  Test Accuracy:  0.8347\n",
      "epoch  15 : Training loss:  0.171006879532  Training Accuracy:  0.8377  Test Accuracy:  0.836\n",
      "epoch  16 : Training loss:  0.168982874264  Training Accuracy:  0.8399  Test Accuracy:  0.8381\n",
      "epoch  17 : Training loss:  0.167179970246  Training Accuracy:  0.8422  Test Accuracy:  0.8396\n",
      "epoch  18 : Training loss:  0.165563980783  Training Accuracy:  0.8438  Test Accuracy:  0.8416\n",
      "epoch  19 : Training loss:  0.164115679777  Training Accuracy:  0.8458  Test Accuracy:  0.8424\n",
      "epoch  20 : Training loss:  0.162812150405  Training Accuracy:  0.8469  Test Accuracy:  0.843\n",
      "epoch  21 : Training loss:  0.161638793552  Training Accuracy:  0.8481  Test Accuracy:  0.8442\n",
      "epoch  22 : Training loss:  0.1605797988  Training Accuracy:  0.8495  Test Accuracy:  0.8461\n",
      "epoch  23 : Training loss:  0.159623896743  Training Accuracy:  0.8505  Test Accuracy:  0.8472\n",
      "epoch  24 : Training loss:  0.158759809898  Training Accuracy:  0.8513  Test Accuracy:  0.8483\n",
      "epoch  25 : Training loss:  0.157978772047  Training Accuracy:  0.853  Test Accuracy:  0.8498\n",
      "epoch  26 : Training loss:  0.15727247139  Training Accuracy:  0.8537  Test Accuracy:  0.8502\n",
      "epoch  27 : Training loss:  0.156634047307  Training Accuracy:  0.8548  Test Accuracy:  0.8511\n",
      "epoch  28 : Training loss:  0.156057194997  Training Accuracy:  0.8556  Test Accuracy:  0.8522\n",
      "epoch  29 : Training loss:  0.15553650664  Training Accuracy:  0.8563  Test Accuracy:  0.853\n",
      "epoch  30 : Training loss:  0.155067085573  Training Accuracy:  0.8573  Test Accuracy:  0.8542\n",
      "epoch  31 : Training loss:  0.154644631992  Training Accuracy:  0.8579  Test Accuracy:  0.855\n",
      "epoch  32 : Training loss:  0.154265270637  Training Accuracy:  0.8585  Test Accuracy:  0.8561\n",
      "epoch  33 : Training loss:  0.153925549407  Training Accuracy:  0.8593  Test Accuracy:  0.8568\n",
      "epoch  34 : Training loss:  0.153622354797  Training Accuracy:  0.8601  Test Accuracy:  0.8584\n",
      "epoch  35 : Training loss:  0.153352887453  Training Accuracy:  0.8608  Test Accuracy:  0.859\n",
      "epoch  36 : Training loss:  0.153114614634  Training Accuracy:  0.8613  Test Accuracy:  0.8591\n",
      "epoch  37 : Training loss:  0.152905244099  Training Accuracy:  0.8619  Test Accuracy:  0.8598\n",
      "epoch  38 : Training loss:  0.15272269364  Training Accuracy:  0.8628  Test Accuracy:  0.8606\n",
      "epoch  39 : Training loss:  0.152565068988  Training Accuracy:  0.864  Test Accuracy:  0.8612\n",
      "epoch  40 : Training loss:  0.152430642404  Training Accuracy:  0.8644  Test Accuracy:  0.8617\n",
      "epoch  41 : Training loss:  0.15231783519  Training Accuracy:  0.8656  Test Accuracy:  0.8621\n",
      "epoch  42 : Training loss:  0.152225201831  Training Accuracy:  0.8657  Test Accuracy:  0.8633\n",
      "epoch  43 : Training loss:  0.152151416388  Training Accuracy:  0.8669  Test Accuracy:  0.8633\n",
      "epoch  44 : Training loss:  0.1520952604  Training Accuracy:  0.8674  Test Accuracy:  0.8641\n",
      "epoch  45 : Training loss:  0.152055612289  Training Accuracy:  0.8682  Test Accuracy:  0.8645\n",
      "epoch  46 : Training loss:  0.152031437977  Training Accuracy:  0.8688  Test Accuracy:  0.8646\n",
      "epoch  47 : Training loss:  0.152021782575  Training Accuracy:  0.869  Test Accuracy:  0.8646\n",
      "epoch  48 : Training loss:  0.152025763006  Training Accuracy:  0.8693  Test Accuracy:  0.8647\n",
      "epoch  49 : Training loss:  0.152042561442  Training Accuracy:  0.87  Test Accuracy:  0.8648\n",
      "epoch  50 : Training loss:  0.152071419441  Training Accuracy:  0.8709  Test Accuracy:  0.8649\n",
      "epoch  51 : Training loss:  0.152111632714  Training Accuracy:  0.8717  Test Accuracy:  0.8655\n",
      "epoch  52 : Training loss:  0.152162546431  Training Accuracy:  0.8721  Test Accuracy:  0.866\n",
      "epoch  53 : Training loss:  0.152223551009  Training Accuracy:  0.8726  Test Accuracy:  0.8662\n",
      "epoch  54 : Training loss:  0.152294078326  Training Accuracy:  0.8731  Test Accuracy:  0.8668\n",
      "epoch  55 : Training loss:  0.1523735983  Training Accuracy:  0.8735  Test Accuracy:  0.8672\n",
      "epoch  56 : Training loss:  0.152461615817  Training Accuracy:  0.8735  Test Accuracy:  0.8679\n",
      "epoch  57 : Training loss:  0.152557667934  Training Accuracy:  0.8737  Test Accuracy:  0.8681\n",
      "epoch  58 : Training loss:  0.152661321358  Training Accuracy:  0.8738  Test Accuracy:  0.8682\n",
      "epoch  59 : Training loss:  0.152772170155  Training Accuracy:  0.8741  Test Accuracy:  0.8685\n",
      "epoch  60 : Training loss:  0.152889833667  Training Accuracy:  0.8746  Test Accuracy:  0.869\n",
      "epoch  61 : Training loss:  0.153013954615  Training Accuracy:  0.8751  Test Accuracy:  0.8694\n",
      "epoch  62 : Training loss:  0.153144197375  Training Accuracy:  0.8753  Test Accuracy:  0.8697\n",
      "epoch  63 : Training loss:  0.153280246395  Training Accuracy:  0.8757  Test Accuracy:  0.8702\n",
      "epoch  64 : Training loss:  0.153421804761  Training Accuracy:  0.8761  Test Accuracy:  0.8705\n",
      "epoch  65 : Training loss:  0.153568592868  Training Accuracy:  0.8766  Test Accuracy:  0.8711\n",
      "epoch  66 : Training loss:  0.153720347219  Training Accuracy:  0.8771  Test Accuracy:  0.8714\n",
      "epoch  67 : Training loss:  0.15387681931  Training Accuracy:  0.8771  Test Accuracy:  0.872\n",
      "epoch  68 : Training loss:  0.154037774611  Training Accuracy:  0.8771  Test Accuracy:  0.8724\n",
      "epoch  69 : Training loss:  0.15420299163  Training Accuracy:  0.8775  Test Accuracy:  0.8729\n",
      "epoch  70 : Training loss:  0.154372261044  Training Accuracy:  0.878  Test Accuracy:  0.8734\n",
      "epoch  71 : Training loss:  0.154545384909  Training Accuracy:  0.8784  Test Accuracy:  0.8739\n",
      "epoch  72 : Training loss:  0.154722175917  Training Accuracy:  0.8787  Test Accuracy:  0.8739\n",
      "epoch  73 : Training loss:  0.154902456725  Training Accuracy:  0.879  Test Accuracy:  0.8743\n",
      "epoch  74 : Training loss:  0.155086059319  Training Accuracy:  0.8791  Test Accuracy:  0.8744\n",
      "epoch  75 : Training loss:  0.155272824435  Training Accuracy:  0.8792  Test Accuracy:  0.8744\n",
      "epoch  76 : Training loss:  0.155462601022  Training Accuracy:  0.8794  Test Accuracy:  0.8748\n",
      "epoch  77 : Training loss:  0.155655245737  Training Accuracy:  0.8796  Test Accuracy:  0.8746\n",
      "epoch  78 : Training loss:  0.155850622485  Training Accuracy:  0.8796  Test Accuracy:  0.8747\n",
      "epoch  79 : Training loss:  0.156048601984  Training Accuracy:  0.8796  Test Accuracy:  0.8752\n",
      "epoch  80 : Training loss:  0.156249061367  Training Accuracy:  0.8798  Test Accuracy:  0.8754\n",
      "epoch  81 : Training loss:  0.156451883802  Training Accuracy:  0.8798  Test Accuracy:  0.8755\n",
      "epoch  82 : Training loss:  0.156656958152  Training Accuracy:  0.8797  Test Accuracy:  0.8757\n",
      "epoch  83 : Training loss:  0.156864178644  Training Accuracy:  0.8798  Test Accuracy:  0.8763\n",
      "epoch  84 : Training loss:  0.157073444565  Training Accuracy:  0.88  Test Accuracy:  0.8768\n",
      "epoch  85 : Training loss:  0.157284659987  Training Accuracy:  0.8802  Test Accuracy:  0.8773\n",
      "epoch  86 : Training loss:  0.157497733493  Training Accuracy:  0.8804  Test Accuracy:  0.8776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  87 : Training loss:  0.157712577935  Training Accuracy:  0.8806  Test Accuracy:  0.8776\n",
      "epoch  88 : Training loss:  0.1579291102  Training Accuracy:  0.8808  Test Accuracy:  0.8777\n",
      "epoch  89 : Training loss:  0.158147250995  Training Accuracy:  0.8808  Test Accuracy:  0.8782\n",
      "epoch  90 : Training loss:  0.158366924642  Training Accuracy:  0.8811  Test Accuracy:  0.8783\n",
      "epoch  91 : Training loss:  0.158588058889  Training Accuracy:  0.8814  Test Accuracy:  0.8785\n",
      "epoch  92 : Training loss:  0.158810584726  Training Accuracy:  0.8815  Test Accuracy:  0.8788\n",
      "epoch  93 : Training loss:  0.159034436226  Training Accuracy:  0.8816  Test Accuracy:  0.8795\n",
      "epoch  94 : Training loss:  0.159259550377  Training Accuracy:  0.8821  Test Accuracy:  0.8796\n",
      "epoch  95 : Training loss:  0.159485866941  Training Accuracy:  0.8823  Test Accuracy:  0.8798\n",
      "epoch  96 : Training loss:  0.159713328309  Training Accuracy:  0.8825  Test Accuracy:  0.8802\n",
      "epoch  97 : Training loss:  0.159941879373  Training Accuracy:  0.883  Test Accuracy:  0.8801\n",
      "epoch  98 : Training loss:  0.160171467399  Training Accuracy:  0.8832  Test Accuracy:  0.8803\n",
      "epoch  99 : Training loss:  0.160402041915  Training Accuracy:  0.8833  Test Accuracy:  0.8803\n",
      "epoch  100 : Training loss:  0.160633554594  Training Accuracy:  0.8837  Test Accuracy:  0.8804\n",
      "epoch  101 : Training loss:  0.160865959156  Training Accuracy:  0.8838  Test Accuracy:  0.8805\n",
      "epoch  102 : Training loss:  0.161099211266  Training Accuracy:  0.8841  Test Accuracy:  0.8809\n",
      "epoch  103 : Training loss:  0.161333268443  Training Accuracy:  0.8842  Test Accuracy:  0.8811\n",
      "epoch  104 : Training loss:  0.161568089975  Training Accuracy:  0.8842  Test Accuracy:  0.8814\n",
      "epoch  105 : Training loss:  0.161803636828  Training Accuracy:  0.8845  Test Accuracy:  0.8815\n",
      "epoch  106 : Training loss:  0.162039871579  Training Accuracy:  0.8845  Test Accuracy:  0.8814\n",
      "epoch  107 : Training loss:  0.162276758331  Training Accuracy:  0.8848  Test Accuracy:  0.8812\n",
      "epoch  108 : Training loss:  0.16251426265  Training Accuracy:  0.8848  Test Accuracy:  0.8812\n",
      "epoch  109 : Training loss:  0.162752351497  Training Accuracy:  0.8848  Test Accuracy:  0.8812\n",
      "epoch  110 : Training loss:  0.162990993164  Training Accuracy:  0.8848  Test Accuracy:  0.8812\n",
      "epoch  111 : Training loss:  0.163230157212  Training Accuracy:  0.8851  Test Accuracy:  0.8813\n",
      "epoch  112 : Training loss:  0.163469814419  Training Accuracy:  0.885  Test Accuracy:  0.8814\n",
      "epoch  113 : Training loss:  0.163709936726  Training Accuracy:  0.8852  Test Accuracy:  0.8817\n",
      "epoch  114 : Training loss:  0.16395049718  Training Accuracy:  0.8852  Test Accuracy:  0.8817\n",
      "epoch  115 : Training loss:  0.164191469892  Training Accuracy:  0.8853  Test Accuracy:  0.8816\n",
      "epoch  116 : Training loss:  0.16443282999  Training Accuracy:  0.8854  Test Accuracy:  0.8817\n",
      "epoch  117 : Training loss:  0.164674553571  Training Accuracy:  0.8858  Test Accuracy:  0.882\n",
      "epoch  118 : Training loss:  0.164916617663  Training Accuracy:  0.8858  Test Accuracy:  0.8822\n",
      "epoch  119 : Training loss:  0.165159000186  Training Accuracy:  0.8861  Test Accuracy:  0.8825\n",
      "epoch  120 : Training loss:  0.165401679913  Training Accuracy:  0.8862  Test Accuracy:  0.8828\n",
      "epoch  121 : Training loss:  0.165644636432  Training Accuracy:  0.8862  Test Accuracy:  0.8829\n",
      "epoch  122 : Training loss:  0.165887850118  Training Accuracy:  0.8863  Test Accuracy:  0.8831\n",
      "epoch  123 : Training loss:  0.166131302093  Training Accuracy:  0.8863  Test Accuracy:  0.8832\n",
      "epoch  124 : Training loss:  0.1663749742  Training Accuracy:  0.8864  Test Accuracy:  0.8832\n",
      "epoch  125 : Training loss:  0.166618848973  Training Accuracy:  0.8866  Test Accuracy:  0.8833\n",
      "epoch  126 : Training loss:  0.166862909607  Training Accuracy:  0.8866  Test Accuracy:  0.8834\n",
      "epoch  127 : Training loss:  0.167107139934  Training Accuracy:  0.8868  Test Accuracy:  0.8837\n",
      "epoch  128 : Training loss:  0.167351524392  Training Accuracy:  0.8868  Test Accuracy:  0.8835\n",
      "epoch  129 : Training loss:  0.167596048009  Training Accuracy:  0.887  Test Accuracy:  0.8835\n",
      "epoch  130 : Training loss:  0.16784069637  Training Accuracy:  0.8871  Test Accuracy:  0.8837\n",
      "epoch  131 : Training loss:  0.168085455604  Training Accuracy:  0.8872  Test Accuracy:  0.8839\n",
      "epoch  132 : Training loss:  0.168330312355  Training Accuracy:  0.8873  Test Accuracy:  0.884\n",
      "epoch  133 : Training loss:  0.168575253767  Training Accuracy:  0.8874  Test Accuracy:  0.884\n",
      "epoch  134 : Training loss:  0.168820267461  Training Accuracy:  0.8873  Test Accuracy:  0.8841\n",
      "epoch  135 : Training loss:  0.16906534152  Training Accuracy:  0.8873  Test Accuracy:  0.8841\n",
      "epoch  136 : Training loss:  0.169310464467  Training Accuracy:  0.8876  Test Accuracy:  0.8842\n",
      "epoch  137 : Training loss:  0.169555625253  Training Accuracy:  0.8876  Test Accuracy:  0.8845\n",
      "epoch  138 : Training loss:  0.169800813234  Training Accuracy:  0.8876  Test Accuracy:  0.8849\n",
      "epoch  139 : Training loss:  0.170046018163  Training Accuracy:  0.8876  Test Accuracy:  0.8852\n",
      "epoch  140 : Training loss:  0.17029123017  Training Accuracy:  0.8877  Test Accuracy:  0.8854\n",
      "epoch  141 : Training loss:  0.17053643975  Training Accuracy:  0.8877  Test Accuracy:  0.8856\n",
      "epoch  142 : Training loss:  0.170781637747  Training Accuracy:  0.8879  Test Accuracy:  0.8857\n",
      "epoch  143 : Training loss:  0.171026815343  Training Accuracy:  0.8881  Test Accuracy:  0.8858\n",
      "epoch  144 : Training loss:  0.171271964047  Training Accuracy:  0.8882  Test Accuracy:  0.886\n",
      "epoch  145 : Training loss:  0.171517075677  Training Accuracy:  0.8885  Test Accuracy:  0.886\n",
      "epoch  146 : Training loss:  0.171762142357  Training Accuracy:  0.8885  Test Accuracy:  0.8861\n",
      "epoch  147 : Training loss:  0.172007156497  Training Accuracy:  0.8886  Test Accuracy:  0.886\n",
      "epoch  148 : Training loss:  0.172252110789  Training Accuracy:  0.889  Test Accuracy:  0.8861\n",
      "epoch  149 : Training loss:  0.172496998194  Training Accuracy:  0.889  Test Accuracy:  0.8862\n",
      "epoch  150 : Training loss:  0.172741811933  Training Accuracy:  0.8891  Test Accuracy:  0.8862\n",
      "epoch  151 : Training loss:  0.172986545476  Training Accuracy:  0.889  Test Accuracy:  0.8863\n",
      "epoch  152 : Training loss:  0.173231192537  Training Accuracy:  0.8889  Test Accuracy:  0.8866\n",
      "epoch  153 : Training loss:  0.173475747061  Training Accuracy:  0.8889  Test Accuracy:  0.8867\n",
      "epoch  154 : Training loss:  0.173720203216  Training Accuracy:  0.889  Test Accuracy:  0.8868\n",
      "epoch  155 : Training loss:  0.173964555389  Training Accuracy:  0.889  Test Accuracy:  0.8868\n",
      "epoch  156 : Training loss:  0.174208798174  Training Accuracy:  0.8891  Test Accuracy:  0.8872\n",
      "epoch  157 : Training loss:  0.174452926367  Training Accuracy:  0.8893  Test Accuracy:  0.8873\n",
      "epoch  158 : Training loss:  0.174696934959  Training Accuracy:  0.8894  Test Accuracy:  0.8875\n",
      "epoch  159 : Training loss:  0.174940819128  Training Accuracy:  0.8894  Test Accuracy:  0.8877\n",
      "epoch  160 : Training loss:  0.175184574231  Training Accuracy:  0.8896  Test Accuracy:  0.8878\n",
      "epoch  161 : Training loss:  0.175428195803  Training Accuracy:  0.8897  Test Accuracy:  0.8879\n",
      "epoch  162 : Training loss:  0.175671679545  Training Accuracy:  0.8898  Test Accuracy:  0.8881\n",
      "epoch  163 : Training loss:  0.175915021321  Training Accuracy:  0.8898  Test Accuracy:  0.8881\n",
      "epoch  164 : Training loss:  0.176158217155  Training Accuracy:  0.8899  Test Accuracy:  0.8883\n",
      "epoch  165 : Training loss:  0.176401263218  Training Accuracy:  0.8899  Test Accuracy:  0.8884\n",
      "epoch  166 : Training loss:  0.176644155832  Training Accuracy:  0.89  Test Accuracy:  0.8887\n",
      "epoch  167 : Training loss:  0.176886891457  Training Accuracy:  0.8902  Test Accuracy:  0.889\n",
      "epoch  168 : Training loss:  0.177129466692  Training Accuracy:  0.8904  Test Accuracy:  0.8891\n",
      "epoch  169 : Training loss:  0.177371878267  Training Accuracy:  0.8905  Test Accuracy:  0.889\n",
      "epoch  170 : Training loss:  0.17761412304  Training Accuracy:  0.8905  Test Accuracy:  0.8892\n",
      "epoch  171 : Training loss:  0.177856197992  Training Accuracy:  0.8903  Test Accuracy:  0.8892\n",
      "epoch  172 : Training loss:  0.178098100223  Training Accuracy:  0.8904  Test Accuracy:  0.8892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  173 : Training loss:  0.178339826948  Training Accuracy:  0.8906  Test Accuracy:  0.8892\n",
      "epoch  174 : Training loss:  0.178581375495  Training Accuracy:  0.8907  Test Accuracy:  0.8893\n",
      "epoch  175 : Training loss:  0.178822743297  Training Accuracy:  0.8907  Test Accuracy:  0.8895\n",
      "epoch  176 : Training loss:  0.179063927891  Training Accuracy:  0.8907  Test Accuracy:  0.8896\n",
      "epoch  177 : Training loss:  0.179304926918  Training Accuracy:  0.8907  Test Accuracy:  0.8897\n",
      "epoch  178 : Training loss:  0.179545738112  Training Accuracy:  0.8908  Test Accuracy:  0.8898\n",
      "epoch  179 : Training loss:  0.179786359302  Training Accuracy:  0.8909  Test Accuracy:  0.8899\n",
      "epoch  180 : Training loss:  0.18002678841  Training Accuracy:  0.8909  Test Accuracy:  0.8898\n",
      "epoch  181 : Training loss:  0.180267023443  Training Accuracy:  0.891  Test Accuracy:  0.8898\n",
      "epoch  182 : Training loss:  0.180507062494  Training Accuracy:  0.8911  Test Accuracy:  0.8898\n",
      "epoch  183 : Training loss:  0.180746903739  Training Accuracy:  0.8913  Test Accuracy:  0.8898\n",
      "epoch  184 : Training loss:  0.180986545432  Training Accuracy:  0.8917  Test Accuracy:  0.8896\n",
      "epoch  185 : Training loss:  0.181225985905  Training Accuracy:  0.8917  Test Accuracy:  0.8897\n",
      "epoch  186 : Training loss:  0.181465223563  Training Accuracy:  0.8917  Test Accuracy:  0.8898\n",
      "epoch  187 : Training loss:  0.181704256884  Training Accuracy:  0.8918  Test Accuracy:  0.8898\n",
      "epoch  188 : Training loss:  0.181943084415  Training Accuracy:  0.8918  Test Accuracy:  0.8898\n",
      "epoch  189 : Training loss:  0.182181704771  Training Accuracy:  0.892  Test Accuracy:  0.8898\n",
      "epoch  190 : Training loss:  0.182420116631  Training Accuracy:  0.8921  Test Accuracy:  0.8898\n",
      "epoch  191 : Training loss:  0.182658318738  Training Accuracy:  0.8919  Test Accuracy:  0.8898\n",
      "epoch  192 : Training loss:  0.182896309894  Training Accuracy:  0.8919  Test Accuracy:  0.89\n",
      "epoch  193 : Training loss:  0.183134088963  Training Accuracy:  0.892  Test Accuracy:  0.89\n",
      "epoch  194 : Training loss:  0.183371654864  Training Accuracy:  0.8921  Test Accuracy:  0.8902\n",
      "epoch  195 : Training loss:  0.183609006571  Training Accuracy:  0.8921  Test Accuracy:  0.8904\n",
      "epoch  196 : Training loss:  0.183846143113  Training Accuracy:  0.8921  Test Accuracy:  0.8905\n",
      "epoch  197 : Training loss:  0.184083063569  Training Accuracy:  0.8922  Test Accuracy:  0.8906\n",
      "epoch  198 : Training loss:  0.184319767068  Training Accuracy:  0.8924  Test Accuracy:  0.8906\n",
      "epoch  199 : Training loss:  0.18455625279  Training Accuracy:  0.8927  Test Accuracy:  0.8906\n",
      "epoch  200 : Training loss:  0.184792519958  Training Accuracy:  0.8927  Test Accuracy:  0.8906\n",
      "epoch  201 : Training loss:  0.185028567844  Training Accuracy:  0.8928  Test Accuracy:  0.8906\n",
      "epoch  202 : Training loss:  0.185264395761  Training Accuracy:  0.8929  Test Accuracy:  0.8906\n",
      "epoch  203 : Training loss:  0.185500003066  Training Accuracy:  0.893  Test Accuracy:  0.8906\n",
      "epoch  204 : Training loss:  0.185735389157  Training Accuracy:  0.893  Test Accuracy:  0.8906\n",
      "epoch  205 : Training loss:  0.185970553471  Training Accuracy:  0.8932  Test Accuracy:  0.8906\n",
      "epoch  206 : Training loss:  0.186205495485  Training Accuracy:  0.8933  Test Accuracy:  0.8906\n",
      "epoch  207 : Training loss:  0.186440214711  Training Accuracy:  0.8933  Test Accuracy:  0.8906\n",
      "epoch  208 : Training loss:  0.186674710699  Training Accuracy:  0.8933  Test Accuracy:  0.8911\n",
      "epoch  209 : Training loss:  0.186908983033  Training Accuracy:  0.8934  Test Accuracy:  0.8912\n",
      "epoch  210 : Training loss:  0.187143031332  Training Accuracy:  0.8936  Test Accuracy:  0.8912\n",
      "epoch  211 : Training loss:  0.187376855245  Training Accuracy:  0.8939  Test Accuracy:  0.8913\n",
      "epoch  212 : Training loss:  0.187610454456  Training Accuracy:  0.8939  Test Accuracy:  0.8913\n",
      "epoch  213 : Training loss:  0.187843828676  Training Accuracy:  0.8941  Test Accuracy:  0.8913\n",
      "epoch  214 : Training loss:  0.18807697765  Training Accuracy:  0.8942  Test Accuracy:  0.8915\n",
      "epoch  215 : Training loss:  0.188309901147  Training Accuracy:  0.8944  Test Accuracy:  0.8915\n",
      "epoch  216 : Training loss:  0.188542598967  Training Accuracy:  0.8944  Test Accuracy:  0.8914\n",
      "epoch  217 : Training loss:  0.188775070936  Training Accuracy:  0.8946  Test Accuracy:  0.8914\n",
      "epoch  218 : Training loss:  0.189007316905  Training Accuracy:  0.8946  Test Accuracy:  0.8914\n",
      "epoch  219 : Training loss:  0.189239336752  Training Accuracy:  0.8948  Test Accuracy:  0.8914\n",
      "epoch  220 : Training loss:  0.189471130377  Training Accuracy:  0.8948  Test Accuracy:  0.8915\n",
      "epoch  221 : Training loss:  0.189702697706  Training Accuracy:  0.8948  Test Accuracy:  0.8915\n",
      "epoch  222 : Training loss:  0.189934038686  Training Accuracy:  0.8949  Test Accuracy:  0.8914\n",
      "epoch  223 : Training loss:  0.190165153286  Training Accuracy:  0.895  Test Accuracy:  0.8914\n",
      "epoch  224 : Training loss:  0.190396041497  Training Accuracy:  0.8951  Test Accuracy:  0.8913\n",
      "epoch  225 : Training loss:  0.190626703331  Training Accuracy:  0.8952  Test Accuracy:  0.8913\n",
      "epoch  226 : Training loss:  0.190857138819  Training Accuracy:  0.8954  Test Accuracy:  0.8913\n",
      "epoch  227 : Training loss:  0.191087348012  Training Accuracy:  0.8955  Test Accuracy:  0.8914\n",
      "epoch  228 : Training loss:  0.191317330978  Training Accuracy:  0.8957  Test Accuracy:  0.8914\n",
      "epoch  229 : Training loss:  0.191547087806  Training Accuracy:  0.8958  Test Accuracy:  0.8914\n",
      "epoch  230 : Training loss:  0.191776618599  Training Accuracy:  0.8961  Test Accuracy:  0.8913\n",
      "epoch  231 : Training loss:  0.192005923479  Training Accuracy:  0.8962  Test Accuracy:  0.8913\n",
      "epoch  232 : Training loss:  0.192235002584  Training Accuracy:  0.8961  Test Accuracy:  0.8913\n",
      "epoch  233 : Training loss:  0.192463856068  Training Accuracy:  0.896  Test Accuracy:  0.8915\n",
      "epoch  234 : Training loss:  0.192692484099  Training Accuracy:  0.896  Test Accuracy:  0.8914\n",
      "epoch  235 : Training loss:  0.19292088686  Training Accuracy:  0.8961  Test Accuracy:  0.8915\n",
      "epoch  236 : Training loss:  0.193149064549  Training Accuracy:  0.8962  Test Accuracy:  0.8915\n",
      "epoch  237 : Training loss:  0.193377017377  Training Accuracy:  0.8962  Test Accuracy:  0.8918\n",
      "epoch  238 : Training loss:  0.193604745569  Training Accuracy:  0.8964  Test Accuracy:  0.8918\n",
      "epoch  239 : Training loss:  0.193832249362  Training Accuracy:  0.8965  Test Accuracy:  0.8917\n",
      "epoch  240 : Training loss:  0.194059529006  Training Accuracy:  0.8965  Test Accuracy:  0.8918\n",
      "epoch  241 : Training loss:  0.194286584763  Training Accuracy:  0.8965  Test Accuracy:  0.8919\n",
      "epoch  242 : Training loss:  0.194513416904  Training Accuracy:  0.8968  Test Accuracy:  0.8921\n",
      "epoch  243 : Training loss:  0.194740025715  Training Accuracy:  0.8968  Test Accuracy:  0.8919\n",
      "epoch  244 : Training loss:  0.194966411491  Training Accuracy:  0.8968  Test Accuracy:  0.8919\n",
      "epoch  245 : Training loss:  0.195192574536  Training Accuracy:  0.8969  Test Accuracy:  0.8919\n",
      "epoch  246 : Training loss:  0.195418515166  Training Accuracy:  0.8972  Test Accuracy:  0.892\n",
      "epoch  247 : Training loss:  0.195644233706  Training Accuracy:  0.8973  Test Accuracy:  0.8921\n",
      "epoch  248 : Training loss:  0.19586973049  Training Accuracy:  0.8973  Test Accuracy:  0.892\n",
      "epoch  249 : Training loss:  0.19609500586  Training Accuracy:  0.8973  Test Accuracy:  0.8921\n",
      "epoch  250 : Training loss:  0.196320060169  Training Accuracy:  0.8975  Test Accuracy:  0.8921\n",
      "epoch  251 : Training loss:  0.196544893777  Training Accuracy:  0.8974  Test Accuracy:  0.892\n",
      "epoch  252 : Training loss:  0.19676950705  Training Accuracy:  0.8974  Test Accuracy:  0.892\n",
      "epoch  253 : Training loss:  0.196993900366  Training Accuracy:  0.8976  Test Accuracy:  0.892\n",
      "epoch  254 : Training loss:  0.197218074106  Training Accuracy:  0.8977  Test Accuracy:  0.892\n",
      "epoch  255 : Training loss:  0.197442028662  Training Accuracy:  0.8979  Test Accuracy:  0.892\n",
      "epoch  256 : Training loss:  0.197665764429  Training Accuracy:  0.8979  Test Accuracy:  0.8921\n",
      "epoch  257 : Training loss:  0.197889281812  Training Accuracy:  0.8978  Test Accuracy:  0.8921\n",
      "epoch  258 : Training loss:  0.198112581221  Training Accuracy:  0.8978  Test Accuracy:  0.8921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  259 : Training loss:  0.198335663071  Training Accuracy:  0.8978  Test Accuracy:  0.8922\n",
      "epoch  260 : Training loss:  0.198558527785  Training Accuracy:  0.8978  Test Accuracy:  0.8923\n",
      "epoch  261 : Training loss:  0.198781175789  Training Accuracy:  0.898  Test Accuracy:  0.8924\n",
      "epoch  262 : Training loss:  0.199003607517  Training Accuracy:  0.898  Test Accuracy:  0.8926\n",
      "epoch  263 : Training loss:  0.199225823407  Training Accuracy:  0.8982  Test Accuracy:  0.8927\n",
      "epoch  264 : Training loss:  0.199447823901  Training Accuracy:  0.8982  Test Accuracy:  0.8928\n",
      "epoch  265 : Training loss:  0.199669609447  Training Accuracy:  0.8982  Test Accuracy:  0.8927\n",
      "epoch  266 : Training loss:  0.199891180498  Training Accuracy:  0.8983  Test Accuracy:  0.8928\n",
      "epoch  267 : Training loss:  0.20011253751  Training Accuracy:  0.8984  Test Accuracy:  0.8929\n",
      "epoch  268 : Training loss:  0.200333680943  Training Accuracy:  0.8985  Test Accuracy:  0.893\n",
      "epoch  269 : Training loss:  0.200554611263  Training Accuracy:  0.8986  Test Accuracy:  0.893\n",
      "epoch  270 : Training loss:  0.200775328938  Training Accuracy:  0.8986  Test Accuracy:  0.8929\n",
      "epoch  271 : Training loss:  0.200995834439  Training Accuracy:  0.8985  Test Accuracy:  0.8929\n",
      "epoch  272 : Training loss:  0.201216128243  Training Accuracy:  0.8985  Test Accuracy:  0.893\n",
      "epoch  273 : Training loss:  0.201436210828  Training Accuracy:  0.8986  Test Accuracy:  0.8931\n",
      "epoch  274 : Training loss:  0.201656082676  Training Accuracy:  0.8987  Test Accuracy:  0.8931\n",
      "epoch  275 : Training loss:  0.201875744272  Training Accuracy:  0.8987  Test Accuracy:  0.8932\n",
      "epoch  276 : Training loss:  0.202095196104  Training Accuracy:  0.8988  Test Accuracy:  0.8931\n",
      "epoch  277 : Training loss:  0.202314438663  Training Accuracy:  0.8986  Test Accuracy:  0.8931\n",
      "epoch  278 : Training loss:  0.20253347244  Training Accuracy:  0.8985  Test Accuracy:  0.8931\n",
      "epoch  279 : Training loss:  0.202752297932  Training Accuracy:  0.8985  Test Accuracy:  0.8931\n",
      "epoch  280 : Training loss:  0.202970915635  Training Accuracy:  0.8989  Test Accuracy:  0.8931\n",
      "epoch  281 : Training loss:  0.203189326051  Training Accuracy:  0.899  Test Accuracy:  0.8931\n",
      "epoch  282 : Training loss:  0.20340752968  Training Accuracy:  0.8989  Test Accuracy:  0.8931\n",
      "epoch  283 : Training loss:  0.203625527026  Training Accuracy:  0.899  Test Accuracy:  0.8931\n",
      "epoch  284 : Training loss:  0.203843318595  Training Accuracy:  0.899  Test Accuracy:  0.8932\n",
      "epoch  285 : Training loss:  0.204060904893  Training Accuracy:  0.899  Test Accuracy:  0.8932\n",
      "epoch  286 : Training loss:  0.20427828643  Training Accuracy:  0.8991  Test Accuracy:  0.8932\n",
      "epoch  287 : Training loss:  0.204495463714  Training Accuracy:  0.8992  Test Accuracy:  0.8933\n",
      "epoch  288 : Training loss:  0.204712437259  Training Accuracy:  0.8993  Test Accuracy:  0.8933\n",
      "epoch  289 : Training loss:  0.204929207576  Training Accuracy:  0.8993  Test Accuracy:  0.8934\n",
      "epoch  290 : Training loss:  0.205145775179  Training Accuracy:  0.8993  Test Accuracy:  0.8934\n",
      "epoch  291 : Training loss:  0.205362140582  Training Accuracy:  0.8994  Test Accuracy:  0.8936\n",
      "epoch  292 : Training loss:  0.205578304303  Training Accuracy:  0.8994  Test Accuracy:  0.8938\n",
      "epoch  293 : Training loss:  0.205794266856  Training Accuracy:  0.8996  Test Accuracy:  0.8939\n",
      "epoch  294 : Training loss:  0.20601002876  Training Accuracy:  0.8996  Test Accuracy:  0.8939\n",
      "epoch  295 : Training loss:  0.206225590533  Training Accuracy:  0.8996  Test Accuracy:  0.8939\n",
      "epoch  296 : Training loss:  0.206440952693  Training Accuracy:  0.8997  Test Accuracy:  0.8941\n",
      "epoch  297 : Training loss:  0.20665611576  Training Accuracy:  0.8998  Test Accuracy:  0.8941\n",
      "epoch  298 : Training loss:  0.206871080253  Training Accuracy:  0.8998  Test Accuracy:  0.894\n",
      "epoch  299 : Training loss:  0.207085846692  Training Accuracy:  0.8997  Test Accuracy:  0.8941\n",
      "test accuracy  0.8941  training loss:  0.207085846692\n"
     ]
    }
   ],
   "source": [
    "gd_weights, train_loss = train_gd(train_data_type2[:10000], epochs, learning_rate, lamda, test_data_type2)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data_type2, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.zeros((10,1))\n",
    "sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
