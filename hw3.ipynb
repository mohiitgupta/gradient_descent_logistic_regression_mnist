{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)   (10,)\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[[ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "(10,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-a2c2c077ca89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# numpy experimentation\n",
    "a=np.ones((10))\n",
    "b=np.zeros(10)\n",
    "b[1]=1\n",
    "print a.shape, \" \", b.shape\n",
    "c =1.2*np.outer(a,b)\n",
    "print (a*b)\n",
    "print np.square(c)\n",
    "print c\n",
    "print c[:,1].shape\n",
    "a[0][b==0]=4\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename,'rb') as fp:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', fp.read(4))\n",
    "        shape = tuple(struct.unpack('>I', fp.read(4))[0] for d in range(dims))\n",
    "        np_array = np.frombuffer(fp.read(), dtype=np.uint8).reshape(shape)\n",
    "    return np_array\n",
    "\n",
    "def preprocess(image_file, label_file):\n",
    "    images = read_file(image_file)\n",
    "    labels = read_file(label_file)\n",
    "    if (len(labels) > 10000):\n",
    "        labels = labels[:10000]\n",
    "        images = images[:10000]    \n",
    "    images = images/255.0\n",
    "    images = images.reshape( (10000, 784))\n",
    "\n",
    "    labels = labels.reshape(-1,1)\n",
    "    data = np.concatenate((images, labels), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def get_features_labels(data, bias):\n",
    "    examples = data[:,:-1]\n",
    "    labels = data[:,-1]\n",
    "    classifier_labels = np.zeros((10, len(labels)))\n",
    "    for i in range(10):\n",
    "        classifier_labels[i][labels == i] = 1\n",
    "    examples = np.append(examples, bias, 1)\n",
    "    return examples, labels, classifier_labels\n",
    "\n",
    "def get_true_label(digit, perceptron_type):\n",
    "    if digit == perceptron_type:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(test_data, weights):\n",
    "    data_size = len(test_data)\n",
    "    bias = np.ones((data_size,1))\n",
    "    examples, labels, classifier_labels = get_features_labels(test_data, bias)\n",
    "    prediction = np.ones(data_size, dtype = int)\n",
    "    correct = 0\n",
    "    for i, example in enumerate(examples):\n",
    "        activation_values = sigmoid(np.sum(weights*example, axis = 1))\n",
    "        prediction[i] = np.argmax(activation_values)\n",
    "        if prediction[i] == labels[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct*1.0/data_size\n",
    "    return prediction, labels, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "def sigmoid(value):\n",
    "    value[value > 100] = 100\n",
    "    value[value < -100] = -100\n",
    "    return 1/(1+np.exp(-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"../hw2/DATA_FOLDER/\"\n",
    "\n",
    "train_data = preprocess(path + '/train-images.idx3-ubyte', path + '/train-labels.idx1-ubyte')\n",
    "# print train_data[1]\n",
    "test_data = preprocess(path + '/t10k-images.idx3-ubyte', path + '/t10k-labels.idx1-ubyte')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate(w, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "\n",
    "    A = sigmoid(np.dot(w,X.T)) \n",
    "    print A.shape\n",
    "\n",
    "    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n",
    "\n",
    "    dz= (1/m)*(A - Y)\n",
    "    dw = np.dot(dz,X)\n",
    "    print dw.shape\n",
    "\n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\"dw\": dw}\n",
    "\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sgd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,785])\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,785))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.00000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.00000001)\n",
    "        \n",
    "        weights -= delta_weights - lamda*weights\n",
    "        loss /= -data_size*1.0 + lamda\n",
    "        loss = np.sum(loss)\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "#         if loss < 3.4 and epoch > 50:\n",
    "#             return weights, loss\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,785])\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,785))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.0000000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.0000000001)\n",
    "        \n",
    "        weights = weights - delta_weights - lamda*weights\n",
    "        loss = loss*-1.0/data_size + lamda*np.sum(np.square(weights), axis = 1)/2.0\n",
    "        loss = np.sum(loss)/10.0\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "#         if loss < 3.4 and epoch > 50:\n",
    "#             return weights, loss\n",
    "    return weights, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.777608446606  Training Accuracy:  0.1909  Test Accuracy:  0.1958\n",
      "epoch  1 : Training loss:  1.38404539488  Training Accuracy:  0.3439  Test Accuracy:  0.3567\n",
      "epoch  2 : Training loss:  0.904091957421  Training Accuracy:  0.41  Test Accuracy:  0.4216\n",
      "epoch  3 : Training loss:  0.476009712109  Training Accuracy:  0.5657  Test Accuracy:  0.5699\n",
      "epoch  4 : Training loss:  0.257369494884  Training Accuracy:  0.6761  Test Accuracy:  0.6622\n",
      "epoch  5 : Training loss:  0.228449768713  Training Accuracy:  0.8028  Test Accuracy:  0.7966\n",
      "epoch  6 : Training loss:  0.167645122412  Training Accuracy:  0.7366  Test Accuracy:  0.7239\n",
      "epoch  7 : Training loss:  0.171673585638  Training Accuracy:  0.7581  Test Accuracy:  0.7541\n",
      "epoch  8 : Training loss:  0.176319548407  Training Accuracy:  0.718  Test Accuracy:  0.7018\n",
      "epoch  9 : Training loss:  0.18101169798  Training Accuracy:  0.7723  Test Accuracy:  0.7689\n",
      "epoch  10 : Training loss:  0.18389401357  Training Accuracy:  0.7792  Test Accuracy:  0.77\n",
      "epoch  11 : Training loss:  0.158293017076  Training Accuracy:  0.8335  Test Accuracy:  0.8291\n",
      "epoch  12 : Training loss:  0.151772968464  Training Accuracy:  0.7721  Test Accuracy:  0.7625\n",
      "epoch  13 : Training loss:  0.158700240888  Training Accuracy:  0.8297  Test Accuracy:  0.8208\n",
      "epoch  14 : Training loss:  0.150797866279  Training Accuracy:  0.7799  Test Accuracy:  0.7692\n",
      "epoch  15 : Training loss:  0.156358115747  Training Accuracy:  0.7988  Test Accuracy:  0.795\n",
      "epoch  16 : Training loss:  0.163000419513  Training Accuracy:  0.8014  Test Accuracy:  0.7954\n",
      "epoch  17 : Training loss:  0.150136809391  Training Accuracy:  0.8322  Test Accuracy:  0.8247\n",
      "epoch  18 : Training loss:  0.148236161523  Training Accuracy:  0.8041  Test Accuracy:  0.795\n",
      "epoch  19 : Training loss:  0.149625739887  Training Accuracy:  0.817  Test Accuracy:  0.813\n",
      "epoch  20 : Training loss:  0.153639073149  Training Accuracy:  0.82  Test Accuracy:  0.8138\n",
      "epoch  21 : Training loss:  0.14496432516  Training Accuracy:  0.8353  Test Accuracy:  0.8304\n",
      "epoch  22 : Training loss:  0.145559157894  Training Accuracy:  0.824  Test Accuracy:  0.8169\n",
      "epoch  23 : Training loss:  0.143690120553  Training Accuracy:  0.8343  Test Accuracy:  0.8285\n",
      "epoch  24 : Training loss:  0.145872077463  Training Accuracy:  0.8344  Test Accuracy:  0.8253\n",
      "epoch  25 : Training loss:  0.141104425775  Training Accuracy:  0.8418  Test Accuracy:  0.8355\n",
      "epoch  26 : Training loss:  0.142517171557  Training Accuracy:  0.8428  Test Accuracy:  0.8323\n",
      "epoch  27 : Training loss:  0.139279528217  Training Accuracy:  0.8472  Test Accuracy:  0.8393\n",
      "epoch  28 : Training loss:  0.140680267938  Training Accuracy:  0.8478  Test Accuracy:  0.8384\n",
      "epoch  29 : Training loss:  0.137535528275  Training Accuracy:  0.8505  Test Accuracy:  0.8431\n",
      "epoch  30 : Training loss:  0.138782448088  Training Accuracy:  0.853  Test Accuracy:  0.8439\n",
      "epoch  31 : Training loss:  0.135990734211  Training Accuracy:  0.8559  Test Accuracy:  0.8474\n",
      "epoch  32 : Training loss:  0.137131511445  Training Accuracy:  0.8568  Test Accuracy:  0.8482\n",
      "epoch  33 : Training loss:  0.134610480236  Training Accuracy:  0.8592  Test Accuracy:  0.8505\n",
      "epoch  34 : Training loss:  0.135672179413  Training Accuracy:  0.8613  Test Accuracy:  0.8521\n",
      "epoch  35 : Training loss:  0.133374738068  Training Accuracy:  0.862  Test Accuracy:  0.8538\n",
      "epoch  36 : Training loss:  0.134379485789  Training Accuracy:  0.8654  Test Accuracy:  0.8558\n",
      "epoch  37 : Training loss:  0.132265946144  Training Accuracy:  0.8646  Test Accuracy:  0.8559\n",
      "epoch  38 : Training loss:  0.133231336292  Training Accuracy:  0.8692  Test Accuracy:  0.8589\n",
      "epoch  39 : Training loss:  0.131268806663  Training Accuracy:  0.8662  Test Accuracy:  0.8591\n",
      "epoch  40 : Training loss:  0.132208468143  Training Accuracy:  0.8715  Test Accuracy:  0.8611\n",
      "epoch  41 : Training loss:  0.130370050863  Training Accuracy:  0.869  Test Accuracy:  0.8605\n",
      "epoch  42 : Training loss:  0.131294289158  Training Accuracy:  0.8732  Test Accuracy:  0.8628\n",
      "epoch  43 : Training loss:  0.129558162901  Training Accuracy:  0.8709  Test Accuracy:  0.8626\n",
      "epoch  44 : Training loss:  0.130474587238  Training Accuracy:  0.8744  Test Accuracy:  0.8642\n",
      "epoch  45 : Training loss:  0.128823110639  Training Accuracy:  0.8721  Test Accuracy:  0.8641\n",
      "epoch  46 : Training loss:  0.129737198241  Training Accuracy:  0.8756  Test Accuracy:  0.8656\n",
      "epoch  47 : Training loss:  0.128156115047  Training Accuracy:  0.8736  Test Accuracy:  0.8649\n",
      "epoch  48 : Training loss:  0.129071692302  Training Accuracy:  0.8769  Test Accuracy:  0.8666\n",
      "epoch  49 : Training loss:  0.127549466838  Training Accuracy:  0.8741  Test Accuracy:  0.866\n",
      "epoch  50 : Training loss:  0.128469104575  Training Accuracy:  0.8777  Test Accuracy:  0.8677\n",
      "epoch  51 : Training loss:  0.12699638417  Training Accuracy:  0.8752  Test Accuracy:  0.8672\n",
      "epoch  52 : Training loss:  0.127921713677  Training Accuracy:  0.8785  Test Accuracy:  0.8696\n",
      "epoch  53 : Training loss:  0.126490900157  Training Accuracy:  0.8756  Test Accuracy:  0.8684\n",
      "epoch  54 : Training loss:  0.127422860861  Training Accuracy:  0.8801  Test Accuracy:  0.8699\n",
      "epoch  55 : Training loss:  0.126027769877  Training Accuracy:  0.8772  Test Accuracy:  0.8699\n",
      "epoch  56 : Training loss:  0.126966800666  Training Accuracy:  0.8811  Test Accuracy:  0.871\n",
      "epoch  57 : Training loss:  0.125602389692  Training Accuracy:  0.878  Test Accuracy:  0.8708\n",
      "epoch  58 : Training loss:  0.12654857516  Training Accuracy:  0.8824  Test Accuracy:  0.8718\n",
      "epoch  59 : Training loss:  0.12521072475  Training Accuracy:  0.8783  Test Accuracy:  0.8713\n",
      "epoch  60 : Training loss:  0.126163906054  Training Accuracy:  0.8835  Test Accuracy:  0.8727\n",
      "epoch  61 : Training loss:  0.12484924271  Training Accuracy:  0.879  Test Accuracy:  0.8717\n",
      "epoch  62 : Training loss:  0.125809100933  Training Accuracy:  0.8845  Test Accuracy:  0.8733\n",
      "epoch  63 : Training loss:  0.124514852933  Training Accuracy:  0.8801  Test Accuracy:  0.872\n",
      "epoch  64 : Training loss:  0.125480971159  Training Accuracy:  0.8853  Test Accuracy:  0.8741\n",
      "epoch  65 : Training loss:  0.124204850989  Training Accuracy:  0.8806  Test Accuracy:  0.873\n",
      "epoch  66 : Training loss:  0.125176759897  Training Accuracy:  0.8855  Test Accuracy:  0.8749\n",
      "epoch  67 : Training loss:  0.123916868467  Training Accuracy:  0.8814  Test Accuracy:  0.8738\n",
      "epoch  68 : Training loss:  0.124894079153  Training Accuracy:  0.8862  Test Accuracy:  0.8758\n",
      "epoch  69 : Training loss:  0.123648828078  Training Accuracy:  0.8817  Test Accuracy:  0.8745\n",
      "epoch  70 : Training loss:  0.124630855002  Training Accuracy:  0.8867  Test Accuracy:  0.8762\n",
      "epoch  71 : Training loss:  0.123398903933  Training Accuracy:  0.8822  Test Accuracy:  0.875\n",
      "epoch  72 : Training loss:  0.124385280276  Training Accuracy:  0.8868  Test Accuracy:  0.8766\n",
      "epoch  73 : Training loss:  0.123165486749  Training Accuracy:  0.8827  Test Accuracy:  0.8751\n",
      "epoch  74 : Training loss:  0.124155774013  Training Accuracy:  0.8874  Test Accuracy:  0.8768\n",
      "epoch  75 : Training loss:  0.122947153667  Training Accuracy:  0.8834  Test Accuracy:  0.8758\n",
      "epoch  76 : Training loss:  0.123940946989  Training Accuracy:  0.8876  Test Accuracy:  0.8776\n",
      "epoch  77 : Training loss:  0.122742642274  Training Accuracy:  0.8838  Test Accuracy:  0.876\n",
      "epoch  78 : Training loss:  0.123739572636  Training Accuracy:  0.8877  Test Accuracy:  0.8778\n",
      "epoch  79 : Training loss:  0.12255082839  Training Accuracy:  0.8842  Test Accuracy:  0.8763\n",
      "epoch  80 : Training loss:  0.123550562665  Training Accuracy:  0.8882  Test Accuracy:  0.8777\n",
      "epoch  81 : Training loss:  0.122370707174  Training Accuracy:  0.8844  Test Accuracy:  0.8764\n",
      "epoch  82 : Training loss:  0.123372946746  Training Accuracy:  0.8884  Test Accuracy:  0.8778\n",
      "epoch  83 : Training loss:  0.122201377104  Training Accuracy:  0.8847  Test Accuracy:  0.8767\n",
      "epoch  84 : Training loss:  0.123205855619  Training Accuracy:  0.8889  Test Accuracy:  0.8777\n",
      "epoch  85 : Training loss:  0.122042026433  Training Accuracy:  0.8854  Test Accuracy:  0.877\n",
      "epoch  86 : Training loss:  0.12304850709  Training Accuracy:  0.8892  Test Accuracy:  0.878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  87 : Training loss:  0.121891921726  Training Accuracy:  0.8856  Test Accuracy:  0.8773\n",
      "epoch  88 : Training loss:  0.122900194412  Training Accuracy:  0.8894  Test Accuracy:  0.8782\n",
      "epoch  89 : Training loss:  0.121750398164  Training Accuracy:  0.8859  Test Accuracy:  0.8777\n",
      "epoch  90 : Training loss:  0.12276027662  Training Accuracy:  0.8899  Test Accuracy:  0.8783\n",
      "epoch  91 : Training loss:  0.12161685132  Training Accuracy:  0.886  Test Accuracy:  0.8777\n",
      "epoch  92 : Training loss:  0.122628170469  Training Accuracy:  0.8899  Test Accuracy:  0.8784\n",
      "epoch  93 : Training loss:  0.121490730154  Training Accuracy:  0.8862  Test Accuracy:  0.8779\n",
      "epoch  94 : Training loss:  0.122503343651  Training Accuracy:  0.89  Test Accuracy:  0.8783\n",
      "epoch  95 : Training loss:  0.121371531034  Training Accuracy:  0.8864  Test Accuracy:  0.8785\n",
      "epoch  96 : Training loss:  0.12238530908  Training Accuracy:  0.8901  Test Accuracy:  0.8782\n",
      "epoch  97 : Training loss:  0.121258792603  Training Accuracy:  0.8869  Test Accuracy:  0.8788\n",
      "epoch  98 : Training loss:  0.122273620006  Training Accuracy:  0.8904  Test Accuracy:  0.8782\n",
      "epoch  99 : Training loss:  0.121152091341  Training Accuracy:  0.887  Test Accuracy:  0.8793\n",
      "epoch  100 : Training loss:  0.12216786583  Training Accuracy:  0.8905  Test Accuracy:  0.8786\n",
      "epoch  101 : Training loss:  0.121051037728  Training Accuracy:  0.8871  Test Accuracy:  0.8795\n",
      "epoch  102 : Training loss:  0.122067668486  Training Accuracy:  0.891  Test Accuracy:  0.8786\n",
      "epoch  103 : Training loss:  0.120955272893  Training Accuracy:  0.8873  Test Accuracy:  0.8797\n",
      "epoch  104 : Training loss:  0.121972679281  Training Accuracy:  0.8911  Test Accuracy:  0.8786\n",
      "epoch  105 : Training loss:  0.120864465676  Training Accuracy:  0.8876  Test Accuracy:  0.8798\n",
      "epoch  106 : Training loss:  0.121882576125  Training Accuracy:  0.8913  Test Accuracy:  0.8788\n",
      "epoch  107 : Training loss:  0.120778310051  Training Accuracy:  0.888  Test Accuracy:  0.8801\n",
      "epoch  108 : Training loss:  0.121797061091  Training Accuracy:  0.8916  Test Accuracy:  0.879\n"
     ]
    }
   ],
   "source": [
    "train_data_size = 10000\n",
    "epochs = 200\n",
    "learning_rate = 0.0001\n",
    "lamda = 0.01\n",
    "# lamda = 0\n",
    "gd_weights, train_loss = train_gd(train_data[:10000], epochs, learning_rate, lamda, test_data)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.zeros((10,1))\n",
    "sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
