{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)   (10,)\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[[ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.44  0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   1.2  0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "(10,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-a2c2c077ca89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# numpy experimentation\n",
    "a=np.ones((10))\n",
    "b=np.zeros(10)\n",
    "b[1]=1\n",
    "print a.shape, \" \", b.shape\n",
    "c =1.2*np.outer(a,b)\n",
    "print (a*b)\n",
    "print np.square(c)\n",
    "print c\n",
    "print c[:,1].shape\n",
    "a[0][b==0]=4\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename,'rb') as fp:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', fp.read(4))\n",
    "        shape = tuple(struct.unpack('>I', fp.read(4))[0] for d in range(dims))\n",
    "        np_array = np.frombuffer(fp.read(), dtype=np.uint8).reshape(shape)\n",
    "    return np_array\n",
    "\n",
    "def preprocess(image_file, label_file):\n",
    "    images = read_file(image_file)\n",
    "    labels = read_file(label_file)\n",
    "    if (len(labels) > 10000):\n",
    "        labels = labels[:10000]\n",
    "        images = images[:10000]    \n",
    "    images = images/255.0\n",
    "    images = images.reshape( (10000, 784))\n",
    "\n",
    "    labels = labels.reshape(-1,1)\n",
    "    data = np.concatenate((images, labels), axis=1)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def get_features_labels(data, bias):\n",
    "    examples = data[:,:-1]\n",
    "    labels = data[:,-1]\n",
    "    classifier_labels = np.zeros((10, len(labels)))\n",
    "    for i in range(10):\n",
    "        classifier_labels[i][labels == i] = 1\n",
    "    examples = np.append(examples, bias, 1)\n",
    "    return examples, labels, classifier_labels\n",
    "\n",
    "def get_true_label(digit, perceptron_type):\n",
    "    if digit == perceptron_type:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(test_data, weights):\n",
    "    data_size = len(test_data)\n",
    "    bias = np.ones((data_size,1))\n",
    "    examples, labels, classifier_labels = get_features_labels(test_data, bias)\n",
    "    prediction = np.ones(data_size, dtype = int)\n",
    "    correct = 0\n",
    "    for i, example in enumerate(examples):\n",
    "        activation_values = sigmoid(np.sum(weights*example, axis = 1))\n",
    "        prediction[i] = np.argmax(activation_values)\n",
    "        if prediction[i] == labels[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct*1.0/data_size\n",
    "    return prediction, labels, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "def sigmoid(value):\n",
    "    value[value > 100] = 100\n",
    "    value[value < -100] = -100\n",
    "    return 1/(1+np.exp(-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"../hw2/DATA_FOLDER/\"\n",
    "\n",
    "train_data = preprocess(path + '/train-images.idx3-ubyte', path + '/train-labels.idx1-ubyte')\n",
    "# print train_data[1]\n",
    "test_data = preprocess(path + '/t10k-images.idx3-ubyte', path + '/t10k-labels.idx1-ubyte')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate(w, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "\n",
    "    A = sigmoid(np.dot(w,X.T)) \n",
    "    print A.shape\n",
    "\n",
    "    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))\n",
    "\n",
    "    dz= (1/m)*(A - Y)\n",
    "    dw = np.dot(dz,X)\n",
    "    print dw.shape\n",
    "\n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\"dw\": dw}\n",
    "\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sgd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,785])\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,785))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.00000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.00000001)\n",
    "        \n",
    "        weights -= delta_weights - lamda*weights\n",
    "        loss /= -data_size*1.0 + lamda\n",
    "        loss = np.sum(loss)\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "#         if loss < 3.4 and epoch > 50:\n",
    "#             return weights, loss\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gd(train_data, num_epoches, learning_rate, lamda, test_data):\n",
    "    data_size = len(train_data)\n",
    "    weights = np.random.uniform(-0.1,0.1,[10,785])\n",
    "    bias = np.ones((data_size,1))\n",
    "    for epoch in range(num_epoches):\n",
    "        loss = np.zeros(10)\n",
    "        np.random.shuffle(train_data)\n",
    "        examples, labels, classifier_labels = get_features_labels(train_data, bias)\n",
    "        delta_weights = np.zeros((10,785))\n",
    "        for i,example in enumerate(examples):\n",
    "            z = np.sum(weights*example, axis = 1)\n",
    "            y_pred = sigmoid(z)\n",
    "            delta_weights += learning_rate*np.outer(y_pred-classifier_labels[:,i],example)\n",
    "            loss+=classifier_labels[:,i]*np.log(y_pred+0.00000001)+(1-classifier_labels[:,i])*np.log(1-y_pred+0.00000001)\n",
    "        \n",
    "        weights = weights - delta_weights - lamda*weights\n",
    "        loss = loss*-1.0/data_size + lamda*np.sum(np.square(weights), axis = 1)/2.0\n",
    "        loss = np.sum(loss)/10.0\n",
    "        train_prediction, train_labels, train_accuracy = inference(train_data[:train_data_size], weights)\n",
    "        test_prediction, test_labels, test_accuracy = inference(test_data, weights)\n",
    "        print \"epoch \", epoch, \": Training loss: \", loss, \" Training Accuracy: \", train_accuracy, \" Test Accuracy: \", test_accuracy\n",
    "#         if loss < 3.4 and epoch > 50:\n",
    "#             return weights, loss\n",
    "    return weights, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : Training loss:  0.734175288656  Training Accuracy:  0.2577  Test Accuracy:  0.2546\n",
      "epoch  1 : Training loss:  0.953996496051  Training Accuracy:  0.5281  Test Accuracy:  0.5122\n",
      "epoch  2 : Training loss:  0.627161918212  Training Accuracy:  0.5884  Test Accuracy:  0.5668\n",
      "epoch  3 : Training loss:  0.335214059157  Training Accuracy:  0.6712  Test Accuracy:  0.6639\n",
      "epoch  4 : Training loss:  0.215818033532  Training Accuracy:  0.7458  Test Accuracy:  0.7377\n",
      "epoch  5 : Training loss:  0.177654883886  Training Accuracy:  0.7893  Test Accuracy:  0.7863\n",
      "epoch  6 : Training loss:  0.159916402452  Training Accuracy:  0.8011  Test Accuracy:  0.8019\n",
      "epoch  7 : Training loss:  0.153935614887  Training Accuracy:  0.8086  Test Accuracy:  0.8071\n",
      "epoch  8 : Training loss:  0.148818043724  Training Accuracy:  0.8181  Test Accuracy:  0.8166\n",
      "epoch  9 : Training loss:  0.144038116419  Training Accuracy:  0.8244  Test Accuracy:  0.8203\n",
      "epoch  10 : Training loss:  0.140676538624  Training Accuracy:  0.8307  Test Accuracy:  0.8269\n",
      "epoch  11 : Training loss:  0.136677525379  Training Accuracy:  0.8363  Test Accuracy:  0.8328\n",
      "epoch  12 : Training loss:  0.13406413998  Training Accuracy:  0.8402  Test Accuracy:  0.8357\n",
      "epoch  13 : Training loss:  0.130803314283  Training Accuracy:  0.8446  Test Accuracy:  0.8417\n",
      "epoch  14 : Training loss:  0.128567813035  Training Accuracy:  0.8494  Test Accuracy:  0.844\n",
      "epoch  15 : Training loss:  0.125959938248  Training Accuracy:  0.8511  Test Accuracy:  0.8467\n",
      "epoch  16 : Training loss:  0.123996881144  Training Accuracy:  0.8543  Test Accuracy:  0.8492\n",
      "epoch  17 : Training loss:  0.121905161676  Training Accuracy:  0.856  Test Accuracy:  0.8528\n",
      "epoch  18 : Training loss:  0.120184224615  Training Accuracy:  0.859  Test Accuracy:  0.8534\n",
      "epoch  19 : Training loss:  0.118473731358  Training Accuracy:  0.861  Test Accuracy:  0.8571\n",
      "epoch  20 : Training loss:  0.116972570915  Training Accuracy:  0.8624  Test Accuracy:  0.8578\n",
      "epoch  21 : Training loss:  0.115536067518  Training Accuracy:  0.8639  Test Accuracy:  0.8601\n",
      "epoch  22 : Training loss:  0.114224942848  Training Accuracy:  0.8653  Test Accuracy:  0.8612\n",
      "epoch  23 : Training loss:  0.112986767658  Training Accuracy:  0.8671  Test Accuracy:  0.8631\n",
      "epoch  24 : Training loss:  0.111832282912  Training Accuracy:  0.8678  Test Accuracy:  0.8635\n",
      "epoch  25 : Training loss:  0.110742345313  Training Accuracy:  0.8681  Test Accuracy:  0.865\n",
      "epoch  26 : Training loss:  0.10971442663  Training Accuracy:  0.8699  Test Accuracy:  0.8656\n",
      "epoch  27 : Training loss:  0.108740191198  Training Accuracy:  0.8702  Test Accuracy:  0.8661\n",
      "epoch  28 : Training loss:  0.107815353362  Training Accuracy:  0.8714  Test Accuracy:  0.8668\n",
      "epoch  29 : Training loss:  0.106935182424  Training Accuracy:  0.8721  Test Accuracy:  0.8672\n",
      "epoch  30 : Training loss:  0.106096068203  Training Accuracy:  0.8729  Test Accuracy:  0.868\n",
      "epoch  31 : Training loss:  0.105294736695  Training Accuracy:  0.8739  Test Accuracy:  0.8688\n",
      "epoch  32 : Training loss:  0.104528365308  Training Accuracy:  0.8748  Test Accuracy:  0.8696\n",
      "epoch  33 : Training loss:  0.103794442158  Training Accuracy:  0.8757  Test Accuracy:  0.8708\n",
      "epoch  34 : Training loss:  0.103090718919  Training Accuracy:  0.8763  Test Accuracy:  0.8713\n",
      "epoch  35 : Training loss:  0.102415172018  Training Accuracy:  0.8771  Test Accuracy:  0.872\n",
      "epoch  36 : Training loss:  0.101765964723  Training Accuracy:  0.8773  Test Accuracy:  0.8726\n",
      "epoch  37 : Training loss:  0.101141426953  Training Accuracy:  0.878  Test Accuracy:  0.8735\n",
      "epoch  38 : Training loss:  0.100540032172  Training Accuracy:  0.8786  Test Accuracy:  0.8741\n",
      "epoch  39 : Training loss:  0.0999603829838  Training Accuracy:  0.8788  Test Accuracy:  0.8751\n",
      "epoch  40 : Training loss:  0.0994011960525  Training Accuracy:  0.8793  Test Accuracy:  0.8759\n",
      "epoch  41 : Training loss:  0.0988612909317  Training Accuracy:  0.8798  Test Accuracy:  0.8763\n",
      "epoch  42 : Training loss:  0.0983395793086  Training Accuracy:  0.8806  Test Accuracy:  0.8763\n",
      "epoch  43 : Training loss:  0.097835056192  Training Accuracy:  0.8813  Test Accuracy:  0.8772\n",
      "epoch  44 : Training loss:  0.0973467918022  Training Accuracy:  0.8818  Test Accuracy:  0.8778\n",
      "epoch  45 : Training loss:  0.0968739245929  Training Accuracy:  0.8824  Test Accuracy:  0.8784\n",
      "epoch  46 : Training loss:  0.0964156549482  Training Accuracy:  0.8828  Test Accuracy:  0.8786\n",
      "epoch  47 : Training loss:  0.0959712396326  Training Accuracy:  0.8831  Test Accuracy:  0.8795\n",
      "epoch  48 : Training loss:  0.0955399868044  Training Accuracy:  0.884  Test Accuracy:  0.8798\n",
      "epoch  49 : Training loss:  0.0951212515739  Training Accuracy:  0.8851  Test Accuracy:  0.8806\n",
      "epoch  50 : Training loss:  0.0947144320112  Training Accuracy:  0.8857  Test Accuracy:  0.8808\n",
      "epoch  51 : Training loss:  0.0943189655643  Training Accuracy:  0.8861  Test Accuracy:  0.8808\n",
      "epoch  52 : Training loss:  0.093934325832  Training Accuracy:  0.8866  Test Accuracy:  0.8809\n",
      "epoch  53 : Training loss:  0.0935600196546  Training Accuracy:  0.8867  Test Accuracy:  0.8812\n",
      "epoch  54 : Training loss:  0.093195584483  Training Accuracy:  0.887  Test Accuracy:  0.8815\n",
      "epoch  55 : Training loss:  0.0928405859985  Training Accuracy:  0.887  Test Accuracy:  0.8818\n",
      "epoch  56 : Training loss:  0.0924946159523  Training Accuracy:  0.8874  Test Accuracy:  0.8821\n",
      "epoch  57 : Training loss:  0.0921572902044  Training Accuracy:  0.888  Test Accuracy:  0.8822\n",
      "epoch  58 : Training loss:  0.0918282469374  Training Accuracy:  0.8883  Test Accuracy:  0.8829\n",
      "epoch  59 : Training loss:  0.0915071450303  Training Accuracy:  0.8886  Test Accuracy:  0.8831\n",
      "epoch  60 : Training loss:  0.0911936625725  Training Accuracy:  0.8889  Test Accuracy:  0.8832\n",
      "epoch  61 : Training loss:  0.0908874955067  Training Accuracy:  0.8893  Test Accuracy:  0.8835\n",
      "epoch  62 : Training loss:  0.0905883563859  Training Accuracy:  0.8895  Test Accuracy:  0.8838\n",
      "epoch  63 : Training loss:  0.090295973234  Training Accuracy:  0.8898  Test Accuracy:  0.8838\n",
      "epoch  64 : Training loss:  0.0900100885004  Training Accuracy:  0.8902  Test Accuracy:  0.8839\n",
      "epoch  65 : Training loss:  0.0897304580988  Training Accuracy:  0.8902  Test Accuracy:  0.8842\n",
      "epoch  66 : Training loss:  0.0894568505229  Training Accuracy:  0.8905  Test Accuracy:  0.8845\n",
      "epoch  67 : Training loss:  0.0891890460312  Training Accuracy:  0.8906  Test Accuracy:  0.8847\n",
      "epoch  68 : Training loss:  0.0889268358961  Training Accuracy:  0.8908  Test Accuracy:  0.8846\n",
      "epoch  69 : Training loss:  0.0886700217091  Training Accuracy:  0.8908  Test Accuracy:  0.8847\n",
      "epoch  70 : Training loss:  0.0884184147396  Training Accuracy:  0.8911  Test Accuracy:  0.8851\n",
      "epoch  71 : Training loss:  0.0881718353408  Training Accuracy:  0.8914  Test Accuracy:  0.8855\n",
      "epoch  72 : Training loss:  0.0879301123994  Training Accuracy:  0.8916  Test Accuracy:  0.8856\n",
      "epoch  73 : Training loss:  0.0876930828258  Training Accuracy:  0.892  Test Accuracy:  0.8861\n",
      "epoch  74 : Training loss:  0.0874605910798  Training Accuracy:  0.8925  Test Accuracy:  0.8863\n",
      "epoch  75 : Training loss:  0.087232488731  Training Accuracy:  0.8929  Test Accuracy:  0.8867\n",
      "epoch  76 : Training loss:  0.087008634049  Training Accuracy:  0.8931  Test Accuracy:  0.8869\n",
      "epoch  77 : Training loss:  0.0867888916224  Training Accuracy:  0.8933  Test Accuracy:  0.8872\n",
      "epoch  78 : Training loss:  0.0865731320038  Training Accuracy:  0.8935  Test Accuracy:  0.8874\n",
      "epoch  79 : Training loss:  0.0863612313784  Training Accuracy:  0.8939  Test Accuracy:  0.8876\n",
      "epoch  80 : Training loss:  0.086153071255  Training Accuracy:  0.8939  Test Accuracy:  0.8878\n",
      "epoch  81 : Training loss:  0.0859485381774  Training Accuracy:  0.8941  Test Accuracy:  0.8884\n",
      "epoch  82 : Training loss:  0.0857475234539  Training Accuracy:  0.8945  Test Accuracy:  0.8884\n",
      "epoch  83 : Training loss:  0.0855499229054  Training Accuracy:  0.8947  Test Accuracy:  0.8886\n",
      "epoch  84 : Training loss:  0.0853556366282  Training Accuracy:  0.8949  Test Accuracy:  0.8889\n",
      "epoch  85 : Training loss:  0.0851645687729  Training Accuracy:  0.895  Test Accuracy:  0.8888\n",
      "epoch  86 : Training loss:  0.0849766273361  Training Accuracy:  0.8953  Test Accuracy:  0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  87 : Training loss:  0.0847917239657  Training Accuracy:  0.8954  Test Accuracy:  0.8889\n",
      "epoch  88 : Training loss:  0.0846097737776  Training Accuracy:  0.8955  Test Accuracy:  0.8892\n",
      "epoch  89 : Training loss:  0.0844306951835  Training Accuracy:  0.8959  Test Accuracy:  0.8893\n",
      "epoch  90 : Training loss:  0.0842544097292  Training Accuracy:  0.8962  Test Accuracy:  0.8894\n",
      "epoch  91 : Training loss:  0.084080841942  Training Accuracy:  0.8963  Test Accuracy:  0.8897\n",
      "epoch  92 : Training loss:  0.0839099191875  Training Accuracy:  0.8966  Test Accuracy:  0.8898\n",
      "epoch  93 : Training loss:  0.0837415715345  Training Accuracy:  0.8969  Test Accuracy:  0.89\n",
      "epoch  94 : Training loss:  0.0835757316274  Training Accuracy:  0.8971  Test Accuracy:  0.8899\n",
      "epoch  95 : Training loss:  0.0834123345664  Training Accuracy:  0.8972  Test Accuracy:  0.8899\n",
      "epoch  96 : Training loss:  0.0832513177934  Training Accuracy:  0.8975  Test Accuracy:  0.8898\n",
      "epoch  97 : Training loss:  0.0830926209858  Training Accuracy:  0.8975  Test Accuracy:  0.8898\n",
      "epoch  98 : Training loss:  0.0829361859542  Training Accuracy:  0.8975  Test Accuracy:  0.8898\n",
      "epoch  99 : Training loss:  0.0827819565476  Training Accuracy:  0.8977  Test Accuracy:  0.8898\n",
      "epoch  100 : Training loss:  0.0826298785623  Training Accuracy:  0.8979  Test Accuracy:  0.8901\n",
      "epoch  101 : Training loss:  0.0824798996566  Training Accuracy:  0.898  Test Accuracy:  0.8903\n",
      "epoch  102 : Training loss:  0.082331969269  Training Accuracy:  0.8981  Test Accuracy:  0.8905\n",
      "epoch  103 : Training loss:  0.082186038542  Training Accuracy:  0.8981  Test Accuracy:  0.8906\n",
      "epoch  104 : Training loss:  0.0820420602487  Training Accuracy:  0.8982  Test Accuracy:  0.8906\n",
      "epoch  105 : Training loss:  0.081899988724  Training Accuracy:  0.8984  Test Accuracy:  0.8904\n",
      "epoch  106 : Training loss:  0.0817597797986  Training Accuracy:  0.8987  Test Accuracy:  0.8906\n",
      "epoch  107 : Training loss:  0.0816213907369  Training Accuracy:  0.8989  Test Accuracy:  0.8907\n",
      "epoch  108 : Training loss:  0.081484780178  Training Accuracy:  0.8991  Test Accuracy:  0.8908\n",
      "epoch  109 : Training loss:  0.0813499080793  Training Accuracy:  0.8996  Test Accuracy:  0.8909\n",
      "epoch  110 : Training loss:  0.0812167356628  Training Accuracy:  0.8999  Test Accuracy:  0.8909\n",
      "epoch  111 : Training loss:  0.0810852253648  Training Accuracy:  0.9001  Test Accuracy:  0.8914\n",
      "epoch  112 : Training loss:  0.0809553407869  Training Accuracy:  0.9001  Test Accuracy:  0.8914\n",
      "epoch  113 : Training loss:  0.0808270466506  Training Accuracy:  0.9002  Test Accuracy:  0.8914\n",
      "epoch  114 : Training loss:  0.0807003087528  Training Accuracy:  0.9003  Test Accuracy:  0.8916\n",
      "epoch  115 : Training loss:  0.0805750939246  Training Accuracy:  0.9005  Test Accuracy:  0.8918\n",
      "epoch  116 : Training loss:  0.080451369991  Training Accuracy:  0.901  Test Accuracy:  0.8919\n",
      "epoch  117 : Training loss:  0.0803291057332  Training Accuracy:  0.9011  Test Accuracy:  0.8918\n",
      "epoch  118 : Training loss:  0.0802082708522  Training Accuracy:  0.9015  Test Accuracy:  0.8922\n",
      "epoch  119 : Training loss:  0.0800888359344  Training Accuracy:  0.9017  Test Accuracy:  0.8926\n",
      "epoch  120 : Training loss:  0.0799707724186  Training Accuracy:  0.9022  Test Accuracy:  0.8929\n",
      "epoch  121 : Training loss:  0.0798540525642  Training Accuracy:  0.9023  Test Accuracy:  0.8932\n",
      "epoch  122 : Training loss:  0.0797386494214  Training Accuracy:  0.9023  Test Accuracy:  0.8933\n",
      "epoch  123 : Training loss:  0.0796245368023  Training Accuracy:  0.9026  Test Accuracy:  0.8933\n",
      "epoch  124 : Training loss:  0.0795116892536  Training Accuracy:  0.9028  Test Accuracy:  0.8936\n",
      "epoch  125 : Training loss:  0.0794000820299  Training Accuracy:  0.9026  Test Accuracy:  0.8936\n",
      "epoch  126 : Training loss:  0.0792896910687  Training Accuracy:  0.9027  Test Accuracy:  0.8936\n",
      "epoch  127 : Training loss:  0.0791804929665  Training Accuracy:  0.9028  Test Accuracy:  0.8937\n",
      "epoch  128 : Training loss:  0.0790724649555  Training Accuracy:  0.903  Test Accuracy:  0.8938\n",
      "epoch  129 : Training loss:  0.0789655848817  Training Accuracy:  0.903  Test Accuracy:  0.8938\n",
      "epoch  130 : Training loss:  0.0788598311836  Training Accuracy:  0.9032  Test Accuracy:  0.8939\n",
      "epoch  131 : Training loss:  0.0787551828719  Training Accuracy:  0.9032  Test Accuracy:  0.8939\n",
      "epoch  132 : Training loss:  0.0786516195103  Training Accuracy:  0.9034  Test Accuracy:  0.894\n",
      "epoch  133 : Training loss:  0.0785491211966  Training Accuracy:  0.9036  Test Accuracy:  0.8941\n",
      "epoch  134 : Training loss:  0.0784476685448  Training Accuracy:  0.9037  Test Accuracy:  0.8943\n",
      "epoch  135 : Training loss:  0.0783472426683  Training Accuracy:  0.9038  Test Accuracy:  0.8944\n",
      "epoch  136 : Training loss:  0.0782478251632  Training Accuracy:  0.9039  Test Accuracy:  0.8945\n",
      "epoch  137 : Training loss:  0.0781493980923  Training Accuracy:  0.9038  Test Accuracy:  0.8947\n",
      "epoch  138 : Training loss:  0.0780519439704  Training Accuracy:  0.9042  Test Accuracy:  0.8947\n",
      "epoch  139 : Training loss:  0.0779554457492  Training Accuracy:  0.9043  Test Accuracy:  0.8947\n",
      "epoch  140 : Training loss:  0.0778598868037  Training Accuracy:  0.9044  Test Accuracy:  0.8947\n",
      "epoch  141 : Training loss:  0.0777652509186  Training Accuracy:  0.9046  Test Accuracy:  0.8949\n",
      "epoch  142 : Training loss:  0.0776715222751  Training Accuracy:  0.9048  Test Accuracy:  0.895\n",
      "epoch  143 : Training loss:  0.077578685439  Training Accuracy:  0.9047  Test Accuracy:  0.8951\n",
      "epoch  144 : Training loss:  0.0774867253481  Training Accuracy:  0.9047  Test Accuracy:  0.8953\n",
      "epoch  145 : Training loss:  0.0773956273012  Training Accuracy:  0.9048  Test Accuracy:  0.8955\n",
      "epoch  146 : Training loss:  0.0773053769466  Training Accuracy:  0.905  Test Accuracy:  0.8956\n",
      "epoch  147 : Training loss:  0.0772159602717  Training Accuracy:  0.9051  Test Accuracy:  0.8957\n",
      "epoch  148 : Training loss:  0.0771273635927  Training Accuracy:  0.9053  Test Accuracy:  0.8957\n",
      "epoch  149 : Training loss:  0.0770395735444  Training Accuracy:  0.9053  Test Accuracy:  0.8959\n",
      "epoch  150 : Training loss:  0.076952577071  Training Accuracy:  0.9054  Test Accuracy:  0.896\n",
      "epoch  151 : Training loss:  0.0768663614169  Training Accuracy:  0.9054  Test Accuracy:  0.8959\n",
      "epoch  152 : Training loss:  0.0767809141174  Training Accuracy:  0.9053  Test Accuracy:  0.8961\n",
      "epoch  153 : Training loss:  0.0766962229908  Training Accuracy:  0.9054  Test Accuracy:  0.8962\n",
      "epoch  154 : Training loss:  0.0766122761296  Training Accuracy:  0.9058  Test Accuracy:  0.8961\n",
      "epoch  155 : Training loss:  0.0765290618929  Training Accuracy:  0.9059  Test Accuracy:  0.8962\n",
      "epoch  156 : Training loss:  0.0764465688986  Training Accuracy:  0.9059  Test Accuracy:  0.8963\n",
      "epoch  157 : Training loss:  0.0763647860159  Training Accuracy:  0.9058  Test Accuracy:  0.8967\n",
      "epoch  158 : Training loss:  0.0762837023583  Training Accuracy:  0.9058  Test Accuracy:  0.8968\n",
      "epoch  159 : Training loss:  0.0762033072767  Training Accuracy:  0.9058  Test Accuracy:  0.8969\n",
      "epoch  160 : Training loss:  0.0761235903528  Training Accuracy:  0.9058  Test Accuracy:  0.897\n",
      "epoch  161 : Training loss:  0.0760445413923  Training Accuracy:  0.9058  Test Accuracy:  0.8971\n",
      "epoch  162 : Training loss:  0.0759661504192  Training Accuracy:  0.9059  Test Accuracy:  0.8973\n",
      "epoch  163 : Training loss:  0.0758884076695  Training Accuracy:  0.9061  Test Accuracy:  0.8974\n",
      "epoch  164 : Training loss:  0.0758113035853  Training Accuracy:  0.9065  Test Accuracy:  0.8974\n",
      "epoch  165 : Training loss:  0.0757348288095  Training Accuracy:  0.9066  Test Accuracy:  0.8974\n",
      "epoch  166 : Training loss:  0.07565897418  Training Accuracy:  0.9067  Test Accuracy:  0.8975\n",
      "epoch  167 : Training loss:  0.0755837307249  Training Accuracy:  0.9067  Test Accuracy:  0.8975\n",
      "epoch  168 : Training loss:  0.075509089657  Training Accuracy:  0.9068  Test Accuracy:  0.8975\n",
      "epoch  169 : Training loss:  0.0754350423691  Training Accuracy:  0.9068  Test Accuracy:  0.8977\n",
      "epoch  170 : Training loss:  0.0753615804293  Training Accuracy:  0.9069  Test Accuracy:  0.898\n",
      "epoch  171 : Training loss:  0.0752886955762  Training Accuracy:  0.9071  Test Accuracy:  0.898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  172 : Training loss:  0.0752163797146  Training Accuracy:  0.9073  Test Accuracy:  0.898\n",
      "epoch  173 : Training loss:  0.0751446249112  Training Accuracy:  0.9073  Test Accuracy:  0.8981\n",
      "epoch  174 : Training loss:  0.0750734233904  Training Accuracy:  0.9075  Test Accuracy:  0.8981\n",
      "epoch  175 : Training loss:  0.0750027675301  Training Accuracy:  0.9078  Test Accuracy:  0.898\n",
      "epoch  176 : Training loss:  0.074932649858  Training Accuracy:  0.9078  Test Accuracy:  0.8981\n",
      "epoch  177 : Training loss:  0.0748630630478  Training Accuracy:  0.9078  Test Accuracy:  0.8983\n",
      "epoch  178 : Training loss:  0.0747939999152  Training Accuracy:  0.9081  Test Accuracy:  0.8984\n",
      "epoch  179 : Training loss:  0.0747254534149  Training Accuracy:  0.9082  Test Accuracy:  0.8985\n",
      "epoch  180 : Training loss:  0.0746574166366  Training Accuracy:  0.9087  Test Accuracy:  0.8986\n",
      "epoch  181 : Training loss:  0.0745898828019  Training Accuracy:  0.9089  Test Accuracy:  0.8987\n",
      "epoch  182 : Training loss:  0.074522845261  Training Accuracy:  0.909  Test Accuracy:  0.8986\n",
      "epoch  183 : Training loss:  0.0744562974897  Training Accuracy:  0.9092  Test Accuracy:  0.8986\n",
      "epoch  184 : Training loss:  0.0743902330861  Training Accuracy:  0.9092  Test Accuracy:  0.8986\n",
      "epoch  185 : Training loss:  0.0743246457678  Training Accuracy:  0.9092  Test Accuracy:  0.8986\n",
      "epoch  186 : Training loss:  0.0742595293689  Training Accuracy:  0.9092  Test Accuracy:  0.8986\n",
      "epoch  187 : Training loss:  0.0741948778372  Training Accuracy:  0.9093  Test Accuracy:  0.8985\n",
      "epoch  188 : Training loss:  0.0741306852317  Training Accuracy:  0.9094  Test Accuracy:  0.8985\n",
      "epoch  189 : Training loss:  0.0740669457198  Training Accuracy:  0.9097  Test Accuracy:  0.8985\n",
      "epoch  190 : Training loss:  0.0740036535746  Training Accuracy:  0.9098  Test Accuracy:  0.8985\n",
      "epoch  191 : Training loss:  0.0739408031729  Training Accuracy:  0.9098  Test Accuracy:  0.8985\n",
      "epoch  192 : Training loss:  0.0738783889921  Training Accuracy:  0.9098  Test Accuracy:  0.8984\n"
     ]
    }
   ],
   "source": [
    "train_data_size = 10000\n",
    "epochs = 200\n",
    "learning_rate = 0.00007\n",
    "lamda = 0.000001\n",
    "gd_weights, train_loss = train_gd(train_data[:10000], epochs, learning_rate, lamda, test_data)\n",
    "test_prediction, test_labels, test_accuracy = inference(test_data, gd_weights)\n",
    "print \"test accuracy \", test_accuracy, \" training loss: \", train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.zeros((10,1))\n",
    "sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
